1
00:00:00,000 --> 00:00:04,525
字幕生成：Galaxies     字幕校对：NaHS

2
00:00:04,525 --> 00:00:06,600
Hello 大家好,我是ZOMI

3
00:00:06,600 --> 00:00:08,280
在 kernel 优化这个内容里面

4
00:00:08,360 --> 00:00:09,800
我知道应该看的人很少了

5
00:00:09,800 --> 00:00:11,600
而且我讲的确实并不太好

6
00:00:11,600 --> 00:00:14,280
今天来到了一个新的内容

7
00:00:14,280 --> 00:00:17,600
叫做间接优化 indirect 优化

8
00:00:17,600 --> 00:00:20,960
这个间接优化的方式还是很有意思的

9
00:00:20,960 --> 00:00:22,240
或者它有一些背景的

10
00:00:22,240 --> 00:00:24,960
看一下在整体的推进型的架构图

11
00:00:25,040 --> 00:00:26,840
现在位于 kernel 层

12
00:00:26,840 --> 00:00:28,120
就中间的这一层

13
00:00:28,120 --> 00:00:30,400
每个 kernel 或者每一个卷积

14
00:00:30,400 --> 00:00:32,440
看到的每一个卷积算子

15
00:00:32,440 --> 00:00:35,480
下面底层可能会对接非常多个 kernel 的

16
00:00:35,480 --> 00:00:37,640
所以在实际的实践过程当中

17
00:00:37,840 --> 00:00:40,840
你看到的你用到的是一个算子

18
00:00:41,040 --> 00:00:43,760
但是你们可能会执行不同的 kernel

19
00:00:43,760 --> 00:00:47,040
而不同的 kernel 是 runtime 去决定的

20
00:00:47,040 --> 00:00:49,560
在整个卷积 kernel 的优化内容里面

21
00:00:49,680 --> 00:00:51,560
现在来到了最后一个内容

22
00:00:51,560 --> 00:00:55,600
QNN Pack 间接卷积优化 indirect algorithm

23
00:00:55,840 --> 00:00:58,920
什幺为之间接的卷积优化呢

24
00:00:58,920 --> 00:01:00,280
现在来看一下

25
00:01:00,280 --> 00:01:02,920
首先一个很重要的概念就是

26
00:01:02,920 --> 00:01:03,920
QNN Pack

27
00:01:03,920 --> 00:01:06,240
QNN Pack 就是 Quantilization

28
00:01:06,240 --> 00:01:08,240
Neural Networks Package

29
00:01:08,240 --> 00:01:09,920
它是由 Facebook

30
00:01:09,920 --> 00:01:11,520
这个人后来去了谷歌

31
00:01:11,520 --> 00:01:13,320
后来现在不知道去哪了

32
00:01:13,320 --> 00:01:14,760
然后他在 Facebook 的时候

33
00:01:14,960 --> 00:01:18,120
当时候是为了对神经网络模型量化

34
00:01:18,120 --> 00:01:19,640
提出的一个算法

35
00:01:19,640 --> 00:01:21,080
当时候提出来的时候

36
00:01:21,280 --> 00:01:22,400
整体的性能

37
00:01:22,480 --> 00:01:24,160
确实已经击败了所有

38
00:01:24,200 --> 00:01:25,600
已公开的加速算法

39
00:01:25,600 --> 00:01:26,320
所以这个算法

40
00:01:26,680 --> 00:01:28,800
不仅仅能够用在量化的时候

41
00:01:28,800 --> 00:01:30,800
非量化的时候也可以去使用

42
00:01:30,800 --> 00:01:32,640
而且效果还是非常的惊人

43
00:01:33,640 --> 00:01:35,440
作者离开了 Facebook 之后

44
00:01:35,520 --> 00:01:36,640
因为在 Facebook 时候

45
00:01:36,760 --> 00:01:37,800
这个算法确实太好

46
00:01:37,800 --> 00:01:39,840
没有公开太多的实现的细节

47
00:01:39,840 --> 00:01:41,360
直到他离开了 Facebook 之后

48
00:01:41,520 --> 00:01:43,880
他就把这篇文章发表了出来

49
00:01:43,880 --> 00:01:45,040
而且就论证了

50
00:01:45,040 --> 00:01:48,520
确实这个算法的效果特别的好

51
00:01:49,480 --> 00:01:51,120
下面回顾一下

52
00:01:51,120 --> 00:01:53,400
Img2Col 的整体的一个算法

53
00:01:53,400 --> 00:01:55,880
现在其实很多卷积的算法

54
00:01:55,880 --> 00:01:58,320
基本上很少会叠代很多个 for

55
00:01:58,320 --> 00:02:01,120
更多的是使用 Img2Col 的算法去实现的

56
00:02:01,120 --> 00:02:02,920
所以不管是讲到

57
00:02:02,920 --> 00:02:03,960
Winograd 算法

58
00:02:04,080 --> 00:02:05,880
还是 QNN Packet 算法

59
00:02:06,320 --> 00:02:08,080
都基本上会经过 Img2Col

60
00:02:08,080 --> 00:02:09,880
来去进行一个比较

61
00:02:10,120 --> 00:02:11,920
假设现在要算一个

62
00:02:11,920 --> 00:02:13,760
MR乘以NR的小块的时候

63
00:02:14,120 --> 00:02:15,760
传统的 GEMM 的方法

64
00:02:15,920 --> 00:02:18,720
就是对 K 维度进行一个拆分

65
00:02:19,320 --> 00:02:20,160
下面看一下

66
00:02:20,160 --> 00:02:21,680
Img2Col 的整体的算法

67
00:02:21,720 --> 00:02:23,880
首先 Img2Col 假设

68
00:02:23,880 --> 00:02:25,240
B 就是 Kernels

69
00:02:25,240 --> 00:02:26,920
然后 A 就是 FeatureMap

70
00:02:26,920 --> 00:02:29,360
C 就是最终的输出的数据

71
00:02:29,360 --> 00:02:31,480
会把 Kernels 的一列

72
00:02:31,480 --> 00:02:33,320
乘以 FeatureMap 的一行

73
00:02:33,320 --> 00:02:36,520
得到最终输出的一个元素的值

74
00:02:36,520 --> 00:02:38,880
所以说它的计算量还是挺大的

75
00:02:38,880 --> 00:02:41,200
每次都要把很多的数据塞进去

76
00:02:41,200 --> 00:02:44,400
当然了为了更加的方便进行操作

77
00:02:44,400 --> 00:02:45,880
一般不会单算一个数

78
00:02:45,880 --> 00:02:48,760
而是会同一时间会算很多数

79
00:02:48,760 --> 00:02:51,000
也就是向量化的操作

80
00:02:51,080 --> 00:02:55,320
就把很多个 B 和 A 同时进行矩阵乘

81
00:02:55,320 --> 00:02:59,240
得到 C 里面的很多的数值

82
00:02:59,240 --> 00:03:03,200
那这个就是一个简单的向量化的加速

83
00:03:04,480 --> 00:03:06,920
后来有了分块之后

84
00:03:06,920 --> 00:03:08,480
或者分块的概念起来之后

85
00:03:08,680 --> 00:03:10,920
在传统的方法就是对 K 维度

86
00:03:10,920 --> 00:03:14,120
就 B 的卷积和按 K 维度进行拆分

87
00:03:14,120 --> 00:03:15,400
在一次计算的时候

88
00:03:15,520 --> 00:03:17,240
只算 K 的某个值

89
00:03:17,240 --> 00:03:19,000
然后 A 就是 FeatureMap

90
00:03:19,040 --> 00:03:21,280
也是按这个维度进行拆分

91
00:03:21,280 --> 00:03:22,840
然后算每一个值

92
00:03:22,840 --> 00:03:25,840
然后再把这些值进行一个累加

93
00:03:25,840 --> 00:03:27,520
但这个时候就会引起

94
00:03:27,520 --> 00:03:30,280
额外的输出的加载和存储了

95
00:03:30,560 --> 00:03:32,160
每次都会有额外的数据

96
00:03:32,160 --> 00:03:35,200
在内存里面重新的加载和存储

97
00:03:36,000 --> 00:03:37,640
下面简单的看一下

98
00:03:37,640 --> 00:03:39,440
QNNPack 这个算法的思想

99
00:03:39,440 --> 00:03:42,280
这里面就 QNNPack indirect 的方法

100
00:03:42,280 --> 00:03:46,760
基本上就消除了输出部分的额外的访存

101
00:03:46,760 --> 00:03:50,000
虽然可以看到 B 还是按 K 维度进行拆分

102
00:03:50,000 --> 00:03:51,360
不是说不拆分

103
00:03:51,360 --> 00:03:52,560
而是拆分之后

104
00:03:53,000 --> 00:03:55,000
不和其他维度进行交换

105
00:03:55,000 --> 00:03:57,680
和重新的一个额外的访存的计算

106
00:03:58,040 --> 00:03:59,480
具体它是怎幺实现的

107
00:03:59,480 --> 00:04:01,040
下面来分解一下

108
00:04:01,040 --> 00:04:02,320
在进入下个内容之前

109
00:04:02,640 --> 00:04:04,200
小新有两个问题

110
00:04:04,440 --> 00:04:06,040
第一个问题就是

111
00:04:07,600 --> 00:04:08,720
ZOMI老师你好

112
00:04:08,720 --> 00:04:11,240
你刚才提到 Img2Col 优化算法

113
00:04:11,440 --> 00:04:12,840
有两个问题

114
00:04:12,920 --> 00:04:16,720
第一个就是会占用额外大量的内存

115
00:04:17,480 --> 00:04:22,200
第二个是需要对输入的数据进行额外的拷贝

116
00:04:22,560 --> 00:04:25,400
这两点 QNNPack 怎幺来解决吗

117
00:04:26,520 --> 00:04:27,560
很有意思

118
00:04:27,920 --> 00:04:30,080
QNNPack 最核心的算法

119
00:04:30,080 --> 00:04:32,960
叫做间接卷积优化算法

120
00:04:33,280 --> 00:04:36,640
它的答案就是有一个间接的缓冲区

121
00:04:36,880 --> 00:04:38,040
Indirect Buffer

122
00:04:38,280 --> 00:04:40,480
首先创建一个间接的缓冲区

123
00:04:40,720 --> 00:04:43,120
对内存进行重新的组织

124
00:04:43,120 --> 00:04:44,480
叫做 Repacking

125
00:04:44,520 --> 00:04:47,880
这样就可以提高整体的命中率

126
00:04:47,880 --> 00:04:49,320
从而提高性能

127
00:04:49,320 --> 00:04:51,960
所以说在卷积的优化

128
00:04:51,960 --> 00:04:53,360
或者一些 kernel 的优化

129
00:04:53,360 --> 00:04:56,040
是离不开对内存的一个优化的

130
00:04:56,040 --> 00:04:57,960
它们俩是相辅相成

131
00:04:57,960 --> 00:05:00,320
下面简单的来去看一下

132
00:05:00,320 --> 00:05:02,360
什幺叫做间接缓冲区

133
00:05:02,360 --> 00:05:04,240
就是间接卷积算法最内核的

134
00:05:04,240 --> 00:05:05,800
就是间接缓冲区了

135
00:05:07,000 --> 00:05:08,280
原来这样

136
00:05:08,480 --> 00:05:10,240
快点给我讲讲吧

137
00:05:14,520 --> 00:05:16,440
好下面来到了

138
00:05:16,440 --> 00:05:20,440
Indirect 卷积算法的整体工作流程

139
00:05:20,720 --> 00:05:22,360
首先 Indirect 卷积算法

140
00:05:22,400 --> 00:05:24,440
简单的看看下面这个图

141
00:05:24,440 --> 00:05:25,800
后面的所有图

142
00:05:26,080 --> 00:05:27,960
它的颜色我都是对齐的

143
00:05:28,000 --> 00:05:29,160
简单的来讲讲

144
00:05:29,160 --> 00:05:30,080
input 的数据

145
00:05:30,080 --> 00:05:31,160
或者 feature map

146
00:05:31,520 --> 00:05:33,960
会以红色的模块作为主

147
00:05:34,000 --> 00:05:35,600
然后权重

148
00:05:35,840 --> 00:05:38,160
会以绿色的小方框作为主

149
00:05:38,200 --> 00:05:39,840
而最终 output 的输出

150
00:05:40,040 --> 00:05:42,680
也会用橙色的模块

151
00:05:42,680 --> 00:05:45,040
作为一个主要的颜色

152
00:05:45,280 --> 00:05:47,600
这里面 IH IC IW

153
00:05:47,600 --> 00:05:48,720
H和W

154
00:05:49,040 --> 00:05:50,880
就是长和宽

155
00:05:50,880 --> 00:05:52,520
对于 I 就是 input

156
00:05:52,560 --> 00:05:54,400
而 O 就是 output

157
00:05:54,440 --> 00:05:56,400
而 K 就是 kernels 的大小

158
00:05:57,160 --> 00:05:59,240
这些概念在前几节课

159
00:05:59,480 --> 00:06:02,600
都是完完全全是对应起来的

160
00:06:02,600 --> 00:06:03,680
现在可以看到

161
00:06:03,960 --> 00:06:05,880
实际上不会把所有的

162
00:06:05,880 --> 00:06:07,000
input 的 feature map

163
00:06:07,520 --> 00:06:08,920
同时加载到 L1

164
00:06:08,920 --> 00:06:10,320
或者 L2 缓存里面

165
00:06:10,320 --> 00:06:12,080
而是先把一部分的数据

166
00:06:12,240 --> 00:06:14,960
搬到输入的缓冲区

167
00:06:14,960 --> 00:06:16,400
也就是 input buffer

168
00:06:16,680 --> 00:06:19,320
然后这里面 indirect convolution

169
00:06:19,320 --> 00:06:20,680
间接卷积优化算法

170
00:06:20,840 --> 00:06:23,360
就引入了一个间接的缓冲区

171
00:06:23,360 --> 00:06:25,400
indirect buffer 这个内容

172
00:06:25,960 --> 00:06:26,960
而间接的缓冲区

173
00:06:27,120 --> 00:06:29,240
是整个算法的一个内核

174
00:06:29,240 --> 00:06:30,440
在网络计算的时候

175
00:06:30,560 --> 00:06:33,720
首先会计算 m*m 的输出

176
00:06:33,720 --> 00:06:36,800
也就是 m*m 的简单的输出

177
00:06:37,040 --> 00:06:38,120
这一个内容

178
00:06:38,520 --> 00:06:41,200
每次我只计算一小个模块

179
00:06:41,520 --> 00:06:44,160
现在已经了解了 indirect buffer

180
00:06:44,160 --> 00:06:46,480
下面大家可以重新的看看这个图

181
00:06:46,480 --> 00:06:49,840
下面也会详细的去展开介绍的

182
00:06:50,600 --> 00:06:53,720
在计算 m*n 规模的大小输出的时候

183
00:06:54,120 --> 00:06:55,800
间接缓冲区

184
00:06:55,960 --> 00:06:58,040
就会取出对应的数据

185
00:06:58,040 --> 00:07:00,840
这里面对应的数据就是 ic*m

186
00:07:00,840 --> 00:07:03,800
然后也会取出对应的权重的数据

187
00:07:03,800 --> 00:07:06,680
去计算 ic*m 和 ic*n

188
00:07:06,680 --> 00:07:09,120
最后是得到 m*m 的数据

189
00:07:09,120 --> 00:07:10,880
塞给输出

190
00:07:11,040 --> 00:07:12,880
这里面怎幺去预储数据

191
00:07:12,880 --> 00:07:15,840
indirect buffer 里面的数据的排布

192
00:07:16,120 --> 00:07:18,160
就显得尤为重要了

193
00:07:18,520 --> 00:07:20,120
下面看一下

194
00:07:20,120 --> 00:07:21,800
在实际的实践当中

195
00:07:22,160 --> 00:07:25,160
软件的执行就分为两个部分

196
00:07:25,920 --> 00:07:27,840
第一部分就是准备阶段

197
00:07:27,840 --> 00:07:29,000
在加载模型的时候

198
00:07:29,080 --> 00:07:32,280
就需要去配置输入的缓冲区

199
00:07:32,280 --> 00:07:33,560
也就是 indirect buffer

200
00:07:33,880 --> 00:07:36,040
第二步需要重排权重

201
00:07:36,280 --> 00:07:38,040
重排权重其实一模一样

202
00:07:38,040 --> 00:07:39,400
可以在离线转换模块

203
00:07:39,400 --> 00:07:40,280
或者预编译阶段

204
00:07:40,600 --> 00:07:41,560
进行重排

205
00:07:41,560 --> 00:07:43,200
使得内存布局

206
00:07:43,640 --> 00:07:45,440
是方便后续

207
00:07:45,440 --> 00:07:47,520
跟输入缓冲区进行相成的

208
00:07:47,760 --> 00:07:49,680
接着第二步就是运行阶段

209
00:07:49,840 --> 00:07:50,840
真正的运行阶段

210
00:07:50,840 --> 00:07:52,240
就是 runtime 阶段

211
00:07:52,240 --> 00:07:54,400
或者 runtime 调起 kernel 的时候

212
00:07:54,400 --> 00:07:56,320
需要对每个输入的执行

213
00:07:56,680 --> 00:07:58,880
进行 OH 乘以 OW 除以 M

214
00:07:58,880 --> 00:08:01,200
乘以 OC 除以 N 次循环

215
00:08:01,200 --> 00:08:02,480
很多次循环

216
00:08:02,480 --> 00:08:04,160
每次使用 GEMM

217
00:08:04,160 --> 00:08:07,240
去计算 M 乘 N 的大小的输出

218
00:08:08,080 --> 00:08:09,920
下面来到间接缓冲区

219
00:08:09,920 --> 00:08:10,840
里面最核心的

220
00:08:10,840 --> 00:08:12,680
看看它到底是怎幺布局的

221
00:08:13,160 --> 00:08:14,560
首先间接缓冲区

222
00:08:14,560 --> 00:08:15,960
 localindoorbuff

223
00:08:15,960 --> 00:08:17,240
可以简单理解为

224
00:08:17,240 --> 00:08:19,240
一组卷积核大小的缓冲区

225
00:08:19,240 --> 00:08:21,560
一共有 OH 乘以 OW 个

226
00:08:21,560 --> 00:08:23,560
每个这是简单的一个

227
00:08:23,880 --> 00:08:27,120
每个缓冲区大小为 KH 乘以 KW

228
00:08:27,800 --> 00:08:28,600
在计算的时候

229
00:08:28,760 --> 00:08:30,200
随着整体的输出的

230
00:08:30,200 --> 00:08:31,600
所有的内存地址的移动

231
00:08:31,720 --> 00:08:34,240
选用不同的间接的缓冲区

232
00:08:34,240 --> 00:08:36,560
你就可以得到相应的输出的地址

233
00:08:36,560 --> 00:08:39,320
没有必要去根据输出的目标重新去

234
00:08:39,320 --> 00:08:40,440
锁定地址

235
00:08:40,720 --> 00:08:43,480
这种方式其实类似于传统进程里面的

236
00:08:43,480 --> 00:08:45,200
用空间换时间的概念

237
00:08:45,680 --> 00:08:47,360
现在放大来看一下

238
00:08:47,360 --> 00:08:49,560
左边这个红色都是 featuremap

239
00:08:49,560 --> 00:08:50,640
或者输入码

240
00:08:50,640 --> 00:08:52,640
会预取一个 input buffer

241
00:08:52,640 --> 00:08:55,040
把一些一部分的数据预取出来

242
00:08:55,040 --> 00:08:57,080
假设现在取的一个简单的

243
00:08:57,080 --> 00:08:58,040
一个快的数据

244
00:08:58,040 --> 00:09:00,560
里面 IH 乘以 IW 乘以 IC

245
00:09:00,560 --> 00:09:04,120
这个时候对之前里面的某个卷积核

246
00:09:04,120 --> 00:09:05,920
或者对里面的某个 kernels 大小

247
00:09:05,920 --> 00:09:07,520
就会把它取出来

248
00:09:07,640 --> 00:09:13,000
把数据按照 012 1234 4567

249
00:09:13,000 --> 00:09:15,600
这种方式进行一个预取

250
00:09:15,600 --> 00:09:17,480
预取成为 indirect buffer

251
00:09:17,480 --> 00:09:20,480
把它变成一个间接的缓冲区

252
00:09:20,480 --> 00:09:21,960
这个间接缓冲区很有意思

253
00:09:21,960 --> 00:09:23,960
就 0123 1234 2345

254
00:09:23,960 --> 00:09:26,920
然后通过这种方式就以空间换时间

255
00:09:26,920 --> 00:09:29,800
把大量的数据全部取出来

256
00:09:29,800 --> 00:09:31,880
方便后续的直接相乘

257
00:09:31,880 --> 00:09:32,640
直接相乘之后

258
00:09:32,640 --> 00:09:35,120
直接得到最后的结果了

259
00:09:36,120 --> 00:09:37,760
其实卷集可以使用

260
00:09:37,760 --> 00:09:39,920
Img2Col 这种优化的算法

261
00:09:39,920 --> 00:09:41,960
本质原因主要是拆分之后

262
00:09:41,960 --> 00:09:43,720
可以忽略内存附用之后的

263
00:09:43,720 --> 00:09:46,760
整个计算过程等价于矩阵乘

264
00:09:46,760 --> 00:09:48,960
也就是使用矩阵乘

265
00:09:48,960 --> 00:09:52,680
对卷集进行一个替换

266
00:09:52,680 --> 00:09:54,760
而间接缓冲区就可以通过大量的

267
00:09:54,760 --> 00:09:56,320
复制地址的数据

268
00:09:56,320 --> 00:09:58,760
然后通过向量化或者模拟向量化的方式

269
00:09:58,760 --> 00:10:00,960
模拟出对输入的访存

270
00:10:00,960 --> 00:10:02,160
这种方式的优点

271
00:10:02,160 --> 00:10:04,120
就是解决空间向量化的问题

272
00:10:04,120 --> 00:10:06,920
同时可以计算很多个数据

273
00:10:06,920 --> 00:10:09,760
第2个就是地址计算会变得更加简单

274
00:10:09,760 --> 00:10:12,160
因为我不需要不断的去寻址了

275
00:10:12,160 --> 00:10:14,160
或者指针来回的去跳跃

276
00:10:14,160 --> 00:10:15,880
而是直接根据下一个地址

277
00:10:15,880 --> 00:10:17,840
去预取数据就行了

278
00:10:17,840 --> 00:10:19,760
第3个就是解决内存

279
00:10:19,760 --> 00:10:22,280
大量的重复拷贝的问题

280
00:10:22,280 --> 00:10:24,080
但是缺点也很明确

281
00:10:24,080 --> 00:10:26,840
就是创建整个数据的缓冲区

282
00:10:26,840 --> 00:10:29,320
需要大量的内存空间

283
00:10:29,320 --> 00:10:32,600
第4个就是数据进行重排 Repacking

284
00:10:32,600 --> 00:10:35,360
会消耗大量的访存

285
00:10:35,360 --> 00:10:37,480
或者大量的预编译的时间

286
00:10:38,360 --> 00:10:41,400
下面对整个卷积算法

287
00:10:41,400 --> 00:10:43,240
进行总结一下

288
00:10:43,560 --> 00:10:45,280
最后一个内容

289
00:10:45,280 --> 00:10:46,960
就是对之前讲到的

290
00:10:46,960 --> 00:10:49,120
好几个 kernel 卷积优化的算法

291
00:10:49,320 --> 00:10:51,560
进行一个横向的总结

292
00:10:51,560 --> 00:10:55,320
首先上面的视频所讲的方法

293
00:10:55,520 --> 00:10:58,280
都是通用的卷积的优化方法

294
00:10:58,520 --> 00:10:59,480
随着神经网络

295
00:10:59,480 --> 00:11:02,760
或者很多的新的 AI 处理器的出现

296
00:11:03,200 --> 00:11:05,160
整个算法的优化

297
00:11:05,160 --> 00:11:07,320
其实还在不断的深挖的

298
00:11:07,320 --> 00:11:10,040
因为不同的卷积的方式

299
00:11:10,040 --> 00:11:12,160
会使用到不同的处理器里面的

300
00:11:12,160 --> 00:11:13,720
一些重要的指令

301
00:11:13,720 --> 00:11:15,880
而且有可能会有更多的新的指令

302
00:11:15,880 --> 00:11:16,680
会提出

303
00:11:16,680 --> 00:11:17,880
例如一开始之前

304
00:11:17,880 --> 00:11:19,360
可能五六年前

305
00:11:19,360 --> 00:11:20,840
我在做深度学习的时候

306
00:11:20,960 --> 00:11:22,240
还没想到会使用到

307
00:11:22,240 --> 00:11:23,600
int8 相关的指令的

308
00:11:23,600 --> 00:11:24,920
或者一些张量的指令

309
00:11:24,920 --> 00:11:27,000
现在 int4, int2

310
00:11:27,000 --> 00:11:28,880
或者 int8 的指令越来越多

311
00:11:28,920 --> 00:11:30,960
而相关的除了向量化的指令

312
00:11:30,960 --> 00:11:32,560
还出现了张量化的指令

313
00:11:32,560 --> 00:11:33,600
也越来越多

314
00:11:33,600 --> 00:11:35,720
不管是 SIMP 还是 SIMD 的架构

315
00:11:35,720 --> 00:11:37,800
也会不断的去演进

316
00:11:38,720 --> 00:11:39,200
好了

317
00:11:39,200 --> 00:11:40,960
今天的内容就到这里为止

318
00:11:40,960 --> 00:11:41,680
谢谢各位

319
00:11:41,680 --> 00:11:42,840
拜拜

320
00:11:43,680 --> 00:11:44,440
卷得不行了

321
00:11:44,440 --> 00:11:45,320
卷得不行了

322
00:11:45,320 --> 00:11:46,760
记得一键三连加关注

323
00:11:47,160 --> 00:11:48,520
所有的内容都会开源

324
00:11:48,520 --> 00:11:50,360
在下面这条链接里面

325
00:11:50,720 --> 00:11:51,680
拜拜

