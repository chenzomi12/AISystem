1
00:00:00,000 --> 00:00:04,560
字幕生成：qiaokai  字幕校对：A 是传奇

2
00:00:04,560 --> 00:00:07,120
诶,诶哟,已经开始了

3
00:00:07,120 --> 00:00:09,000
大家好,我是 ZOMI

4
00:00:09,000 --> 00:00:13,280
今天还是模型转换和优化的系列里面

5
00:00:13,280 --> 00:00:18,040
今天主要给大家介绍的一个内容是模型转换的技术细节

6
00:00:18,040 --> 00:00:20,554
就真正的来到模型转换怎么转

7
00:00:20,554 --> 00:00:22,554
应该怎么去定义自己的计算图

8
00:00:23,200 --> 00:00:27,720
之前有很多好朋友建议 ZOMI 去讲一些具体的代码

9
00:00:27,720 --> 00:00:28,960
不要讲太虚的东西

10
00:00:28,960 --> 00:00:32,560
但是 ZOMI 还是觉得也一定要跳出具体的代码

11
00:00:32,560 --> 00:00:34,000
跳出具体的工程

12
00:00:34,000 --> 00:00:37,200
跳出具体每天编码的事情来看一看

13
00:00:37,200 --> 00:00:38,600
看一看整体的原理

14
00:00:38,600 --> 00:00:40,000
看一看整体的架构

15
00:00:40,000 --> 00:00:40,920
去了解一下

16
00:00:40,920 --> 00:00:42,400
看一下不同的 AI 框架

17
00:00:42,400 --> 00:00:43,680
不同的 AI 编译器

18
00:00:43,680 --> 00:00:44,920
不同的推理引擎

19
00:00:44,920 --> 00:00:47,360
他整体上面有什么差异

20
00:00:47,360 --> 00:00:50,880
它使用不同的文件格式有什么不一样的地方

21
00:00:50,880 --> 00:00:51,840
每一个模块

22
00:00:51,840 --> 00:00:52,600
每一个流程

23
00:00:52,600 --> 00:00:53,440
每一个细节

24
00:00:53,440 --> 00:00:55,560
都应该知道

25
00:00:55,560 --> 00:00:59,360
只有这样才能够称为自己是一个 AI 系统的专家

26
00:01:00,480 --> 00:01:03,400
而不是像我以前聚焦于某一个特性

27
00:01:03,400 --> 00:01:05,320
你们知道这个特性应该怎么写

28
00:01:05,320 --> 00:01:06,920
这代码我能讲得很明白

29
00:01:06,920 --> 00:01:09,400
而且我可以给你讲代码讲两三个小时

30
00:01:09,400 --> 00:01:11,080
但是我那个时候还做不到

31
00:01:11,080 --> 00:01:13,240
我能够跳出这个特性出来

32
00:01:13,240 --> 00:01:15,560
去看一看这个特性跟其他特性

33
00:01:15,560 --> 00:01:17,520
看看整体有什么区别

34
00:01:17,520 --> 00:01:19,560
这也是我希望给大家去汇报

35
00:01:19,560 --> 00:01:22,200
或者给大家去掌握的一个思想

36
00:01:23,520 --> 00:01:24,600
其实在上一节课

37
00:01:24,640 --> 00:01:28,600
了解了一下模型转换的一个具体的格式

38
00:01:28,600 --> 00:01:29,720
还有相关的内容

39
00:01:30,400 --> 00:01:32,080
今天很重要的一个内容

40
00:01:32,080 --> 00:01:34,520
就是了解一下怎么自定义一个计算图

41
00:01:34,520 --> 00:01:36,600
还有转换的流程和细节

42
00:01:37,880 --> 00:01:39,960
下面来看一下计算图的回顾

43
00:01:40,160 --> 00:01:41,880
既然谈到计算图

44
00:01:41,880 --> 00:01:44,960
肯定需要去回顾一下什么是计算图

45
00:01:46,400 --> 00:01:47,760
ZOMI 老师你好

46
00:01:48,600 --> 00:01:50,520
你说要讲计算图

47
00:01:50,520 --> 00:01:52,000
但是我想问一下

48
00:01:52,120 --> 00:01:55,160
为什么推理引擎需要自定义计算图呢

49
00:01:56,640 --> 00:01:58,720
小心又来了一个灵魂问题

50
00:01:59,640 --> 00:02:02,120
可以看到在整个转换模块架构里面

51
00:02:02,120 --> 00:02:04,400
它分为一个转换模块

52
00:02:04,400 --> 00:02:05,880
还有图优化

53
00:02:05,880 --> 00:02:09,360
中间是有一个 IR 或者计算图来去承载

54
00:02:09,360 --> 00:02:11,200
会把不同的 AI 框架

55
00:02:11,200 --> 00:02:13,000
去对接到同一个 IR

56
00:02:13,000 --> 00:02:14,360
有了这个 IR 之后

57
00:02:14,360 --> 00:02:16,680
就可以很方便的做一些

58
00:02:16,680 --> 00:02:19,280
很多的不同的图优化的工作

59
00:02:19,280 --> 00:02:20,640
那这些图优化的工作

60
00:02:20,640 --> 00:02:22,800
都是基于一个很重要的概念

61
00:02:22,800 --> 00:02:23,920
就是计算图

62
00:02:23,920 --> 00:02:26,800
所以说不管是推理引擎也好

63
00:02:26,800 --> 00:02:27,920
AI 训练框架也好

64
00:02:27,920 --> 00:02:29,720
计算图这个概念

65
00:02:29,720 --> 00:02:31,440
还是非常的重要

66
00:02:31,440 --> 00:02:34,280
于是 ZOMI 在之前 AI 框架的分享里面

67
00:02:34,440 --> 00:02:36,560
就有一个非常详细的系列了

68
00:02:36,560 --> 00:02:39,520
去独立的把计算图每一个模块

69
00:02:39,520 --> 00:02:42,920
都展开的去详细的给大家去汇报

70
00:02:44,440 --> 00:02:47,960
下面看一下计算图的一个基本的组成

71
00:02:48,040 --> 00:02:49,360
这个也是 AI 框架

72
00:02:49,400 --> 00:02:51,920
不管现在是 AI 框架还是推理引擎

73
00:02:52,160 --> 00:02:53,680
它的基本组成都是不变

74
00:02:53,680 --> 00:02:57,080
因为前提的出于是计算图

75
00:02:57,680 --> 00:02:59,680
现在看一下计算图的具体的组成

76
00:02:59,680 --> 00:03:00,640
有两个

77
00:03:00,640 --> 00:03:01,960
一个是张量

78
00:03:01,960 --> 00:03:03,880
一个是算子

79
00:03:04,280 --> 00:03:07,200
张量就是整个计算图去流传的数据

80
00:03:07,200 --> 00:03:09,040
或者计算图里面去计算的数据

81
00:03:09,040 --> 00:03:12,320
而算子就是具体的执行的单元

82
00:03:13,240 --> 00:03:14,240
ZOMI 老师你好

83
00:03:14,720 --> 00:03:16,200
我又有个问题了

84
00:03:17,400 --> 00:03:18,200
你说

85
00:03:19,200 --> 00:03:20,800
AI 框架的计算图

86
00:03:20,800 --> 00:03:23,600
和推理引擎的计算图有什么不同吗

87
00:03:24,760 --> 00:03:27,040
这个问题确实问的挺好

88
00:03:27,040 --> 00:03:30,000
这也是我应该总结了好一段时间

89
00:03:30,000 --> 00:03:32,120
这个表确实我总结了挺久

90
00:03:32,120 --> 00:03:33,920
有十来分钟

91
00:03:34,480 --> 00:03:35,600
下面看一下

92
00:03:35,600 --> 00:03:36,760
AI 框架计算图

93
00:03:36,760 --> 00:03:38,120
还有推理引擎的计算图

94
00:03:38,560 --> 00:03:40,280
对比了几个维度

95
00:03:40,280 --> 00:03:41,920
一个是它的一个组成

96
00:03:41,920 --> 00:03:43,080
接着是正反向

97
00:03:43,080 --> 00:03:43,880
动静态图

98
00:03:43,880 --> 00:03:44,840
还有分布式并行

99
00:03:44,840 --> 00:03:46,480
还有具体的使用场景

100
00:03:46,760 --> 00:03:48,320
可以看到计算图的组成

101
00:03:48,320 --> 00:03:49,560
AI 框架的计算图

102
00:03:49,560 --> 00:03:50,880
和推理引擎的计算图

103
00:03:50,880 --> 00:03:52,080
其实是差不多

104
00:03:52,080 --> 00:03:53,920
但是有一个很大的区别

105
00:03:53,920 --> 00:03:55,320
就是推理引擎更多的是

106
00:03:55,320 --> 00:03:56,920
聚焦于做一个 forward

107
00:03:56,920 --> 00:03:58,120
前向的计算

108
00:03:58,120 --> 00:03:59,080
不需要 backward

109
00:03:59,080 --> 00:04:00,680
就不需要有反向了

110
00:04:00,680 --> 00:04:02,400
而在动静态图里面

111
00:04:02,520 --> 00:04:03,360
确实 AI 框架

112
00:04:03,360 --> 00:04:05,040
它需要支持非常灵活

113
00:04:05,040 --> 00:04:06,080
动态图的写法

114
00:04:06,080 --> 00:04:07,960
但是有时候在训练过程当中

115
00:04:07,960 --> 00:04:09,440
希望它越快越好

116
00:04:09,440 --> 00:04:11,280
于是会有一个动静转移

117
00:04:11,280 --> 00:04:12,160
或者动静统一

118
00:04:12,160 --> 00:04:14,520
或者动静态图都支持的情况

119
00:04:14,520 --> 00:04:15,320
而推理引擎

120
00:04:15,440 --> 00:04:17,480
大部分都是以静态图为主

121
00:04:17,760 --> 00:04:19,160
基本上在推理引擎

122
00:04:19,160 --> 00:04:20,520
不希望它是一个动态图

123
00:04:20,520 --> 00:04:22,360
动态图对推理引擎

124
00:04:22,360 --> 00:04:23,320
时间的消耗

125
00:04:23,320 --> 00:04:24,760
对 Runtime 的调度

126
00:04:24,760 --> 00:04:25,880
还有 Kernel 的调度

127
00:04:25,880 --> 00:04:27,720
确实非常的不友好

128
00:04:28,240 --> 00:04:29,280
所以一般都会把它

129
00:04:29,280 --> 00:04:31,200
转为静态图去进行执行的话

130
00:04:31,200 --> 00:04:32,520
大家一定要注意这个点

131
00:04:32,520 --> 00:04:33,400
就是一个 forward

132
00:04:33,400 --> 00:04:34,560
一个静态图

133
00:04:34,560 --> 00:04:36,040
接着分布式并行

134
00:04:36,040 --> 00:04:36,480
AI 框架

135
00:04:36,480 --> 00:04:38,800
之前确实有三个系列

136
00:04:38,800 --> 00:04:40,880
去单独的去汇报了给大家

137
00:04:40,880 --> 00:04:42,040
AI 框架的计算图

138
00:04:42,040 --> 00:04:43,520
到底是怎么样去切分

139
00:04:43,520 --> 00:04:44,760
应该有哪些策略

140
00:04:44,880 --> 00:04:45,880
但是在推理引擎

141
00:04:45,880 --> 00:04:47,600
大部分都是以

142
00:04:47,600 --> 00:04:49,320
单卡的推理服务为主

143
00:04:49,320 --> 00:04:51,600
很少去考虑分布式的推理

144
00:04:51,600 --> 00:04:52,680
确实分布式的推理

145
00:04:52,680 --> 00:04:55,120
至少 ZOMI 在从业这么多年

146
00:04:55,120 --> 00:04:57,680
没有遇到过太多相关的工作

147
00:04:57,680 --> 00:04:58,240
有是有

148
00:04:58,240 --> 00:04:59,400
但是基本上很少

149
00:04:59,400 --> 00:05:00,160
很少客户

150
00:05:00,160 --> 00:05:01,720
大部分都是创新的场景

151
00:05:02,080 --> 00:05:03,720
最后一个就是看一下

152
00:05:03,720 --> 00:05:04,920
AI 框架的计算图

153
00:05:05,040 --> 00:05:06,800
更多的是指训练的场景

154
00:05:06,800 --> 00:05:08,120
支持科研的创新

155
00:05:08,120 --> 00:05:09,880
对网络模型的训练的微调

156
00:05:09,960 --> 00:05:11,240
提升算法为主

157
00:05:11,240 --> 00:05:14,320
但是推理引擎确实它比较特别

158
00:05:14,320 --> 00:05:16,320
它的计算图主要是支持

159
00:05:16,320 --> 00:05:18,360
工业级的应用的部署

160
00:05:18,360 --> 00:05:19,440
对外提供服务

161
00:05:19,440 --> 00:05:22,200
所以说因为这些特殊的原因

162
00:05:22,200 --> 00:05:26,560
所以推理引擎有自己的计算图的定义

163
00:05:26,560 --> 00:05:27,920
当然它也可以复用

164
00:05:27,920 --> 00:05:29,760
AI 框架计算图的定义

165
00:05:29,760 --> 00:05:32,320
这个也是 MindSpore 端营统一的一个概念

166
00:05:32,320 --> 00:05:34,040
废话就不多说了

167
00:05:34,040 --> 00:05:35,720
继续往下看一看

168
00:05:37,760 --> 00:05:39,040
接下来看一下

169
00:05:39,040 --> 00:05:41,480
推理引擎到底怎么样去定义

170
00:05:41,480 --> 00:05:42,440
一个计算图

171
00:05:42,440 --> 00:05:43,760
计算图的最基本

172
00:05:43,760 --> 00:05:45,240
应该有哪些结构

173
00:05:45,240 --> 00:05:48,240
这里面我就会带着大家去看一看

174
00:05:48,240 --> 00:05:49,440
具体的代码

175
00:05:50,000 --> 00:05:51,680
下面来回顾一下

176
00:05:51,680 --> 00:05:52,560
重新回顾一下

177
00:05:52,560 --> 00:05:53,960
计算图有两个组成

178
00:05:53,960 --> 00:05:55,880
第一个就是张量 Tensor

179
00:05:55,880 --> 00:05:57,200
第二个就是 Operation

180
00:05:57,200 --> 00:05:57,840
算子

181
00:05:57,840 --> 00:05:59,320
执行单元

182
00:05:59,720 --> 00:06:01,600
下面就不看 slide 了

183
00:06:01,600 --> 00:06:02,440
就不看 PPT 了

184
00:06:02,440 --> 00:06:04,240
而转到具体的代码

185
00:06:05,960 --> 00:06:07,520
原量 ZOMI 的鼠标

186
00:06:07,720 --> 00:06:09,080
一直都是比较大

187
00:06:09,080 --> 00:06:10,760
我也被很多人吐槽过

188
00:06:10,760 --> 00:06:12,680
说我已经是老人眼了

189
00:06:12,800 --> 00:06:14,680
确实鼠标大一点好看了

190
00:06:14,680 --> 00:06:17,240
不要去看一看它

191
00:06:17,960 --> 00:06:20,520
我建议大家都把自己的鼠标调大一点

192
00:06:20,520 --> 00:06:22,320
确实很方便很舒服

193
00:06:22,320 --> 00:06:24,840
现在回到推理引擎计算图

194
00:06:24,840 --> 00:06:26,840
一个 Tensor 张量的表示

195
00:06:26,840 --> 00:06:27,840
首先张量

196
00:06:27,840 --> 00:06:29,800
肯定要定义自己的数据结构

197
00:06:29,800 --> 00:06:31,720
证明推理引擎

198
00:06:31,720 --> 00:06:35,080
里面支持哪几种的数据的运行的方式

199
00:06:35,280 --> 00:06:36,560
一般都会定义

200
00:06:36,560 --> 00:06:38,240
Double,FLOAT,Int32

201
00:06:38,240 --> 00:06:40,360
这些跟传统的计算机没什么区别

202
00:06:40,360 --> 00:06:41,960
叫做 Data Type

203
00:06:42,080 --> 00:06:43,920
接着要定义一个非常重要的内容

204
00:06:44,080 --> 00:06:46,240
就是数据的排布

205
00:06:46,920 --> 00:06:48,720
在 AI 编译器前端优化里面

206
00:06:48,840 --> 00:06:50,920
确实提到单独提到过

207
00:06:50,920 --> 00:06:51,920
数据的排布

208
00:06:51,920 --> 00:06:52,960
而且开了两节课

209
00:06:52,960 --> 00:06:55,320
去给大家去介绍了大概 20 分钟

210
00:06:55,320 --> 00:06:58,360
这里面包括 NCHW,NHWC

211
00:06:58,360 --> 00:07:00,400
NCHWC0,ND

212
00:07:00,400 --> 00:07:01,360
不同的格式

213
00:07:01,480 --> 00:07:03,440
确实需要声明

214
00:07:03,440 --> 00:07:04,600
就告诉 AI 框架

215
00:07:04,600 --> 00:07:05,720
或告诉算子

216
00:07:05,720 --> 00:07:09,160
我执行的到底是一个什么样的数据的排布

217
00:07:09,160 --> 00:07:10,440
有了这两个之后

218
00:07:10,640 --> 00:07:12,880
还要定义张量

219
00:07:13,080 --> 00:07:14,560
张量就会比较简单

220
00:07:14,560 --> 00:07:15,680
这里面的内容不太多

221
00:07:15,680 --> 00:07:17,280
第一个就是张量的 DimS

222
00:07:17,280 --> 00:07:18,360
张量的 Shape

223
00:07:18,360 --> 00:07:20,560
它到底是一个什么样的形态

224
00:07:20,560 --> 00:07:23,080
接着就会有一个 Data Format

225
00:07:23,080 --> 00:07:25,840
Data Format 就是刚才所定义

226
00:07:25,840 --> 00:07:28,040
这个 Data Format 到底是 NCHW

227
00:07:28,040 --> 00:07:29,360
还是 NHWC

228
00:07:29,360 --> 00:07:30,600
另外还有 Data Type

229
00:07:30,600 --> 00:07:32,080
Data Type 就默认了

230
00:07:32,080 --> 00:07:34,160
你是使用 Fp32,Fp16

231
00:07:34,160 --> 00:07:35,200
还是 Int8

232
00:07:35,560 --> 00:07:37,760
通过这么简单的一个 FBS

233
00:07:37,760 --> 00:07:39,080
就 FlatBuffer 的定义

234
00:07:39,320 --> 00:07:42,640
就完成了整个对张量的定义了

235
00:07:44,160 --> 00:07:46,040
下面就来看一看

236
00:07:46,040 --> 00:07:48,080
推理引擎里面对算子的定义

237
00:07:48,240 --> 00:07:48,920
算子定义

238
00:07:49,040 --> 00:07:51,440
同样去看看具体的代码

239
00:07:53,160 --> 00:07:55,560
算子的定义可能跟张量不太一样

240
00:07:55,560 --> 00:07:56,960
因为要对接到

241
00:07:56,960 --> 00:07:59,000
很多不同的 AI 框架里面

242
00:07:59,000 --> 00:08:00,200
同一个算子

243
00:08:00,200 --> 00:08:01,280
Pytorch 的定义

244
00:08:01,280 --> 00:08:03,240
可能和 TensorFlow 的定义不太一样

245
00:08:03,240 --> 00:08:05,080
也有可能跟 MindSpore

246
00:08:05,080 --> 00:08:07,200
三个 AI 框架的定义都不太一样

247
00:08:07,720 --> 00:08:09,120
所以在推理引擎里面

248
00:08:09,280 --> 00:08:10,400
对于每一个算子

249
00:08:10,560 --> 00:08:12,160
都需要有一个独立的定义

250
00:08:12,160 --> 00:08:13,600
于是用 table

251
00:08:13,600 --> 00:08:14,480
卷积 2D

252
00:08:14,480 --> 00:08:16,000
然后把一些最基本

253
00:08:16,000 --> 00:08:18,440
Padding, Kernel, Stride, Dialation

254
00:08:18,440 --> 00:08:19,680
Padmore, Group

255
00:08:19,680 --> 00:08:21,520
还有 Pad 的一些方式

256
00:08:21,520 --> 00:08:23,360
把它定义出来

257
00:08:23,680 --> 00:08:25,520
具体就通过工程性的代码

258
00:08:25,520 --> 00:08:27,080
或者 Converted 模块

259
00:08:27,080 --> 00:08:29,200
把不同的 AI 框架的一些参数

260
00:08:29,320 --> 00:08:31,600
对应到自己的一个定义里面

261
00:08:31,600 --> 00:08:33,240
有了具体的算子

262
00:08:33,400 --> 00:08:34,920
可能这算子有非常多

263
00:08:35,920 --> 00:08:37,760
然后需要告诉推理引擎

264
00:08:37,760 --> 00:08:39,280
现在支持哪些算子

265
00:08:39,280 --> 00:08:40,800
于是有个 OpType

266
00:08:40,800 --> 00:08:42,080
有个算子的列表

267
00:08:42,080 --> 00:08:44,120
有 Constant, Concat,卷积

268
00:08:44,120 --> 00:08:46,320
Deconvolution, 反卷积, Matmul

269
00:08:46,320 --> 00:08:48,080
有非常多的算子

270
00:08:48,080 --> 00:08:49,400
但是这些算子

271
00:08:49,520 --> 00:08:50,480
其实我建议

272
00:08:50,600 --> 00:08:52,960
一般控制在 200 到 300 个之间

273
00:08:52,960 --> 00:08:55,240
基本上能够覆盖 95%的场景

274
00:08:55,800 --> 00:08:57,240
像 Pytorch 里面

275
00:08:57,360 --> 00:08:58,920
就有 1200 多个算子

276
00:08:58,920 --> 00:09:01,080
TensorFlow 里面就有 1500 多个算子

277
00:09:01,080 --> 00:09:02,760
其实很多时候在推理引擎

278
00:09:02,840 --> 00:09:04,480
真的没有必要塞那么多算子

279
00:09:04,920 --> 00:09:06,480
一个算子具体实现的时候

280
00:09:06,560 --> 00:09:08,080
就可能有好几个 Kernel

281
00:09:08,640 --> 00:09:09,560
这会非常影响

282
00:09:09,560 --> 00:09:11,520
整个推理引擎的大小

283
00:09:11,520 --> 00:09:13,440
推理引擎要真正部署在端测

284
00:09:13,600 --> 00:09:14,760
肯定是越小越好

285
00:09:14,800 --> 00:09:17,880
接着会有一些算子的公共的属性

286
00:09:17,880 --> 00:09:19,480
例如 axis, shape, size

287
00:09:19,840 --> 00:09:22,160
还有一些 while, if, else

288
00:09:22,240 --> 00:09:23,440
特殊含义的算子

289
00:09:23,440 --> 00:09:26,280
或者特殊含义的一些属性参数

290
00:09:26,680 --> 00:09:29,360
下面这个才是算子真正的定义

291
00:09:29,360 --> 00:09:30,120
算子的定义

292
00:09:30,240 --> 00:09:32,280
就需要告诉这个算子

293
00:09:32,360 --> 00:09:33,840
它有多少个输入

294
00:09:33,880 --> 00:09:35,320
有多少个输出

295
00:09:35,440 --> 00:09:38,800
这里面的 main 是属于哪个公共的属性

296
00:09:38,800 --> 00:09:42,200
另外它的 type 是属于哪一个算子

297
00:09:42,200 --> 00:09:45,200
那 optype 就可以在这里面去找到

298
00:09:45,200 --> 00:09:49,000
通过这种方式去声明整个算子的定义

299
00:09:51,200 --> 00:09:53,800
回到 PPT 里面

300
00:09:54,000 --> 00:09:56,000
接下来有一个很重要的内容

301
00:09:56,000 --> 00:09:59,000
就是计算图的表示

302
00:09:59,000 --> 00:10:01,760
刚才说计算图主要是由

303
00:10:01,760 --> 00:10:03,400
算子跟张量来组成

304
00:10:03,800 --> 00:10:05,680
但是图这个概念还是要有

305
00:10:05,680 --> 00:10:07,080
你不能把它拆开

306
00:10:07,080 --> 00:10:08,320
里面具体的内容

307
00:10:08,320 --> 00:10:10,760
现在来看看它的图的定义

308
00:10:10,760 --> 00:10:12,480
那图其实有两个

309
00:10:12,480 --> 00:10:14,480
一个是定义网络模型的子图

310
00:10:14,480 --> 00:10:16,840
一个是定义整个网络模型

311
00:10:18,160 --> 00:10:20,000
像一些分类的网络模型

312
00:10:20,120 --> 00:10:21,880
确实有一个网络模型

313
00:10:21,880 --> 00:10:22,840
一个 net 就好了

314
00:10:22,840 --> 00:10:23,920
就没有子图

315
00:10:24,040 --> 00:10:25,400
但是在具体工程

316
00:10:25,400 --> 00:10:26,920
或者具体实现的过程当中

317
00:10:27,040 --> 00:10:28,480
遇到 if, else, while, for

318
00:10:28,480 --> 00:10:30,920
或者这些就会拆开成为子图

319
00:10:30,960 --> 00:10:33,280
这个也是在之前的计算图概念

320
00:10:33,400 --> 00:10:34,680
去给大家普及过

321
00:10:34,680 --> 00:10:36,560
看一下模型怎么定义

322
00:10:36,720 --> 00:10:37,640
这里面有个 net

323
00:10:37,640 --> 00:10:38,440
在存储的时候

324
00:10:38,560 --> 00:10:39,560
就需要去定义

325
00:10:39,560 --> 00:10:41,560
这个网络模型叫什么名字

326
00:10:41,560 --> 00:10:43,280
它的输入的 tensor 的名字

327
00:10:43,280 --> 00:10:44,920
它的 output tensor 的名字

328
00:10:45,200 --> 00:10:47,120
方便去做一个代码的控制

329
00:10:47,120 --> 00:10:48,280
另外还需要告诉

330
00:10:48,280 --> 00:10:51,040
这个网络模型有哪些算子

331
00:10:51,560 --> 00:10:53,160
这个算子的列表是一个 list

332
00:10:53,160 --> 00:10:54,360
这个 list 就告诉

333
00:10:54,360 --> 00:10:56,680
应该先执行哪一个算子

334
00:10:56,680 --> 00:10:58,080
后执行哪一个算子

335
00:10:58,080 --> 00:11:00,040
算子跟算子之间的一个关系

336
00:11:00,200 --> 00:11:02,080
就是通过刚才定义

337
00:11:02,080 --> 00:11:03,960
根据 input index 跟 output index

338
00:11:03,960 --> 00:11:06,000
去检索相关的边

339
00:11:06,200 --> 00:11:07,760
最后就有一个 subgraph

340
00:11:07,760 --> 00:11:08,960
有没有子图

341
00:11:08,960 --> 00:11:09,840
有子图的话

342
00:11:09,840 --> 00:11:11,920
就去调用下面一个子图了

343
00:11:11,920 --> 00:11:13,200
像遇到 if, else 这种

344
00:11:13,360 --> 00:11:15,640
确实它就会产生不同的子图

345
00:11:15,840 --> 00:11:17,160
子图也有自己的名字

346
00:11:17,160 --> 00:11:18,960
也有自己的输入输出

347
00:11:18,960 --> 00:11:20,720
当然了还有一个 node 的 op

348
00:11:20,840 --> 00:11:21,520
就 op list

349
00:11:21,960 --> 00:11:24,320
其实跟上面的网络模型的定义差不多

350
00:11:24,320 --> 00:11:26,000
它只是一个简单的子图

351
00:11:26,000 --> 00:11:28,200
可能信息会比整个大图

352
00:11:28,360 --> 00:11:29,960
会稍微少一点

353
00:11:30,080 --> 00:11:31,280
没有那么多用意的信息

354
00:11:31,280 --> 00:11:33,200
当然了这里面有很多点点点

355
00:11:33,200 --> 00:11:34,120
就告诉大家

356
00:11:34,120 --> 00:11:35,480
其实这里面还可以塞很多

357
00:11:35,480 --> 00:11:37,280
不同的相关的信息

358
00:11:38,840 --> 00:11:41,000
了解完怎么通过 flat buffer

359
00:11:41,000 --> 00:11:42,000
或者 protobuffer

360
00:11:42,000 --> 00:11:43,840
去自定义一个计算图之后

361
00:11:44,000 --> 00:11:45,640
现在来回头

362
00:11:45,640 --> 00:11:47,720
来看看整体的流程

363
00:11:47,720 --> 00:11:48,400
整体流程

364
00:11:48,520 --> 00:11:51,800
首先需要构建一个计算图的 IR

365
00:11:52,240 --> 00:11:54,040
刚才我就已经以伪代码

366
00:11:54,040 --> 00:11:55,240
带着大家去构建

367
00:11:55,240 --> 00:11:56,960
自己的一个计算图的 IR

368
00:11:56,960 --> 00:11:58,120
这个更重要的是

369
00:11:58,120 --> 00:11:59,920
需要结合自己的一个推进引擎

370
00:11:59,920 --> 00:12:00,560
特殊性

371
00:12:00,560 --> 00:12:02,480
还有竞争力去构建

372
00:12:02,760 --> 00:12:04,400
第二步确实是

373
00:12:04,400 --> 00:12:06,200
更多的是工程化的工作了

374
00:12:06,200 --> 00:12:08,280
去解析训练模型

375
00:12:08,280 --> 00:12:09,280
就 AI 框架

376
00:12:09,280 --> 00:12:10,240
不同的框架

377
00:12:10,240 --> 00:12:12,080
导出来的模型

378
00:12:12,520 --> 00:12:16,240
第三步就是生成自定义的计算图

379
00:12:16,240 --> 00:12:18,120
这里面就是通过 flat buffer

380
00:12:18,120 --> 00:12:19,360
或者 protobuffer 的 API

381
00:12:19,760 --> 00:12:22,120
来去对接到对应的计算图

382
00:12:22,360 --> 00:12:24,640
看一下右边的这两个图

383
00:12:24,640 --> 00:12:25,680
右边的这个图

384
00:12:25,680 --> 00:12:27,320
你大家可以看到非常的长

385
00:12:27,360 --> 00:12:29,640
就是我用刚才定义的一个伪代码

386
00:12:29,840 --> 00:12:32,840
然后写了一个 ResNet50 的网络模型

387
00:12:32,840 --> 00:12:36,520
右边的这个就是其中一小段的展开

388
00:12:37,960 --> 00:12:38,760
卷的不行了

389
00:12:38,760 --> 00:12:39,560
卷的不行了

390
00:12:39,560 --> 00:12:41,040
记得一键三连加关注

391
00:12:41,400 --> 00:12:44,520
所有的内容都会开源在下面这条链接里面

392
00:12:45,046 --> 00:12:45,880
拜了个拜

