1
00:00:00,000 --> 00:00:05,900
字幕生成：mkwei 字幕校对：qiaokai

2
00:00:06,150 --> 00:00:06,920
Hello大家好

3
00:00:06,920 --> 00:00:07,920
我是ZOMI

4
00:00:07,920 --> 00:00:10,800
今天我来给大家分享一个新的内容

5
00:00:10,800 --> 00:00:13,680
就是ChatGPT狂飙原理剖析

6
00:00:13,680 --> 00:00:17,440
深入的去看看ChatGPT里面的核心的原理

7
00:00:17,440 --> 00:00:20,360
其实ChatGPT就不用我说它是什么

8
00:00:20,360 --> 00:00:21,520
最近发生了什么

9
00:00:21,520 --> 00:00:23,960
确实已经火遍大江南北了

10
00:00:23,960 --> 00:00:26,120
然后我今天要分享的一个内容

11
00:00:26,320 --> 00:00:29,920
主要是看一下ChatGPT里面的一些核心的

12
00:00:29,920 --> 00:00:30,560
技术点

13
00:00:30,560 --> 00:00:34,080
那首先会分开4个内容去给大家介绍的

14
00:00:34,080 --> 00:00:36,720
主要可能我后面会分开三个视频

15
00:00:36,720 --> 00:00:38,320
那第一个视频去看一看

16
00:00:38,320 --> 00:00:38,920
bert模型

17
00:00:38,920 --> 00:00:41,560
还有GPT这个模型的系列

18
00:00:41,560 --> 00:00:43,600
这个系列到底发生了什么

19
00:00:43,600 --> 00:00:46,120
接着我们在后面第2个内容里面

20
00:00:46,120 --> 00:00:48,360
去看看强化学习里面

21
00:00:48,360 --> 00:00:50,400
怎么去引入了人类的反馈

22
00:00:50,400 --> 00:00:51,360
就Reinforcement

23
00:00:51,360 --> 00:00:53,615
Human Feedback这种模式

24
00:00:53,615 --> 00:00:53,640
那这种模式又加入了PPO的算法

25
00:00:53,640 --> 00:00:56,775
那这种模式又加入了PPO的算法

26
00:00:57,920 --> 00:00:59,320
在第3个内容里面

27
00:00:59,560 --> 00:01:02,200
我们就会去深入的来到InstructGPT的

28
00:01:02,200 --> 00:01:04,680
一个原理的深度剖析

29
00:01:04,680 --> 00:01:08,080
其实InstructGPT就是ChatGPT的一个原生

30
00:01:08,080 --> 00:01:10,640
当然了ChatGPT现在的论文没有公布

31
00:01:10,640 --> 00:01:13,000
但是InstructGPT是现在为止

32
00:01:13,000 --> 00:01:16,600
跟ChatGPT的算法原理是最接近的

33
00:01:17,240 --> 00:01:19,240
下面我们来到第1个内容

34
00:01:19,240 --> 00:01:24,400
从GPT12到GPT-3里面的一个技术的过渡

35
00:01:24,400 --> 00:01:25,680
或者技术的变化

36
00:01:25,680 --> 00:01:28,440
那ChatGPT12大部分都是用微调的

37
00:01:28,440 --> 00:01:29,240
这种方式

38
00:01:29,400 --> 00:01:33,680
到GPT-3就引入了一个prompt learning的方式

39
00:01:33,760 --> 00:01:36,400
下面我们来看看具体的内容

40
00:01:36,400 --> 00:01:38,280
像在GPT系列里面

41
00:01:38,480 --> 00:01:40,360
我们已经经历了三代

42
00:01:40,360 --> 00:01:43,040
GPT1了2了3了三代

43
00:01:43,040 --> 00:01:46,040
其实三代都是以Transformer为核心

44
00:01:46,040 --> 00:01:47,840
去构造网络模型

45
00:01:47,840 --> 00:01:50,440
不同的就在于他们的一个模型层

46
00:01:50,440 --> 00:01:52,040
还有词向量的长度 

47
00:01:52,280 --> 00:01:54,640
最大的不同就是学习的方式

48
00:01:54,640 --> 00:01:57,000
learning的方式不太一样

49
00:01:57,000 --> 00:02:00,360
下面就是我汇总的一个简单的小表格

50
00:02:00,360 --> 00:02:02,200
可以看到OpenAI

51
00:02:02,200 --> 00:02:05,600
主导了GPT123整个系列

52
00:02:05,600 --> 00:02:08,000
从18年19年20年

53
00:02:08,000 --> 00:02:09,600
到现在的23年

54
00:02:09,600 --> 00:02:10,800
ChatGPT出来

55
00:02:10,800 --> 00:02:13,360
确实我们的网络模型的参数量

56
00:02:13,360 --> 00:02:14,800
进一步的提升

57
00:02:14,800 --> 00:02:16,280
而且网络模型的参数量

58
00:02:16,680 --> 00:02:19,360
到了现在的1000多亿的规模

59
00:02:19,360 --> 00:02:22,080
基本上我们在生态里面要训起来

60
00:02:22,080 --> 00:02:24,840
一个ChatGPT或者一个GPT-3

61
00:02:24,880 --> 00:02:28,080
可能要消耗好多的集群的资源

62
00:02:28,640 --> 00:02:31,320
下面我们来看一下GPT-1

63
00:02:31,320 --> 00:02:35,080
GPT-1它主要是基于Transformer的decoder


64
00:02:35,080 --> 00:02:37,520
再加上微调的这种方式

65
00:02:37,720 --> 00:02:39,760
既然是decoder跟微调

66
00:02:39,760 --> 00:02:42,400
它就分开了两个阶段

67
00:02:42,600 --> 00:02:45,760
第一个阶段就是预训练的阶段

68
00:02:45,760 --> 00:02:48,240
利用语言模型进行一个预训练

69
00:02:48,240 --> 00:02:49,320
预学习

70
00:02:49,320 --> 00:02:52,640
接着到第二阶段就需要进行微调

71
00:02:52,680 --> 00:02:55,000
微调就是针对我们的下游任务

72
00:02:55,000 --> 00:02:56,800
或者下游的一些数据

73
00:02:56,800 --> 00:02:58,200
进行fine tuning

74
00:02:58,200 --> 00:02:59,120
fine tuning的工作

75
00:02:59,240 --> 00:03:01,440
就会可能加几层layer层

76
00:03:01,440 --> 00:03:03,360
或者加几层其他head

77
00:03:03,360 --> 00:03:04,880
然后进行一个微调的

78
00:03:04,880 --> 00:03:05,640
微调的工作

79
00:03:05,840 --> 00:03:08,120
确实会带来一些新的入参

80
00:03:08,120 --> 00:03:09,600
新的模型层

81
00:03:10,150 --> 00:03:11,040
哎

82
00:03:11,040 --> 00:03:12,360
ZOMI老师你好

83
00:03:12,360 --> 00:03:14,880
像这种预训练加微调的方式

84
00:03:14,880 --> 00:03:16,840
跟Bert非常类似

85
00:03:17,135 --> 00:03:20,080
那它跟Bert有什么区别吗 

86
00:03:20,080 --> 00:03:23,240
小新的问题问得非常及时

87
00:03:23,240 --> 00:03:25,440
我们先来看一看这个图

88
00:03:25,440 --> 00:03:27,600
这个图就是GPT-1

89
00:03:27,600 --> 00:03:29,680
就GPT-1里面的一个图

90
00:03:29,680 --> 00:03:32,760
左边的就是Transformer的一个结构

91
00:03:32,760 --> 00:03:34,240
用了Transformer的结构之后

92
00:03:34,400 --> 00:03:36,360
针对不同的下游任务

93
00:03:36,520 --> 00:03:38,520
右边就列了4个下游任务

94
00:03:38,520 --> 00:03:39,120
4个下游任务

95
00:03:39,120 --> 00:03:40,560
输了不同的数据之后

96
00:03:40,760 --> 00:03:42,360
通过不同的堆叠方式

97
00:03:42,360 --> 00:03:45,800
然后去组成新的下游任务处理方式

98
00:03:46,400 --> 00:03:47,920
GPT-1的这种方式

99
00:03:48,080 --> 00:03:50,280
确实跟Bert非常类似

100
00:03:50,280 --> 00:03:51,960
但是我们看下面两个图

101
00:03:51,960 --> 00:03:53,280
有个最大的区别

102
00:03:53,280 --> 00:03:54,920
我们可以看到左边的图

103
00:03:55,240 --> 00:03:56,560
就是谷歌的Bert

104
00:03:56,560 --> 00:03:58,200
它一个架构的图

105
00:03:58,200 --> 00:04:01,480
右边就是OpenAI的一个GPT的图

106
00:04:01,480 --> 00:04:03,080
我们从下面来看

107
00:04:03,080 --> 00:04:04,920
基本上的层数都是一样的

108
00:04:04,920 --> 00:04:06,600
通过我们的磁相量

109
00:04:06,880 --> 00:04:08,440
传进去变成embedding

110
00:04:08,440 --> 00:04:10,600
然后给我们的Transformer的层

111
00:04:10,600 --> 00:04:11,280
Transformer层

112
00:04:11,400 --> 00:04:13,320
最后输出的是一些token

113
00:04:13,880 --> 00:04:15,600
我们看到最大的区别

114
00:04:16,120 --> 00:04:17,000
像这里面

115
00:04:17,000 --> 00:04:19,680
这个E2就是我们第二个embedding层

116
00:04:19,680 --> 00:04:21,880
它会向左边有一个箭头

117
00:04:21,880 --> 00:04:23,440
像embedding最后一层

118
00:04:23,440 --> 00:04:26,120
向左边也有一个箭头

119
00:04:26,160 --> 00:04:29,200
但是反观OpenAI的GPT

120
00:04:29,440 --> 00:04:32,160
它基本上只会向右边的箭头

121
00:04:32,160 --> 00:04:34,160
它没有左边的箭头

122
00:04:34,640 --> 00:04:36,480
两者之间最大的区别

123
00:04:36,480 --> 00:04:39,080
就是对任务的处理不太一样

124
00:04:39,080 --> 00:04:41,760
我们看看左边的一个输入的例子

125
00:04:41,840 --> 00:04:44,080
假设现在我们有一个

126
00:04:44,080 --> 00:04:45,200
或者我们有一句话

127
00:04:45,200 --> 00:04:47,160
ZOMI经常更新什么

128
00:04:47,160 --> 00:04:48,080
在大晚上

129
00:04:48,240 --> 00:04:50,880
这个时候我要预测中间的一个词

130
00:04:50,880 --> 00:04:52,760
可能这里面做了个musk

131
00:04:52,760 --> 00:04:54,280
ZOMI经常更新视频

132
00:04:54,280 --> 00:04:55,080
在大晚上

133
00:04:55,080 --> 00:04:56,400
中间这个musk的词

134
00:04:56,680 --> 00:04:58,760
是嵌在我左边跟右边

135
00:04:59,000 --> 00:05:01,200
假设我要预测中间的词

136
00:05:01,200 --> 00:05:02,720
我可能会根据左边

137
00:05:02,720 --> 00:05:03,760
根据我前面

138
00:05:03,760 --> 00:05:04,720
根据我后面

139
00:05:04,720 --> 00:05:05,960
根据我上下文

140
00:05:05,960 --> 00:05:07,480
去做一个预测的

141
00:05:07,520 --> 00:05:10,280
但是像GPT这种方式

142
00:05:10,560 --> 00:05:12,360
就是ZOMI经常在大晚上

143
00:05:12,360 --> 00:05:13,280
更新什么

144
00:05:13,720 --> 00:05:14,360
什么

145
00:05:14,560 --> 00:05:15,200
我们这时候

146
00:05:15,470 --> 00:05:18,320
基本上我只会根据前文的信息

147
00:05:18,320 --> 00:05:20,920
去预测下一个单词是什么

148
00:05:20,920 --> 00:05:23,160
这种只是做一个简单的

149
00:05:23,160 --> 00:05:24,320
后向的预测

150
00:05:24,320 --> 00:05:25,000
或者预测

151
00:05:25,000 --> 00:05:26,840
我接下来要发生什么

152
00:05:26,960 --> 00:05:28,680
所以他们最大的区别

153
00:05:28,680 --> 00:05:31,080
就是语言任务上的区别

154
00:05:31,080 --> 00:05:32,760
那我们可以看一下

155
00:05:32,760 --> 00:05:34,240
一个简单的总结

156
00:05:34,240 --> 00:05:35,320
像GPT-1

157
00:05:35,600 --> 00:05:38,400
它虽然也是以语言模型作为目标

158
00:05:38,400 --> 00:05:40,880
但采用的是单向的语言模型

159
00:05:40,880 --> 00:05:42,160
注意是单向

160
00:05:42,160 --> 00:05:43,040
像BERT那种

161
00:05:43,200 --> 00:05:46,360
确实是双向的语言模型

162
00:05:46,720 --> 00:05:47,920
在网络结构方面

163
00:05:48,080 --> 00:05:49,000
BERT网络模型

164
00:05:49,160 --> 00:05:50,600
更多的是采用了

165
00:05:50,600 --> 00:05:53,160
像Transformer encoder的部分

166
00:05:53,160 --> 00:05:55,600
而GPT更多的是采用了 

167
00:05:55,600 --> 00:05:59,840
类似于Transformer decoder的部分

168
00:06:00,000 --> 00:06:01,360
我们可以看到下面这个图

169
00:06:01,600 --> 00:06:04,520
就是GDP-1里面的一个简单的图

170
00:06:04,520 --> 00:06:05,920
里面主要是用了

171
00:06:05,920 --> 00:06:08,160
Transformer decoder的模块

172
00:06:08,360 --> 00:06:08,920
简单的

173
00:06:08,920 --> 00:06:11,760
我们从单个网络模型的结构来看

174
00:06:11,760 --> 00:06:13,440
最大最明显的区别

175
00:06:13,440 --> 00:06:14,520
就是像BERT

176
00:06:14,840 --> 00:06:16,680
会采用multi-head attention

177
00:06:16,840 --> 00:06:20,320
像GDP会采用max multi-head attention

178
00:06:20,320 --> 00:06:21,280
这种方式

179
00:06:21,640 --> 00:06:22,520
总结来说

180
00:06:22,600 --> 00:06:23,880
我们从三个维度

181
00:06:23,880 --> 00:06:25,160
去看他们的区别

182
00:06:25,160 --> 00:06:26,520
第一个是语言模型

183
00:06:26,520 --> 00:06:27,360
到底是单向的

184
00:06:27,360 --> 00:06:28,400
还是双向的

185
00:06:28,480 --> 00:06:30,480
第二个我们采用了Transformer

186
00:06:30,480 --> 00:06:31,520
哪个部分

187
00:06:31,520 --> 00:06:32,760
然后去组成的

188
00:06:32,760 --> 00:06:36,040
第三个在某一个具体的结构上面

189
00:06:36,040 --> 00:06:37,640
它到底是multi-head attention

190
00:06:37,640 --> 00:06:40,160
还是max multi-head attention

191
00:06:40,160 --> 00:06:41,000
三种

192
00:06:42,240 --> 00:06:43,440
下面我们来看看

193
00:06:43,440 --> 00:06:45,720
什么是max multi-head attention

194
00:06:45,960 --> 00:06:46,640
multi-head attention

195
00:06:46,760 --> 00:06:48,520
我就不再多说了

196
00:06:48,520 --> 00:06:49,400
因为在Transformer

197
00:06:49,400 --> 00:06:50,920
还有BERT这些网络模型里面的

198
00:06:50,920 --> 00:06:51,400
大量的

199
00:06:51,400 --> 00:06:53,360
已经做了非常多的例子

200
00:06:53,360 --> 00:06:54,920
网上你搜也很多

201
00:06:54,920 --> 00:06:56,720
我们来看看GPT-1里面的

202
00:06:56,720 --> 00:06:58,040
max multi-head attention

203
00:06:58,040 --> 00:06:59,320
最主要的通俗理解

204
00:06:59,320 --> 00:07:00,960
就是在处理当前词的时候

205
00:07:00,960 --> 00:07:02,360
看不到后面的词

206
00:07:02,360 --> 00:07:03,760
假设我在处理一的时候

207
00:07:03,920 --> 00:07:05,520
我是看不到后面的词

208
00:07:05,520 --> 00:07:07,560
但是我会看到前面的单词

209
00:07:07,560 --> 00:07:08,320
a和o

210
00:07:08,320 --> 00:07:09,520
这种就是单向

211
00:07:09,520 --> 00:07:11,280
我去看a和o的时候

212
00:07:11,400 --> 00:07:13,320
就去预测跟it之间的

213
00:07:13,320 --> 00:07:14,240
一个attention

214
00:07:14,240 --> 00:07:15,320
还有它的分数

215
00:07:15,320 --> 00:07:17,520
还有它之间的关联关系

216
00:07:17,520 --> 00:07:19,480
然后去算qkb的词

217
00:07:19,480 --> 00:07:21,840
这个就是max multi-head attention

218
00:07:21,840 --> 00:07:23,560
一个简单的例子

219
00:07:24,080 --> 00:07:27,480
现在我们来到GDP-2

220
00:07:27,480 --> 00:07:29,040
这个模型里面

221
00:07:29,360 --> 00:07:31,240
GDP-2跟GDP-1

222
00:07:31,240 --> 00:07:32,120
最大的区别

223
00:07:32,520 --> 00:07:34,360
就是我们的标题

224
00:07:34,360 --> 00:07:36,200
没有了微调的任务

225
00:07:36,200 --> 00:07:37,440
直接使用了

226
00:07:37,440 --> 00:07:39,240
zero shot learning

227
00:07:39,640 --> 00:07:41,040
谈到zero shot learning

228
00:07:41,360 --> 00:07:43,000
就是我们的小样本学习

229
00:07:43,360 --> 00:07:45,200
我们来看看小样本学习

230
00:07:45,200 --> 00:07:46,920
具体分为哪几种

231
00:07:47,120 --> 00:07:48,240
现在小样本学习

232
00:07:48,440 --> 00:07:51,480
其实最主要的是下面三种模式

233
00:07:51,480 --> 00:07:53,080
第一种就是zero shot

234
00:07:53,080 --> 00:07:54,800
就是零样本的学习

235
00:07:54,800 --> 00:07:56,200
针对具体的项目任务

236
00:07:56,360 --> 00:07:58,760
就不需要进行一个微调了

237
00:07:58,760 --> 00:07:59,880
像one shot learning

238
00:08:00,000 --> 00:08:01,360
就是单样本学习

239
00:08:01,360 --> 00:08:03,160
可能我有小量的样本

240
00:08:03,160 --> 00:08:05,240
进行一个简单的微调

241
00:08:05,240 --> 00:08:07,560
然后去预测更多的任务

242
00:08:07,880 --> 00:08:08,840
那few shot learning

243
00:08:09,080 --> 00:08:10,840
更多的就是少量的样本

244
00:08:10,840 --> 00:08:12,000
进行学习

245
00:08:12,000 --> 00:08:13,560
进行一个简单的微调

246
00:08:13,560 --> 00:08:15,280
完成特殊的任务

247
00:08:15,440 --> 00:08:16,800
最主要的ChatGPT2

248
00:08:17,000 --> 00:08:19,200
就是使用了Few shot learning

249
00:08:19,200 --> 00:08:21,440
这种学习的方式

250
00:08:22,080 --> 00:08:24,400
除了刚才我们提到的GPT-2

251
00:08:24,640 --> 00:08:26,680
采用了一种Zero shot learning的方式

252
00:08:26,680 --> 00:08:27,920
其实最大的区别

253
00:08:27,920 --> 00:08:30,240
就是因为我引用了Zero shot learning

254
00:08:30,240 --> 00:08:31,800
我需要更多的参数

255
00:08:31,800 --> 00:08:33,200
更大的网络模型

256
00:08:33,240 --> 00:08:35,240
记录我们数据的特征

257
00:08:35,440 --> 00:08:36,840
这个时候最有效的办法

258
00:08:36,840 --> 00:08:39,200
就是增大我们的网络模型

259
00:08:39,200 --> 00:08:41,080
还用更大的数据集

260
00:08:41,120 --> 00:08:42,560
从下面这个图可以看到

261
00:08:42,560 --> 00:08:43,920
其实GPT-2

262
00:08:44,680 --> 00:08:45,320
网络模型

263
00:08:45,320 --> 00:08:49,240
提供了4种不同的模型的结构

264
00:08:49,400 --> 00:08:50,160
不同模型结构

265
00:08:50,280 --> 00:08:51,600
更多的是通过decoder

266
00:08:51,600 --> 00:08:53,480
来不断的去堆叠

267
00:08:53,480 --> 00:08:55,440
所以简单的对比GPT-2

268
00:08:55,440 --> 00:08:56,360
还有GPT-1

269
00:08:56,360 --> 00:08:57,600
可以看到GPT-2

270
00:08:58,040 --> 00:08:59,560
拾弃了微调的方式

271
00:08:59,560 --> 00:09:01,160
使用了Zero shot learning

272
00:09:01,160 --> 00:09:03,880
因此引入了更大的网络模型

273
00:09:03,880 --> 00:09:05,920
还有更大的数据集

274
00:09:07,040 --> 00:09:09,840
下面我们来到第三个内容

275
00:09:09,840 --> 00:09:12,440
就是GPT-3了

276
00:09:12,560 --> 00:09:13,360
GPT-3

277
00:09:13,600 --> 00:09:16,400
作为一个非常划时代的一个模型

278
00:09:16,400 --> 00:09:18,040
我们看一看GDP-3

279
00:09:18,040 --> 00:09:20,880
主要是开启了NLP的新方式

280
00:09:20,880 --> 00:09:21,600
Prompt learning

281
00:09:21,600 --> 00:09:23,800
实现了小样本的学习

282
00:09:23,800 --> 00:09:25,080
把我们的zero shot

283
00:09:25,080 --> 00:09:27,440
精度进一步的提升

284
00:09:27,640 --> 00:09:29,040
其实在一开始

285
00:09:29,160 --> 00:09:30,640
像Prompt tuning这种动机

286
00:09:30,800 --> 00:09:31,520
主要是解决

287
00:09:31,520 --> 00:09:33,800
目前fine tuning的两个痛点

288
00:09:34,000 --> 00:09:36,960
第一个就是降低语义的差别

289
00:09:36,960 --> 00:09:37,800
降低语义的差别

290
00:09:37,800 --> 00:09:40,440
其实下面这句话有点冗余

291
00:09:40,440 --> 00:09:41,240
很好理解

292
00:09:41,240 --> 00:09:42,440
我们的预训练模型

293
00:09:42,440 --> 00:09:43,440
跟我们的下游任务

294
00:09:43,440 --> 00:09:45,680
其实有一个比较大的区别的

295
00:09:45,680 --> 00:09:46,920
需要引入新的参数

296
00:09:46,920 --> 00:09:48,560
或者新的网络的模型层

297
00:09:48,560 --> 00:09:49,680
针对不同的下游任务

298
00:09:49,840 --> 00:09:51,240
可能需要重新调参

299
00:09:51,240 --> 00:09:52,480
进行一个训练

300
00:09:52,680 --> 00:09:53,320
这个时候

301
00:09:53,640 --> 00:09:55,200
我们的预训练模型跟下游任务

302
00:09:55,200 --> 00:09:56,960
其实脱节还是比较严重的

303
00:09:56,960 --> 00:09:59,160
就像现在的CV一样

304
00:09:59,160 --> 00:10:00,920
为什么CV没有那么多大模型

305
00:10:00,920 --> 00:10:02,040
就是因为他们现在

306
00:10:02,080 --> 00:10:03,400
还没有一个很好的

307
00:10:03,400 --> 00:10:04,640
统一的范式

308
00:10:04,640 --> 00:10:05,040
当然了

309
00:10:05,040 --> 00:10:06,200
现在慢慢的出现了

310
00:10:06,200 --> 00:10:07,840
不能说完全没有

311
00:10:07,840 --> 00:10:09,440
那我们回到正题

312
00:10:09,440 --> 00:10:13,200
第二个就是避免过拟和over fitting

313
00:10:13,200 --> 00:10:14,080
这个工作

314
00:10:14,080 --> 00:10:15,960
因为我们在fine tuning的阶段

315
00:10:15,960 --> 00:10:17,800
会引入新的一些参数

316
00:10:17,800 --> 00:10:18,680
会重新训练

317
00:10:18,680 --> 00:10:20,320
这个时候对我们的预训的模型

318
00:10:20,440 --> 00:10:23,160
就有可能会造成过拟和的问题了

319
00:10:24,400 --> 00:10:26,120
GPT-3针对这两个问题

320
00:10:26,640 --> 00:10:29,280
提出了新的Prompt一种范式

321
00:10:29,280 --> 00:10:31,320
那Prompt它一开始其实不叫Prompt

322
00:10:31,320 --> 00:10:32,520
后来大家总结总结的

323
00:10:32,520 --> 00:10:33,640
或者弄着弄着

324
00:10:33,640 --> 00:10:36,160
就把它重新的命名为Prompt了

325
00:10:36,160 --> 00:10:37,600
我们看看PPT

326
00:10:37,760 --> 00:10:40,520
这个是一个新的模型里面的一张图

327
00:10:40,520 --> 00:10:41,640
我们可以看到最上面

328
00:10:41,760 --> 00:10:44,880
就是原始的一种预训练的方式

329
00:10:44,880 --> 00:10:45,640
通过Prompt tuning

330
00:10:45,800 --> 00:10:47,280
就是我有一句话

331
00:10:47,280 --> 00:10:49,160
去指引我下面的那句话

332
00:10:49,160 --> 00:10:50,320
到底预测是什么

333
00:10:50,320 --> 00:10:51,680
我每一次训练的时候

334
00:10:51,840 --> 00:10:53,360
都会塞一句Prompt tuning

335
00:10:53,360 --> 00:10:54,280
就是塞一句

336
00:10:54,280 --> 00:10:55,800
指示性的一个语言

337
00:10:55,800 --> 00:10:57,400
或者指示性的一个句子进去

338
00:10:57,400 --> 00:10:59,240
更好的对我们后面的数据

339
00:10:59,240 --> 00:11:00,400
进行一个预测

340
00:11:00,400 --> 00:11:01,440
或者训练

341
00:11:01,440 --> 00:11:02,520
那后面训练的时候

342
00:11:02,760 --> 00:11:04,760
就可能会把自己里面做一个mask

343
00:11:04,760 --> 00:11:05,800
比起一个mask

344
00:11:06,000 --> 00:11:07,240
预训练可能简单的

345
00:11:07,240 --> 00:11:08,080
只有后面

346
00:11:08,080 --> 00:11:10,840
那现在加了一句更好的句子

347
00:11:10,840 --> 00:11:12,600
或者更好的上下文

348
00:11:12,600 --> 00:11:14,720
对它进行一个指导

349
00:11:14,920 --> 00:11:16,560
那下面我们看看

350
00:11:16,560 --> 00:11:20,320
GPT-3的一个具体的GIF的图

351
00:11:20,320 --> 00:11:21,360
可以看到下面

352
00:11:21,560 --> 00:11:23,280
最上面就是我们的一些

353
00:11:23,280 --> 00:11:24,280
具体的数据

354
00:11:24,720 --> 00:11:26,000
这个就是我们的Prompt

355
00:11:26,000 --> 00:11:27,680
Prompt的一些语料

356
00:11:28,160 --> 00:11:29,720
可以看到最上面第一句话

357
00:11:29,840 --> 00:11:30,960
就是我们的Prompt语调

358
00:11:30,960 --> 00:11:32,160
Prompt语调输进来

359
00:11:32,160 --> 00:11:33,360
给我们的GDP-3之后

360
00:11:33,680 --> 00:11:35,640
我们就去对下面的句子

361
00:11:35,640 --> 00:11:37,240
进行一个预测

362
00:11:37,400 --> 00:11:39,720
可能每一次都是预测最后一句话

363
00:11:39,960 --> 00:11:41,440
或者最后一个单词

364
00:11:41,440 --> 00:11:44,120
然后下次再预测下一个单词

365
00:11:44,320 --> 00:11:46,800
这种方式就结合了GPT-2

366
00:11:46,800 --> 00:11:48,920
然后引用了Prompt learning

367
00:11:48,920 --> 00:11:49,800
这种方式

368
00:11:49,800 --> 00:11:52,960
完成了我们的GPT-1到GPT-3

369
00:11:52,960 --> 00:11:55,400
的一个整体的升级

370
00:11:55,680 --> 00:11:57,640
我们现在来总结一下

371
00:11:57,640 --> 00:11:58,960
整个GPT系列

372
00:11:59,160 --> 00:12:00,720
从一开始的fine tuning

373
00:12:00,720 --> 00:12:03,680
再到Prompt tuning这种工作

374
00:12:04,720 --> 00:12:07,480
简单的用一个图来概括一下

375
00:12:07,480 --> 00:12:08,840
我们可以看到下面这个图

376
00:12:09,000 --> 00:12:10,120
从GPT-1

377
00:12:10,120 --> 00:12:10,720
GPT-2

378
00:12:10,720 --> 00:12:11,440
GPT-3

379
00:12:11,440 --> 00:12:12,920
到InstructGPT

380
00:12:12,920 --> 00:12:14,680
到最后的ChatGPT

381
00:12:14,680 --> 00:12:16,000
它们最大的不同

382
00:12:16,000 --> 00:12:18,400
就是一开始从预训练到微调

383
00:12:18,400 --> 00:12:20,840
引入了预训练加Zero Shot

384
00:12:20,840 --> 00:12:22,520
最后到GPT-3的时候

385
00:12:22,680 --> 00:12:25,320
就引入了预训练加Prompt tuning

386
00:12:25,320 --> 00:12:27,200
而在InstructGPT的时候

387
00:12:27,360 --> 00:12:30,000
引入了一个新的学习的方式

388
00:12:30,000 --> 00:12:31,600
instruct learning

389
00:12:31,760 --> 00:12:32,880
下面我们来看看

390
00:12:32,880 --> 00:12:35,680
什么叫做instruct learning

391
00:12:35,680 --> 00:12:36,600
所以大家不要觉得

392
00:12:36,600 --> 00:12:38,400
我在重复讲GPT-3

393
00:12:38,400 --> 00:12:39,240
没有什么意义

394
00:12:39,240 --> 00:12:41,480
我们慢慢的引导下来

395
00:12:41,480 --> 00:12:42,840
像这种Prompt tuning

396
00:12:43,120 --> 00:12:44,000
或者Prompt learning

397
00:12:44,160 --> 00:12:46,160
我们叫做提示的学习

398
00:12:46,160 --> 00:12:47,640
而instruct learning

399
00:12:47,960 --> 00:12:50,160
我们叫做指示性的学习

400
00:12:50,280 --> 00:12:52,400
它们都有相同点和区别

401
00:12:52,600 --> 00:12:54,760
相同点都是想去挖掘

402
00:12:54,760 --> 00:12:55,960
我们的语言模型

403
00:12:56,000 --> 00:12:58,240
本身所具备的知识

404
00:12:58,440 --> 00:13:00,280
这句话其实是废话

405
00:13:01,600 --> 00:13:02,920
我们的目标都是相同的

406
00:13:02,920 --> 00:13:04,640
都是搞LLM大模型

407
00:13:04,640 --> 00:13:07,320
我们来看看区别点在哪

408
00:13:07,400 --> 00:13:08,600
像Prompt这种方式

409
00:13:08,760 --> 00:13:12,000
更多的是做一种补全的功能

410
00:13:12,040 --> 00:13:13,640
确实类似于补全

411
00:13:13,640 --> 00:13:14,880
根据上半句

412
00:13:15,000 --> 00:13:17,240
上半句就是Prompt的一种提示

413
00:13:17,240 --> 00:13:20,400
生成或者完成下半句的任务

414
00:13:20,400 --> 00:13:22,200
这种更像完形填空

415
00:13:22,200 --> 00:13:24,640
补全我们整体的语言语调

416
00:13:24,640 --> 00:13:25,920
的一种模型能力

417
00:13:26,360 --> 00:13:27,360
instruct的方式

418
00:13:27,560 --> 00:13:31,760
更多的是希望激发语言模型的理解能力

419
00:13:31,760 --> 00:13:34,160
我一开始给出一个明确的指示

420
00:13:34,160 --> 00:13:35,720
让模型去做一个

421
00:13:35,720 --> 00:13:37,680
对这个指示的一个认知

422
00:13:37,680 --> 00:13:38,680
或者理解

423
00:13:39,080 --> 00:13:41,000
说起来可能比较难理解

424
00:13:41,000 --> 00:13:42,960
我们还是来看看一个具体的

425
00:13:42,960 --> 00:13:44,200
或者可爱的例子

426
00:13:44,520 --> 00:13:47,120
第一个就是我们的提示学习

427
00:13:47,120 --> 00:13:48,160
我们的Prompt tunning

428
00:13:48,200 --> 00:13:50,080
假设我们现在有一句话

429
00:13:50,080 --> 00:13:51,880
他很喜欢这个项链

430
00:13:51,880 --> 00:13:53,200
太什么太好了

431
00:13:53,200 --> 00:13:54,160
太好看了

432
00:13:54,200 --> 00:13:55,880
这种就是对我们的语料

433
00:13:55,880 --> 00:13:57,000
进行一个完形填空

434
00:13:57,000 --> 00:13:58,080
或者补齐

435
00:13:58,440 --> 00:14:00,640
而此次学习更多的

436
00:14:00,640 --> 00:14:03,400
我们可以判断这句话的情感

437
00:14:03,400 --> 00:14:05,000
我给他买了个项链

438
00:14:05,000 --> 00:14:06,160
他很喜欢

439
00:14:06,160 --> 00:14:08,120
他到底是好还是不好

440
00:14:08,480 --> 00:14:10,560
我们需要去理解这句话

441
00:14:10,720 --> 00:14:13,240
这也是GPT这种单一训练模型

442
00:14:13,440 --> 00:14:14,960
跟ChatGPT这种

443
00:14:14,960 --> 00:14:16,400
可学习可反馈的模型

444
00:14:16,400 --> 00:14:17,880
最大的区别

445
00:14:17,880 --> 00:14:20,800
我们看看右边的几个图

446
00:14:21,040 --> 00:14:22,680
确实我们还是在这里面

447
00:14:23,080 --> 00:14:24,600
只是通过不同的维度

448
00:14:24,600 --> 00:14:26,160
给大家去分享

449
00:14:26,400 --> 00:14:27,320
像模型微调

450
00:14:27,560 --> 00:14:29,120
这个任务确实比较简单

451
00:14:29,120 --> 00:14:30,000
我们从预训练

452
00:14:30,000 --> 00:14:31,240
training model

453
00:14:31,240 --> 00:14:32,520
然后再到fine tuning

454
00:14:32,520 --> 00:14:34,480
接着进行一个预测

455
00:14:34,520 --> 00:14:35,320
而提示学习

456
00:14:35,480 --> 00:14:37,120
只要通过一个简单的预训练

457
00:14:37,120 --> 00:14:38,680
就可以在不同的任务上面

458
00:14:38,680 --> 00:14:39,840
做一个预测

459
00:14:39,880 --> 00:14:40,960
像提示学习

460
00:14:41,160 --> 00:14:42,280
我可能首先

461
00:14:42,400 --> 00:14:43,640
大家都要有一个预训练

462
00:14:44,040 --> 00:14:45,480
然后我会在BCD

463
00:14:45,480 --> 00:14:45,960
任务里面

464
00:14:46,080 --> 00:14:47,400
做一个仔指示性的学习

465
00:14:47,400 --> 00:14:50,280
接着我回到A任务上面做预测

466
00:14:50,560 --> 00:14:52,040
就是希望让我们的模型

467
00:14:52,280 --> 00:14:54,760
更加具备理解能力

468
00:14:54,800 --> 00:14:55,640
提示学习

469
00:14:55,840 --> 00:14:57,080
更加聚焦于

470
00:14:57,080 --> 00:15:00,640
我们对语料的一种预测生成

471
00:15:01,960 --> 00:15:02,440
好了

472
00:15:02,440 --> 00:15:04,240
这一节的内容就到这里为止

473
00:15:04,240 --> 00:15:04,960
我们下一节

474
00:15:04,960 --> 00:15:06,240
更加深入的去看看

475
00:15:06,240 --> 00:15:07,360
ChatGPT里面的

476
00:15:07,360 --> 00:15:08,440
强化学习部分

477
00:15:08,867 --> 00:15:10,867
谢谢各位拜了个拜

478
00:15:10,867 --> 00:15:15,092
卷的不行了卷的不行了   记得一键三连加关注哦

479
00:15:15,092 --> 00:15:18,392
所有的内容都会开源在下面的链接里面 拜了个拜

