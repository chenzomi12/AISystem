1
00:00:00,100 --> 00:00:04,425
字幕生成：Galaxies     字幕校对：NaHS

2
00:00:04,425 --> 00:00:06,800
Hello 大家好,ZOMI又回来了

3
00:00:06,800 --> 00:00:09,640
今天还是在推理引擎的最后一个内容

4
00:00:09,640 --> 00:00:10,800
Kernels 优化

5
00:00:10,800 --> 00:00:13,200
今天主要是给大家去分享一下

6
00:00:13,200 --> 00:00:16,800
Img2Col 这种卷积的优化方式

7
00:00:16,800 --> 00:00:20,000
回到整个 Kernel 优化的课程系列

8
00:00:20,000 --> 00:00:23,200
会讲算法的优化内存的布局

9
00:00:23,200 --> 00:00:25,600
还有编译和调度优化

10
00:00:25,600 --> 00:00:28,000
在整体里面算法的优化

11
00:00:28,000 --> 00:00:30,600
将会深入的去讲解一下

12
00:00:30,600 --> 00:00:33,800
而算法的优化更多的是集中在 Kernel 层

13
00:00:33,800 --> 00:00:36,000
这里面很多不同的算法

14
00:00:36,000 --> 00:00:38,400
或者理解到的具体执行的算法

15
00:00:38,400 --> 00:00:40,800
都承载在 Kernel 层

16
00:00:40,800 --> 00:00:42,400
在这一节课程里面

17
00:00:42,400 --> 00:00:44,800
将会聚焦两个内容

18
00:00:44,800 --> 00:00:47,000
第一个内容就是 Img2Col

19
00:00:47,000 --> 00:00:50,800
第二个就是 Spatial Pack Optimizer

20
00:00:50,800 --> 00:00:53,000
空间组合优化两个方式

21
00:00:53,000 --> 00:00:55,400
现在来到第一个内容

22
00:00:55,600 --> 00:00:58,800
就是 Img2Col 整体的算法原理

23
00:01:00,200 --> 00:01:03,200
在 Img2Col 的算法原理

24
00:01:03,200 --> 00:01:05,200
其实 IMG2Clone

25
00:01:05,200 --> 00:01:07,400
简单叫做 Image to Column

26
00:01:07,400 --> 00:01:10,200
然后其实这种方式是

27
00:01:10,200 --> 00:01:13,400
Caffe 早期的 AI 框架里面去采用的

28
00:01:13,400 --> 00:01:15,200
为什么说是早期

29
00:01:15,200 --> 00:01:18,600
是因为一开始卷积的计算方式

30
00:01:18,600 --> 00:01:19,600
确实太复杂了

31
00:01:19,600 --> 00:01:21,000
而且不容易优化

32
00:01:21,000 --> 00:01:24,200
于是 Caffe 一开始就采用了 Img2Col

33
00:01:24,200 --> 00:01:26,600
这种方式把高维的张量

34
00:01:26,600 --> 00:01:29,400
转换成为低维的矩阵的相乘

35
00:01:29,400 --> 00:01:32,400
简单的看看下面的示例图

36
00:01:32,400 --> 00:01:35,000
知道在整个神经网络里面

37
00:01:35,000 --> 00:01:37,000
基本上很多计算

38
00:01:37,000 --> 00:01:40,200
都是用高维的张量去进行计算的

39
00:01:40,200 --> 00:01:41,800
而高维的张量的表示

40
00:01:41,800 --> 00:01:45,200
一般使用 NHWC 这种表示方式

41
00:01:45,200 --> 00:01:47,200
然后会把高维的张量

42
00:01:47,200 --> 00:01:49,400
这种 NHWC 转换成为

43
00:01:49,400 --> 00:01:51,600
通过 Image to Column 这种方式

44
00:01:51,600 --> 00:01:54,600
转换成为 GEMM 或者 BLAS MTK 这种库

45
00:01:54,600 --> 00:01:57,200
可以进行直接矩阵层的操作

46
00:01:57,200 --> 00:01:59,800
接着进行一个逆变的操作

47
00:01:59,800 --> 00:02:02,000
Column to Image 这种方式

48
00:02:02,000 --> 00:02:05,200
把张量恢复成为 NHWC 的格式

49
00:02:05,200 --> 00:02:07,400
给下一个算子去进行计算

50
00:02:07,400 --> 00:02:10,000
而这里面就把卷积的方式

51
00:02:10,000 --> 00:02:12,000
就变成 GEMM 的方式了

52
00:02:12,000 --> 00:02:15,800
下面看一个比较具体的例子

53
00:02:15,800 --> 00:02:17,200
在具体例子进入之前

54
00:02:17,200 --> 00:02:19,800
看看 Img2col 整体的算法过程

55
00:02:19,800 --> 00:02:22,000
虽然只看算法过程没什么意思

56
00:02:22,000 --> 00:02:25,200
但是有助于后面的了解

57
00:02:25,200 --> 00:02:27,400
首先这里面分开两个步骤

58
00:02:27,400 --> 00:02:30,400
第一个步骤就是 Image to Column

59
00:02:30,400 --> 00:02:33,000
就把输入的数据

60
00:02:33,000 --> 00:02:34,800
还有权重的数据

61
00:02:34,800 --> 00:02:36,000
转换排布

62
00:02:36,000 --> 00:02:40,000
转换成为 Matmul 可以进行计算的排布

63
00:02:40,000 --> 00:02:41,800
所以这里面分开两个步骤

64
00:02:41,800 --> 00:02:44,400
第一个步骤就是第一行

65
00:02:44,400 --> 00:02:46,200
第一句话 Image to Column

66
00:02:46,200 --> 00:02:48,400
第二个步骤就是 Matmul

67
00:02:48,400 --> 00:02:50,600
第二行第二句话的意思

68
00:02:50,600 --> 00:02:52,400
下面具体来看看

69
00:02:52,400 --> 00:02:55,600
一般的图像是怎么操作的

70
00:02:55,600 --> 00:02:57,800
可以看到图像的数的维度

71
00:02:57,800 --> 00:02:59,000
一般都是三维

72
00:02:59,000 --> 00:03:01,000
H W 3

73
00:03:01,000 --> 00:03:03,800
H 就是长、宽乘以三个信道

74
00:03:03,800 --> 00:03:05,400
是一般的图片

75
00:03:05,400 --> 00:03:08,000
而卷积核可能会有四维

76
00:03:08,000 --> 00:03:10,000
N、C、KH、KW

77
00:03:10,000 --> 00:03:12,600
KH、KW代表卷积核

78
00:03:12,600 --> 00:03:14,200
Kernel 的长和宽

79
00:03:14,200 --> 00:03:17,800
而 C 是代表单一个卷积核的Channel数

80
00:03:17,800 --> 00:03:20,800
N 代表是有多少这样的一个小组

81
00:03:20,800 --> 00:03:22,800
最后的输出的维度就是

82
00:03:22,800 --> 00:03:26,400
N H W 最右边的图所示

83
00:03:26,400 --> 00:03:30,200
当然这是最简单的图片的卷积的操作

84
00:03:30,200 --> 00:03:31,800
现在来看一下

85
00:03:31,800 --> 00:03:33,200
在神经网络里面

86
00:03:33,200 --> 00:03:36,600
数据的排布一般都是高维的、四维的

87
00:03:36,600 --> 00:03:39,800
甚至到了点云它可能是五维的

88
00:03:39,800 --> 00:03:41,600
默认的以四维为例子

89
00:03:41,600 --> 00:03:45,000
N H W C 输入的就不是图片了

90
00:03:45,000 --> 00:03:46,200
而是 Feature Map

91
00:03:46,200 --> 00:03:48,200
或者一个 Tensor

92
00:03:48,200 --> 00:03:50,000
Tensor 的维度就是 N

93
00:03:50,000 --> 00:03:52,200
IH、IW、IC

94
00:03:52,200 --> 00:03:55,200
I 就是 Input Height、Input Width

95
00:03:55,200 --> 00:03:57,600
输入的 Feature Map 长和宽

96
00:03:57,600 --> 00:04:00,800
而 I C 就是 Input Channels 的大小

97
00:04:00,800 --> 00:04:02,800
一共有 N 组这样的维度

98
00:04:02,800 --> 00:04:04,800
而卷积核的维度

99
00:04:04,800 --> 00:04:07,200
可能在前面加了个 K W

100
00:04:07,200 --> 00:04:09,600
K H Kernels Width Kernels Height

101
00:04:09,600 --> 00:04:13,800
然后 I C 另外有一个就是 Featured N

102
00:04:13,800 --> 00:04:15,600
这个是相同的

103
00:04:15,600 --> 00:04:18,000
而输出的维度其实也有所不同

104
00:04:18,000 --> 00:04:21,000
大家要注意的就是前面的下标

105
00:04:21,000 --> 00:04:23,800
哪个是 I 哪个是 O 哪个是 N

106
00:04:23,800 --> 00:04:26,400
输出就是 O H O W 乘以 O C

107
00:04:26,400 --> 00:04:29,800
当然了同样有 N 组这样的一些张量

108
00:04:29,800 --> 00:04:30,600
或者 Feature Map

109
00:04:30,600 --> 00:04:33,400
下面看一下更加具体的例子

110
00:04:33,400 --> 00:04:34,800
可以看到 Img2col

111
00:04:34,800 --> 00:04:39,400
最重要的是改变了数据的排布的方式

112
00:04:39,400 --> 00:04:41,200
既然改变了数据的排布方式

113
00:04:41,200 --> 00:04:44,400
就可以方便把刚才权重的数据

114
00:04:44,400 --> 00:04:46,200
变成一个二维的矩阵

115
00:04:46,200 --> 00:04:50,000
把 Feature Map 变成了一个二维的矩阵

116
00:04:50,000 --> 00:04:52,800
通过行跟列相乘

117
00:04:52,800 --> 00:04:56,000
得到最终的输出的结果

118
00:04:56,000 --> 00:04:58,800
就完成了整个卷积的计算

119
00:04:58,800 --> 00:04:59,600
很有意思

120
00:04:59,600 --> 00:05:02,400
更多的是数学上面的变换

121
00:05:02,400 --> 00:05:06,400
那下面看看怎么进行算法的重排

122
00:05:06,400 --> 00:05:09,800
或者怎么对内存的数据进行重排

123
00:05:09,800 --> 00:05:12,600
可以看到灰色的这个小框框

124
00:05:12,800 --> 00:05:17,200
是卷积核或者滑动窗口的大小

125
00:05:17,200 --> 00:05:20,600
那滑动窗口是 1 2 3 4 5 6 这么排的数据

126
00:05:20,600 --> 00:05:23,400
但实际上数据在滑动窗口里面

127
00:05:23,400 --> 00:05:25,600
是 1 2 3 7 8 9

128
00:05:25,600 --> 00:05:28,000
那可能下面还有更大的数了

129
00:05:28,000 --> 00:05:31,000
那这个时候就把一个滑动窗口的数据

130
00:05:31,000 --> 00:05:33,000
对它进行展开

131
00:05:33,000 --> 00:05:35,000
同样对第二个滑动窗口

132
00:05:35,000 --> 00:05:37,000
是第二个Channel的滑动窗口

133
00:05:37,000 --> 00:05:39,200
对它进行展开

134
00:05:39,200 --> 00:05:41,600
不断的展开成为一行

135
00:05:41,600 --> 00:05:46,400
那这一行对应的就是 kw 乘以 kh 乘以 ic

136
00:05:46,400 --> 00:05:49,600
是完完全全跟卷积核展开的方式

137
00:05:49,600 --> 00:05:52,200
是对应起来就方便相乘

138
00:05:52,200 --> 00:05:55,000
而一共有多少行呢

139
00:05:55,000 --> 00:05:57,600
多少就是 oh 乘以 ow 行了

140
00:05:57,600 --> 00:06:00,400
这个就是对应到输出

141
00:06:00,400 --> 00:06:04,600
下面看一下怎么对权重的数据进行重排

142
00:06:04,600 --> 00:06:06,200
权重的数据进行重排

143
00:06:06,200 --> 00:06:07,600
其实很好理解

144
00:06:07,600 --> 00:06:09,600
而且很有意思一点就是

145
00:06:09,600 --> 00:06:13,800
权重的数据重排不是在 kernel 执行的时候进行重排的

146
00:06:13,800 --> 00:06:16,200
在推定引擎架构里面

147
00:06:16,200 --> 00:06:20,600
一般对 Img2col这种转换的方式的数据重排

148
00:06:20,600 --> 00:06:25,400
会在模型转换或者图优化的过程当中

149
00:06:25,400 --> 00:06:29,000
特别是布局优化或者内存优化的时候

150
00:06:29,000 --> 00:06:31,200
进行转换重排的

151
00:06:31,200 --> 00:06:34,200
但有可能在 Runtime 的预编译阶段

152
00:06:34,200 --> 00:06:35,800
或者 Runtime 的预执行阶段

153
00:06:35,800 --> 00:06:38,000
进行重排也是有可能的

154
00:06:38,000 --> 00:06:41,200
具体就取决于推定引擎的架构是怎么设计的

155
00:06:41,200 --> 00:06:43,600
这个模块应该装载在哪里

156
00:06:43,600 --> 00:06:48,800
现在又回到刚才的 img2col 的这种算法过程里面

157
00:06:48,800 --> 00:06:51,200
对权重的数据进行重排

158
00:06:51,200 --> 00:06:54,200
权重数据进行重排是比较简单的

159
00:06:54,200 --> 00:06:57,200
可以看到左边的紫色的这小框框

160
00:06:57,200 --> 00:06:59,400
就是一个卷积核

161
00:06:59,400 --> 00:07:02,200
那卷积核 1 2 3 4 5 6 7 8 9

162
00:07:02,200 --> 00:07:05,200
直接把它展开成为一行

163
00:07:05,200 --> 00:07:06,800
可以看到直接展开成一行

164
00:07:07,000 --> 00:07:09,400
然后对第二个 channel 进行展开

165
00:07:09,400 --> 00:07:10,800
第三个 channel 进行展开

166
00:07:10,800 --> 00:07:12,800
每个 filter 对它进行展开

167
00:07:12,800 --> 00:07:17,000
所以一共有 n 行 n 乘以 kw 乘以 kh 乘以 ic

168
00:07:17,000 --> 00:07:19,400
就组成了一个大的矩阵

169
00:07:19,400 --> 00:07:22,800
把高维的四维的张量的数据

170
00:07:22,800 --> 00:07:24,600
变成一个二维的矩阵

171
00:07:24,600 --> 00:07:26,200
既然变成一个二维矩阵

172
00:07:26,200 --> 00:07:29,600
就非常好的利用 GEMM 的特性

173
00:07:29,600 --> 00:07:32,200
对它进行一个计算

174
00:07:32,200 --> 00:07:35,200
现在整体的看看一个过程

175
00:07:35,200 --> 00:07:36,600
这里面分开两步

176
00:07:36,600 --> 00:07:38,600
上面的是原来高维的数据

177
00:07:38,600 --> 00:07:39,600
高维的张量

178
00:07:39,600 --> 00:07:41,400
进行一个卷积的过程

179
00:07:41,400 --> 00:07:42,800
这个就是卷积核

180
00:07:42,800 --> 00:07:44,200
这个就是 feature map

181
00:07:44,200 --> 00:07:47,000
最终得到输出的结果

182
00:07:47,000 --> 00:07:51,000
然后把它进行 image to column 的方式

183
00:07:51,000 --> 00:07:52,000
把权重

184
00:07:52,000 --> 00:07:54,400
把卷积核进行转换

185
00:07:54,400 --> 00:07:57,600
成为一个单独的二维的矩阵

186
00:07:57,600 --> 00:08:00,400
接着把 feature map 同样进行展开

187
00:08:00,400 --> 00:08:02,400
变成一个单独的矩阵

188
00:08:02,400 --> 00:08:05,600
接着两个矩阵相乘得到输出的矩阵

189
00:08:05,600 --> 00:08:06,600
输出的矩阵

190
00:08:06,600 --> 00:08:08,200
最后的箭头是向上的

191
00:08:08,200 --> 00:08:09,400
大家值得注意的就是

192
00:08:09,400 --> 00:08:11,200
需要通过 column to image

193
00:08:11,200 --> 00:08:13,400
把它逆变回来

194
00:08:13,400 --> 00:08:15,400
接下来整体的看看

195
00:08:15,400 --> 00:08:17,400
img2col 的算法流程

196
00:08:17,400 --> 00:08:19,000
算法流程分为四步

197
00:08:19,000 --> 00:08:22,400
第一步就是对输入的数据

198
00:08:22,400 --> 00:08:24,400
进行展开

199
00:08:24,400 --> 00:08:28,200
展开成为一个独特的独立的权重

200
00:08:28,200 --> 00:08:30,600
第二个就是对权重的数据

201
00:08:30,600 --> 00:08:32,400
进行展开

202
00:08:32,400 --> 00:08:34,400
同样就是就展开重排

203
00:08:34,400 --> 00:08:37,800
接着对上面一二步得到的两个矩阵

204
00:08:37,800 --> 00:08:39,200
进行相乘

205
00:08:39,200 --> 00:08:41,200
最终得到输出的矩阵

206
00:08:41,200 --> 00:08:42,400
输出的矩阵

207
00:08:42,400 --> 00:08:45,200
同样需要进行一个逆变的过程

208
00:08:45,200 --> 00:08:47,800
所以整体来说分开四个步骤

209
00:08:47,800 --> 00:08:50,800
四个步骤的执行方式和执行的模块

210
00:08:50,800 --> 00:08:52,000
都是不一样的

211
00:08:52,000 --> 00:08:55,200
可能 1 3 4

212
00:08:55,200 --> 00:08:58,000
是进行到具体的 kernel 层里面

213
00:08:58,000 --> 00:08:59,200
但是第二个

214
00:08:59,200 --> 00:09:01,000
可能会在预编译阶段

215
00:09:01,000 --> 00:09:02,200
或者在

216
00:09:02,400 --> 00:09:04,800
离线转换优化模块里面去实现

217
00:09:04,800 --> 00:09:06,600
那下面来总结一下

218
00:09:06,600 --> 00:09:09,400
Img2col计算的方式

219
00:09:09,400 --> 00:09:10,800
可以看到 Img2col

220
00:09:10,800 --> 00:09:14,000
就是把传统的卷积大量的计算

221
00:09:14,000 --> 00:09:17,000
使用 GEMM 这种经过优化的库

222
00:09:17,000 --> 00:09:19,400
来进行一个加速的

223
00:09:19,400 --> 00:09:21,800
但是有个问题就是使用 Img2col

224
00:09:21,800 --> 00:09:23,600
可以看到需要对数据

225
00:09:23,600 --> 00:09:25,000
进行重排

226
00:09:25,000 --> 00:09:26,800
把三维或者高维的数据

227
00:09:26,800 --> 00:09:29,200
展开成为二维的矩阵

228
00:09:29,200 --> 00:09:30,400
那这个时候

229
00:09:30,400 --> 00:09:32,800
就需要对数据的数据

230
00:09:32,800 --> 00:09:34,600
拷贝多份

231
00:09:34,600 --> 00:09:37,800
而且就对内存有开销了

232
00:09:37,800 --> 00:09:40,200
第二个就是转换之后

233
00:09:40,200 --> 00:09:42,000
就有很多不同

234
00:09:42,000 --> 00:09:45,000
已经实现好的高速的优化库

235
00:09:45,000 --> 00:09:49,400
BLAS、MKL、NumPy 这种去实现

236
00:09:49,400 --> 00:09:50,600
然后值得一提的

237
00:09:50,600 --> 00:09:52,600
就是刚才也给大家介绍过

238
00:09:52,600 --> 00:09:55,200
就是首先会在权重

239
00:09:55,200 --> 00:09:58,000
会预先的去把它转换成为Img2col

240
00:09:58,000 --> 00:09:59,800
而不是在真正全众来的时候

241
00:09:59,800 --> 00:10:00,800
或者计算的时候

242
00:10:00,800 --> 00:10:02,000
我才做转换

243
00:10:02,000 --> 00:10:03,600
在训练的阶段

244
00:10:03,600 --> 00:10:07,000
其实已经获得到权重的数据了

245
00:10:07,000 --> 00:10:08,200
而 Input 的数据

246
00:10:08,200 --> 00:10:10,800
确实只有在数据真正来的时候

247
00:10:10,800 --> 00:10:12,000
数据流来的时候

248
00:10:12,000 --> 00:10:12,800
才能感知

249
00:10:12,800 --> 00:10:17,400
那这时候确实没办法进行提前的重排

250
00:10:17,400 --> 00:10:20,200
下面来到第二个内容

251
00:10:20,200 --> 00:10:22,800
也是这一节小课里面的

252
00:10:22,800 --> 00:10:23,600
最后一个内容

253
00:10:23,600 --> 00:10:26,000
空间的组合优化

254
00:10:26,000 --> 00:10:28,200
像 Img2col这种方式

255
00:10:28,200 --> 00:10:29,200
到空间组合优化

256
00:10:29,200 --> 00:10:30,800
Img2col可以理解为一个

257
00:10:30,800 --> 00:10:34,000
比较朴素的卷积的优化的手段

258
00:10:34,000 --> 00:10:35,200
把卷积的方式

259
00:10:35,200 --> 00:10:37,800
变换成为一个矩阵层的方式

260
00:10:37,800 --> 00:10:39,200
而空间组合优化

261
00:10:39,200 --> 00:10:41,400
更多的是基于一个分字的思想

262
00:10:41,400 --> 00:10:42,200
既然分治

263
00:10:42,200 --> 00:10:45,200
就可以知道里面很重要的一个词

264
00:10:45,200 --> 00:10:46,800
就是空间

265
00:10:46,800 --> 00:10:47,600
空间这两个字

266
00:10:47,600 --> 00:10:49,600
就帮卷积的计算

267
00:10:49,600 --> 00:10:50,800
利用空间的特征

268
00:10:50,800 --> 00:10:52,800
划分成为若干份了

269
00:10:52,800 --> 00:10:54,400
然后进行分别处理

270
00:10:54,400 --> 00:10:55,400
那可以看到

271
00:10:55,400 --> 00:10:58,200
下面就是空间组合优化的一种方式

272
00:10:58,200 --> 00:10:58,600
当然了

273
00:10:58,600 --> 00:11:01,400
这里面不是用 GEMM 来去示例

274
00:11:01,400 --> 00:11:03,600
也不是用 Img2col 来示例

275
00:11:03,600 --> 00:11:06,200
而是直接用传统的卷积的方式

276
00:11:06,200 --> 00:11:07,600
进行示例

277
00:11:07,600 --> 00:11:09,600
这里面对输入的数据

278
00:11:09,600 --> 00:11:12,400
划分成为四个模块

279
00:11:12,400 --> 00:11:13,200
四个部分

280
00:11:13,200 --> 00:11:16,000
也就是 IH 还有 IW

281
00:11:16,000 --> 00:11:18,200
进行两两切分

282
00:11:18,200 --> 00:11:20,000
划分成为四块

283
00:11:20,000 --> 00:11:20,800
这第一块

284
00:11:20,800 --> 00:11:21,800
第二块

285
00:11:21,800 --> 00:11:23,000
第三块

286
00:11:23,000 --> 00:11:24,000
第四块

287
00:11:24,000 --> 00:11:25,400
分别对权重

288
00:11:25,400 --> 00:11:26,400
进行卷积

289
00:11:26,400 --> 00:11:27,400
得到输出

290
00:11:27,400 --> 00:11:29,200
最后把输出拼接到一起

291
00:11:29,200 --> 00:11:30,200
这种就是最简单

292
00:11:30,200 --> 00:11:32,600
最朴素的空间优化的方法了

293
00:11:32,600 --> 00:11:34,000
现在看一下

294
00:11:34,000 --> 00:11:37,000
整个空间优化的原理

295
00:11:37,000 --> 00:11:38,400
原理还是非常简单的

296
00:11:38,400 --> 00:11:39,800
主要是下面这几个图

297
00:11:39,800 --> 00:11:42,400
划这几个图确实花了不少时间

298
00:11:42,400 --> 00:11:43,600
像空间组合优化

299
00:11:43,600 --> 00:11:45,600
其实是非常好理解的原理

300
00:11:45,600 --> 00:11:47,200
首先会把输入的

301
00:11:47,200 --> 00:11:49,000
一个很大的 Feature Map

302
00:11:49,000 --> 00:11:51,200
把它分成 Unpack 层

303
00:11:51,200 --> 00:11:53,400
多个不同的 Feature Map

304
00:11:53,400 --> 00:11:54,800
根据不同的小的 Feature Map

305
00:11:54,800 --> 00:11:56,200
跟权重

306
00:11:56,200 --> 00:11:58,600
跟数据进行卷积

307
00:11:58,600 --> 00:12:00,800
得到多个数据的输出

308
00:12:00,800 --> 00:12:02,000
但是有一点值得注意的

309
00:12:02,000 --> 00:12:04,400
就是这里面的小框框的窗口

310
00:12:04,400 --> 00:12:06,000
或者跨分的一个小模块

311
00:12:06,000 --> 00:12:07,800
必须要跟卷积核的

312
00:12:07,800 --> 00:12:10,400
Windows 的大小相匹配

313
00:12:10,400 --> 00:12:12,400
而且跟 Stride 相匹配

314
00:12:12,400 --> 00:12:14,200
这个时候就可以很好的

315
00:12:14,200 --> 00:12:16,400
利用计算机的存储结构

316
00:12:16,400 --> 00:12:18,600
获得性能的提升

317
00:12:18,600 --> 00:12:21,200
为什么说是计算机的存储结构了

318
00:12:21,200 --> 00:12:22,800
因为知道计算机里面

319
00:12:22,800 --> 00:12:24,600
或者 CPU GPU 里面

320
00:12:24,800 --> 00:12:27,000
还有 L0 L1 L2

321
00:12:27,000 --> 00:12:29,000
不同的 Cache

322
00:12:29,000 --> 00:12:31,200
有不同的性能的提升

323
00:12:31,200 --> 00:12:33,000
下面看一下

324
00:12:33,000 --> 00:12:35,800
空间左右化一些注意的点

325
00:12:35,800 --> 00:12:38,000
其实在上文里面

326
00:12:38,000 --> 00:12:39,400
讲了不管是 Img2col

327
00:12:39,400 --> 00:12:41,400
还是空间左右化

328
00:12:41,400 --> 00:12:44,800
都忽略了 Padding 的操作

329
00:12:44,800 --> 00:12:46,200
有了 Padding 这个操作

330
00:12:46,200 --> 00:12:47,800
其实还是需要注意

331
00:12:47,800 --> 00:12:49,400
Padding 为 Value 的时候

332
00:12:49,400 --> 00:12:51,200
可以基本上忽略了

333
00:12:51,200 --> 00:12:53,600
但是 Padding 等于 Same 的时候

334
00:12:53,600 --> 00:12:55,200
需要利用边界补0

335
00:12:55,200 --> 00:12:56,600
不在边界补0的时候

336
00:12:56,600 --> 00:12:59,400
需要利用 0g 的张量的值

337
00:12:59,400 --> 00:13:00,600
所以一般来说

338
00:13:00,600 --> 00:13:02,400
都会多出了

339
00:13:02,400 --> 00:13:05,800
那么一小个模块进行重叠计算的

340
00:13:05,800 --> 00:13:07,600
这也是在真正计算的时候

341
00:13:07,600 --> 00:13:10,200
需要注意的一个内容

342
00:13:10,200 --> 00:13:11,400
那现在来看看

343
00:13:11,400 --> 00:13:15,600
空间组合优化的 Coins 它的问题

344
00:13:15,600 --> 00:13:18,600
在真正的空间组合优化这种方式

345
00:13:18,600 --> 00:13:20,800
确实用的非常多

346
00:13:20,800 --> 00:13:22,800
它是 Kernel 实现的一个

347
00:13:22,800 --> 00:13:24,200
很重要的 Trick

348
00:13:24,200 --> 00:13:26,400
假设现在把一些张量

349
00:13:26,400 --> 00:13:29,000
分成边长为 4 或者 8

350
00:13:29,000 --> 00:13:30,400
为什么会为 4 和 8

351
00:13:30,400 --> 00:13:32,600
是因为方便 AI 编译器

352
00:13:32,600 --> 00:13:34,200
或者传统编译器

353
00:13:34,200 --> 00:13:37,200
进行向量化的操作

354
00:13:37,200 --> 00:13:39,000
向量化的转变

355
00:13:39,000 --> 00:13:41,000
不过值得注意的就是

356
00:13:41,000 --> 00:13:45,600
这个模块并不是分的越小越好的

357
00:13:45,600 --> 00:13:46,600
当然了越小

358
00:13:46,600 --> 00:13:47,800
它有个好处就是

359
00:13:47,800 --> 00:13:51,200
充分的利用了计算机体系里面的

360
00:13:51,200 --> 00:13:52,600
多级的 Cache

361
00:13:52,600 --> 00:13:54,400
但是模块越小

362
00:13:54,400 --> 00:13:56,200
局部性也就越高

363
00:13:56,200 --> 00:13:57,200
负面的作用就是

364
00:13:57,200 --> 00:14:00,800
消耗更多的额外的内存

365
00:14:00,800 --> 00:14:03,000
这也是它带来的好处和问题

366
00:14:03,000 --> 00:14:05,000
所以在 Kernel 实现的时候

367
00:14:05,000 --> 00:14:06,600
需要把握一个度

368
00:14:06,600 --> 00:14:08,800
寻找一个合适的划分的方式

369
00:14:08,800 --> 00:14:11,000
或者合适的划分的尺寸

370
00:14:11,000 --> 00:14:12,200
是一个不容易的事情

371
00:14:12,200 --> 00:14:14,400
需要经过大量的时间的优化

372
00:14:14,400 --> 00:14:15,600
当然了这里也可以通过

373
00:14:15,600 --> 00:14:18,400
AI 编译器去自动的寻优

374
00:14:18,600 --> 00:14:21,200
但是在推理场景

375
00:14:21,200 --> 00:14:23,000
一般寻优完一次之后

376
00:14:23,000 --> 00:14:25,200
基本上就很少去改动了

377
00:14:25,200 --> 00:14:29,000
那最后来到回头

378
00:14:29,000 --> 00:14:31,200
看看整个推理引擎架构里面

379
00:14:31,200 --> 00:14:34,000
主要讲的是在 Kernel 优化

380
00:14:34,000 --> 00:14:35,000
而 Kernel 优化

381
00:14:35,000 --> 00:14:36,600
其实这里面有很多种

382
00:14:36,600 --> 00:14:38,200
第一种像左边的这个

383
00:14:38,200 --> 00:14:40,000
就是针对 x86 的

384
00:14:40,000 --> 00:14:41,600
而这种中间的这个

385
00:14:41,600 --> 00:14:43,000
就针对 GPU 的

386
00:14:43,000 --> 00:14:44,600
不管是 PC 的 GPU

387
00:14:44,600 --> 00:14:47,200
还是手机的 GPU 都会有

388
00:14:47,200 --> 00:14:50,200
而另外一种是针对编译器的

389
00:14:50,200 --> 00:14:51,800
就通过编译器来实现的

390
00:14:51,800 --> 00:14:54,400
所以说可能 Kernel 层

391
00:14:54,400 --> 00:14:56,800
在整个推理引擎的代码里面

392
00:14:56,800 --> 00:14:58,800
占了绝大部分

393
00:14:58,800 --> 00:15:00,400
大部分都是 Kernel 层

394
00:15:00,400 --> 00:15:02,000
一个 CUDA 的算子

395
00:15:02,000 --> 00:15:05,400
可能就有很多种不同的实现

396
00:15:05,400 --> 00:15:07,200
例如会实现

397
00:15:07,200 --> 00:15:08,800
Image Clump 的这种方式

398
00:15:08,800 --> 00:15:10,400
对 3x3 的卷积

399
00:15:10,400 --> 00:15:12,000
可能会使用 Winograd

400
00:15:12,000 --> 00:15:14,800
另外会使用 TNM Pack 的方式

401
00:15:14,800 --> 00:15:16,000
针对普通的卷积

402
00:15:16,000 --> 00:15:17,600
有普通卷积的实现方式

403
00:15:17,600 --> 00:15:19,400
所以说一个卷积的操作

404
00:15:19,400 --> 00:15:22,000
就可能有七八种 Kernel 了

405
00:15:22,000 --> 00:15:23,200
针对 x86 里面

406
00:15:23,200 --> 00:15:25,600
可能同样的一个卷积操作

407
00:15:25,600 --> 00:15:27,200
又有七八种 Kernel 了

408
00:15:27,200 --> 00:15:28,200
那一个推理引擎

409
00:15:28,200 --> 00:15:30,200
要同时支持 CPU

410
00:15:30,200 --> 00:15:32,400
也要同时具体 GPU

411
00:15:32,400 --> 00:15:34,000
可能一个 3x3 的卷积

412
00:15:34,000 --> 00:15:34,800
Winograd

413
00:15:34,800 --> 00:15:37,000
就有两个 Kernel 的实现方式了

414
00:15:37,000 --> 00:15:38,600
所以说为什么 Kernel 层

415
00:15:38,600 --> 00:15:40,200
是非常的厚重

416
00:15:40,200 --> 00:15:41,600
也是这个原因

417
00:15:41,600 --> 00:15:42,200
好了

418
00:15:42,200 --> 00:15:44,800
今天的内容就到这里为止

419
00:15:44,800 --> 00:15:45,600
谢谢各位

420
00:15:45,600 --> 00:15:46,600
拜了个拜

