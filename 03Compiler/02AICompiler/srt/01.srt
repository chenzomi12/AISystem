1
00:00:00,000 --> 00:00:04,500
字幕生成：BLACK 字幕校对：凝渊

2
00:00:05,700 --> 00:00:07,160
嗨!大家好，是 ZOMI

3
00:00:07,160 --> 00:00:10,760
今天来到 AI 编译器的一个系列里面

4
00:00:10,760 --> 00:00:14,520
正式的来聊一聊 AI 编译器的一个发展过程

5
00:00:14,520 --> 00:00:18,440
首先这一节会分开三个内容

6
00:00:18,440 --> 00:00:21,080
第一个就是为什么需要 AI 编译器

7
00:00:21,080 --> 00:00:23,000
就是 why need 的一个问题

8
00:00:23,000 --> 00:00:26,080
第二个 what is 就 AI 编译器是什么

9
00:00:26,080 --> 00:00:28,160
AI 编译器的架构怎么样的

10
00:00:28,200 --> 00:00:30,400
第三个就是 AI 编译器未来的挑战

11
00:00:30,400 --> 00:00:32,760
和针对 AI 编译器的一个思考

12
00:00:33,600 --> 00:00:37,040
所以后面我会分开三个内容去给大家汇报一下

13
00:00:37,600 --> 00:00:40,800
在正式进入到这一节给大家汇报的内容之前

14
00:00:41,000 --> 00:00:43,520
我想给大家安利两个视频

15
00:00:43,720 --> 00:00:47,200
第一个就是计算机的架构的新的黄金年代

16
00:00:47,660 --> 00:00:50,660
这个视频是 2018 年图灵的得奖者 David

17
00:00:50,760 --> 00:00:53,600
然后在 2019 年 5 月份发表的一个演讲

18
00:00:53,735 --> 00:00:56,575
这里面就对历史的 RISC 还有 CISC

19
00:00:56,640 --> 00:00:59,440
经典指令集和复杂指令集的一个回顾

20
00:00:59,440 --> 00:01:00,400
做一个畅想

21
00:01:00,400 --> 00:01:02,560
未来肯定是一个芯片异构的时代

22
00:01:02,560 --> 00:01:05,360
而 AI 的加速功能将会无处不在

23
00:01:05,560 --> 00:01:07,240
第二个要给大家安利的视频

24
00:01:07,400 --> 00:01:09,720
就是编译器的黄金时代

25
00:01:10,240 --> 00:01:12,560
这个视频是 Chris LLVM 之父

26
00:01:12,720 --> 00:01:14,840
在 2021 年的一个 presentation

27
00:01:15,280 --> 00:01:16,120
这个视频里面

28
00:01:16,240 --> 00:01:18,320
Chris 就分享了 90 年代开始

29
00:01:18,320 --> 00:01:20,440
GCC 的出现很大程度解决了

30
00:01:20,440 --> 00:01:22,480
编译体系生态化碎片的问题

31
00:01:22,840 --> 00:01:24,520
然后谈到 LLVM 的出现

32
00:01:24,680 --> 00:01:27,240
极大地促进了整个编译器的发展

33
00:01:27,720 --> 00:01:29,760
不同的厂商推出自己不同的芯片

34
00:01:29,760 --> 00:01:32,280
而这些芯片之上肯定需要有编译器的

35
00:01:32,280 --> 00:01:34,480
因为也需要把 AI 的语言

36
00:01:34,480 --> 00:01:35,600
或者高级语言

37
00:01:35,840 --> 00:01:38,440
转换成为真正能够执行的机器码

38
00:01:38,440 --> 00:01:40,600
让芯片的能力发挥出来

39
00:01:40,800 --> 00:01:41,760
而在现在这个阶段

40
00:01:41,880 --> 00:01:43,840
基本上每一家都会推出自己的一个

41
00:01:43,840 --> 00:01:45,800
编译器或者自己的一个 AI 框架

42
00:01:45,800 --> 00:01:47,720
甚至是自己的 AI 软件栈

43
00:01:47,960 --> 00:01:50,000
导致了整个 AI 的编译器的行业

44
00:01:50,120 --> 00:01:51,480
是极度的碎片化了

45
00:01:51,480 --> 00:01:53,120
这个时候就好像回到当时候

46
00:01:53,120 --> 00:01:54,800
80 年代末 90 年代初的

47
00:01:54,800 --> 00:01:55,920
编译器遍地开花

48
00:01:55,920 --> 00:01:57,440
但是没有一个统一的范式

49
00:01:57,440 --> 00:01:58,560
或者统一的形态

50
00:01:58,800 --> 00:02:00,760
所以 Chris 就提出了未来的 10 年

51
00:02:00,760 --> 00:02:03,240
肯定是一个编译器风起云涌的 10 年

52
00:02:03,240 --> 00:02:05,800
而这个时候确实有很多大的技术

53
00:02:05,800 --> 00:02:06,960
会重新的整合

54
00:02:07,240 --> 00:02:08,280
整个编译器的行业

55
00:02:08,360 --> 00:02:09,760
尽快重新的洗牌

56
00:02:11,480 --> 00:02:13,520
看完刚才我给大家安利的两个视频

57
00:02:13,640 --> 00:02:14,880
其实今天的内容

58
00:02:15,360 --> 00:02:17,160
就已经可以结束了

59
00:02:26,770 --> 00:02:29,240
如果大家对于翻墙会有点困难的话

60
00:02:29,240 --> 00:02:31,080
大家可以在弹幕给我留言

61
00:02:31,440 --> 00:02:32,880
我也可以把 YouTube 这两个

62
00:02:32,880 --> 00:02:33,880
presentation 的视频

63
00:02:34,040 --> 00:02:35,840
搬到 bilibili 里面

64
00:02:37,200 --> 00:02:39,480
不过针对为什么需要 AI 编译器

65
00:02:39,600 --> 00:02:40,920
其实我还是有点

66
00:02:40,920 --> 00:02:42,840
额外的一些知识给大家汇报的

67
00:02:42,840 --> 00:02:45,920
刚才其实是站在两个比较宏观的角度

68
00:02:45,920 --> 00:02:47,520
或者两个比较硬核的角度

69
00:02:47,520 --> 00:02:50,680
第一个就是从硬件的架构去看待问题的

70
00:02:50,680 --> 00:02:52,880
就是 AI 的芯片越来越多

71
00:02:52,880 --> 00:02:54,560
异构的芯片越来越多

72
00:02:54,560 --> 00:02:57,600
第二个就是 AI 的编译器极度的分散化

73
00:02:57,600 --> 00:02:59,800
AI 的编译器也是每一个硬件厂商

74
00:02:59,800 --> 00:03:01,520
都会推出自己的一套标准

75
00:03:01,520 --> 00:03:04,600
我今天主要是想从更上层的一个角度

76
00:03:04,600 --> 00:03:06,560
去给大家看待这个问题

77
00:03:06,560 --> 00:03:08,680
首先看一下深度学习

78
00:03:08,680 --> 00:03:11,400
其实在这几年是发展的非常的快

79
00:03:11,400 --> 00:03:12,440
例如 CV

80
00:03:12,440 --> 00:03:15,455
在 2014 年我接触深度学习的时候

81
00:03:15,455 --> 00:03:15,480
我还觉得深度学习

82
00:03:15,480 --> 00:03:16,935
我还觉得深度学习

83
00:03:17,160 --> 00:03:19,440
只能做一个分类的工作

84
00:03:19,440 --> 00:03:21,240
而且一个 GPU 那时候还贼贵

85
00:03:21,760 --> 00:03:24,080
只能到淘宝进行一些海外淘

86
00:03:24,080 --> 00:03:26,600
现在深度学习不仅能够做分类

87
00:03:26,600 --> 00:03:28,840
还可以做图像的分割检测

88
00:03:29,200 --> 00:03:30,080
除了二维之后

89
00:03:30,080 --> 00:03:31,560
又迈向了三维

90
00:03:31,560 --> 00:03:32,520
对三维的数据

91
00:03:32,520 --> 00:03:34,160
三维的点云进行处理

92
00:03:34,520 --> 00:03:37,240
而这两年又涌现出了语言大模型

93
00:03:37,240 --> 00:03:38,720
简单的一个 T5 模型

94
00:03:38,840 --> 00:03:41,600
就可以处理 100 多种语言的会议

95
00:03:41,600 --> 00:03:42,240
另外的话

96
00:03:42,240 --> 00:03:43,040
AI 这个技术

97
00:03:43,160 --> 00:03:44,760
已经烧到 HPC

98
00:03:44,760 --> 00:03:46,215
或者科学计算里面了

99
00:03:46,215 --> 00:03:46,240
可以做一些遥感的处理

100
00:03:46,240 --> 00:03:47,695
可以做一些遥感的处理

101
00:03:47,720 --> 00:03:49,760
蛋白质折叠的处理和预测

102
00:03:49,840 --> 00:03:52,280
另外还可以做一些流体动力学和电磁仿真

103
00:03:52,480 --> 00:03:54,840
用 AI 去求解韦伯斯特方程

104
00:03:55,200 --> 00:03:57,880
所以说现在 AI 的算法越来越多

105
00:03:57,880 --> 00:04:00,400
AI 的框架也是越来越多

106
00:04:00,400 --> 00:04:02,880
而硬件也是不断的去膨胀

107
00:04:02,880 --> 00:04:05,080
每一家都有自己的一个编译体系

108
00:04:05,720 --> 00:04:07,160
确实像 Chris 所说的

109
00:04:07,160 --> 00:04:09,520
可能这个时候编译器体系

110
00:04:09,640 --> 00:04:11,400
就像回到了 90 年代初

111
00:04:11,400 --> 00:04:13,760
每一家都有自己的一个编译体系

112
00:04:14,000 --> 00:04:16,360
每一家都会有自己的一个 AI 编译器

113
00:04:16,360 --> 00:04:17,680
和 AI 编程体系

114
00:04:17,880 --> 00:04:18,680
这个时候

115
00:04:19,040 --> 00:04:21,200
随着现在的算法越来越多

116
00:04:21,200 --> 00:04:23,400
很多新的算子新的算法

117
00:04:23,400 --> 00:04:24,320
会被提出

118
00:04:24,320 --> 00:04:27,520
这些算子的开发维护和测试周期的工作

119
00:04:27,520 --> 00:04:29,400
就会指数式的上升

120
00:04:29,400 --> 00:04:31,680
就是我需要一大批工程师

121
00:04:31,680 --> 00:04:34,960
去解决这一类型相同的问题

122
00:04:35,400 --> 00:04:37,280
第 6 个就是专用芯片的爆发了

123
00:04:37,280 --> 00:04:39,320
导致现在可移植性了

124
00:04:39,320 --> 00:04:40,560
成为一种刚需

125
00:04:40,560 --> 00:04:42,160
那什么叫做可移植性

126
00:04:42,160 --> 00:04:44,120
会在后面去展开一下

127
00:04:44,120 --> 00:04:47,920
首先第 1 个就是 operator 算子越来越多

128
00:04:48,680 --> 00:04:50,920
简单的去实现一个新的算子

129
00:04:50,920 --> 00:04:52,240
或者新的算法的逻辑

130
00:04:52,240 --> 00:04:53,160
其实很简单

131
00:04:53,160 --> 00:04:55,160
但是如果想结合硬件

132
00:04:55,160 --> 00:04:57,440
充分的去发挥硬件的性能

133
00:04:57,440 --> 00:04:59,320
就极致的压榨硬件的性能的

134
00:04:59,320 --> 00:04:59,920
这个时候

135
00:05:00,200 --> 00:05:02,720
就需要做大量的调测工作

136
00:05:03,480 --> 00:05:04,680
所以现在的英伟达

137
00:05:04,680 --> 00:05:05,800
AMD 还有 intel

138
00:05:06,120 --> 00:05:07,920
就会推出自己的优化库

139
00:05:07,920 --> 00:05:09,320
也就是算子库

140
00:05:09,960 --> 00:05:11,720
但实际上无论是哪个厂商

141
00:05:11,720 --> 00:05:13,000
英伟达苹果也好

142
00:05:13,000 --> 00:05:14,680
他们这些推出的算子库

143
00:05:14,680 --> 00:05:16,160
其实是极大的重复的

144
00:05:17,040 --> 00:05:18,240
每一个 DNN 库后面

145
00:05:18,360 --> 00:05:19,760
都有相同的卷积

146
00:05:19,760 --> 00:05:21,840
GEMM 相同的运算

147
00:05:22,960 --> 00:05:23,520
第 2 个点

148
00:05:23,640 --> 00:05:26,520
刚才讲到了可移植性的问题

149
00:05:27,720 --> 00:05:29,200
假设现在针对 AI

150
00:05:29,200 --> 00:05:30,440
在 CPU 和 GPU 上面

151
00:05:30,440 --> 00:05:31,280
已经开发了一个

152
00:05:31,280 --> 00:05:32,480
很好的优化的 pass

153
00:05:32,480 --> 00:05:33,840
但是这些优化的 pass

154
00:05:34,000 --> 00:05:36,480
很难去移植到新的 NPU 上面

155
00:05:36,680 --> 00:05:38,200
这个时候就导致

156
00:05:38,200 --> 00:05:40,480
很多优化的工作就不能复用

157
00:05:41,360 --> 00:05:43,560
可能这会对某个硬件厂商来说

158
00:05:43,720 --> 00:05:44,920
它有独特的优势

159
00:05:45,000 --> 00:05:46,560
但这种优势不是持久的

160
00:05:46,560 --> 00:05:48,360
可能很快就会被超越

161
00:05:48,640 --> 00:05:50,880
因为很多 idea 会不断的互相借鉴

162
00:05:50,880 --> 00:05:52,720
但是对于整个行业来说

163
00:05:52,720 --> 00:05:55,640
垂直的去整合这些新的 pass

164
00:05:55,920 --> 00:05:58,520
推出一个类似于 GCC 或者 LLVM 的编译器

165
00:05:58,520 --> 00:05:59,720
是非常有必要的

166
00:06:01,360 --> 00:06:03,560
这样才能够解决无限的算力

167
00:06:03,560 --> 00:06:06,760
还有有限的精力之间的一个平衡

168
00:06:08,800 --> 00:06:09,880
你不要过来

169
00:06:11,760 --> 00:06:12,920
在前面的内容里面

170
00:06:12,920 --> 00:06:14,120
其实已经充分的

171
00:06:14,120 --> 00:06:17,240
去给大家展开了一个传统编译器的概念

172
00:06:17,240 --> 00:06:19,640
下面来看看一个 AI 编译器

173
00:06:19,640 --> 00:06:21,800
跟传统编译器的一个区别

174
00:06:23,080 --> 00:06:25,240
首先它们的目标都是非常相似的

175
00:06:25,240 --> 00:06:28,040
就是我会自动化的去对程序进行优化

176
00:06:28,640 --> 00:06:31,080
目标都是降低对不同硬件的手工优化

177
00:06:31,080 --> 00:06:33,880
第二个就是优化的方式是类似的

178
00:06:33,880 --> 00:06:35,720
也就是都是通过一个 pass

179
00:06:35,960 --> 00:06:38,160
去提升硬件执行性能

180
00:06:38,160 --> 00:06:41,440
第三点就是软硬件其实是相同的

181
00:06:41,440 --> 00:06:43,120
都分为编译器的前端

182
00:06:43,120 --> 00:06:44,480
编译器的中间优化层

183
00:06:44,480 --> 00:06:45,430
编译器的后端

184
00:06:45,430 --> 00:06:45,480
中间通过 IR 对前后端进行解耦表示

185
00:06:45,480 --> 00:06:49,350
中间通过 IR 对前后端进行解耦表示

186
00:06:49,400 --> 00:06:51,120
最后一个就是 AI 编译器

187
00:06:51,120 --> 00:06:53,000
其实是依赖于传统编译器的

188
00:06:53,000 --> 00:06:55,200
因为传统编译器已经很成熟很稳定了

189
00:06:55,560 --> 00:06:58,240
AI 编译器作为传统编译器的一种补充

190
00:07:00,200 --> 00:07:01,080
下面来看看

191
00:07:01,240 --> 00:07:03,400
这个就是现在的一个编译器

192
00:07:03,400 --> 00:07:05,240
它的输入是一个高级的语言

193
00:07:05,240 --> 00:07:07,040
输出是一个机器的

194
00:07:07,240 --> 00:07:08,800
这个就是传统编译器

195
00:07:08,800 --> 00:07:11,120
而 AI 编译器就是计算图

196
00:07:11,160 --> 00:07:13,080
输出就是机器码

197
00:07:13,760 --> 00:07:16,160
最大的区别就是输入是不同的

198
00:07:16,160 --> 00:07:17,280
是一个计算图

199
00:07:17,520 --> 00:07:19,640
大家想了解一下什么是计算图

200
00:07:20,320 --> 00:07:21,920
可以直接到 B 站

201
00:07:24,920 --> 00:07:26,720
这里面就有详细的去介绍

202
00:07:26,720 --> 00:07:28,200
计算图的概念

203
00:07:29,560 --> 00:07:31,920
第二个不同就是传统的编译器

204
00:07:31,920 --> 00:07:33,160
假设是 LLVM

205
00:07:33,160 --> 00:07:36,040
它的目的是降低整个编程的难度

206
00:07:36,280 --> 00:07:38,040
其次是优化程序

207
00:07:38,600 --> 00:07:41,360
面向开发者提供更高级的语言

208
00:07:41,360 --> 00:07:42,760
而编译器去处理

209
00:07:42,760 --> 00:07:44,640
把它变成一些低级的语言

210
00:07:45,640 --> 00:07:47,480
AI 编译器它最主要的目的

211
00:07:47,640 --> 00:07:49,520
是优化整个程序的性能

212
00:07:49,520 --> 00:07:51,680
就是对计算图进行优化

213
00:07:52,560 --> 00:07:54,360
使得计算图跑在

214
00:07:54,360 --> 00:07:56,320
AI 芯片上面越快越好

215
00:07:56,560 --> 00:07:59,360
其次才是降低整个编程的难度

216
00:08:01,360 --> 00:08:03,080
下面这个图就很好地展示了

217
00:08:03,080 --> 00:08:04,960
传统编译器左边的这一块

218
00:08:04,960 --> 00:08:07,120
跟 AI 编译器右边这一块

219
00:08:07,120 --> 00:08:08,280
之间的一个差别

220
00:08:08,280 --> 00:08:10,400
从左边这块开始先看起

221
00:08:10,640 --> 00:08:13,480
首先编译器都有前端

222
00:08:13,480 --> 00:08:15,400
终端优化还有后端

223
00:08:15,400 --> 00:08:17,760
包括 AI 编译器也会分为有前端

224
00:08:17,760 --> 00:08:19,440
中间优化还有后端

225
00:08:19,440 --> 00:08:22,800
但是传统编译器的前端

226
00:08:22,920 --> 00:08:24,440
主要是对一些语法分析

227
00:08:24,440 --> 00:08:25,880
词法分析和语义分析

228
00:08:25,880 --> 00:08:28,320
而中间的优化主要是做一些

229
00:08:29,080 --> 00:08:31,440
针对高级语言做各种各样的 Pass

230
00:08:31,440 --> 00:08:33,160
后端就是对指令

231
00:08:33,160 --> 00:08:35,240
寄存器代码进行一个布局

232
00:08:35,640 --> 00:08:37,040
生成机器码

233
00:08:37,240 --> 00:08:39,840
现在看看右边 AI 编译器做哪些工作

234
00:08:39,840 --> 00:08:40,960
AI 编译器的前端

235
00:08:40,960 --> 00:08:43,760
可能跟刚才传统编译器

236
00:08:43,760 --> 00:08:44,760
有非常大的区别

237
00:08:44,760 --> 00:08:46,560
它主要是对计算图进行转换

238
00:08:46,560 --> 00:08:48,400
对 NN API 进行表达

239
00:08:48,400 --> 00:08:51,000
而中间优化主要是针对图

240
00:08:51,000 --> 00:08:53,440
和算子进行优化的图算的融合

241
00:08:53,440 --> 00:08:54,280
做一些自动微分

242
00:08:54,280 --> 00:08:55,560
做一些并行的切分

243
00:08:57,120 --> 00:08:58,800
后端就是针对硬件的

244
00:08:58,800 --> 00:09:00,080
kernel 做一些优化的

245
00:09:00,080 --> 00:09:03,200
优化完之后就分给不同的硬件去执行

246
00:09:03,200 --> 00:09:05,160
而分到好像 CPU TPU 这里面

247
00:09:05,160 --> 00:09:06,840
就可能会执行 LLVM

248
00:09:07,080 --> 00:09:09,920
就是把传统的编译器这一套引进来

249
00:09:09,920 --> 00:09:12,080
所以他们所以刚才说了

250
00:09:12,080 --> 00:09:14,960
AI 编译器是构建在传统编译器之上的

251
00:09:14,960 --> 00:09:17,520
它们之间是一个相互补充的关系

252
00:09:19,640 --> 00:09:21,720
下面来总结一下两个差异

253
00:09:21,840 --> 00:09:23,480
第一个就是 IR 的差异

254
00:09:23,480 --> 00:09:26,280
AI 编译器的 IR 会比较 high level 一点

255
00:09:26,280 --> 00:09:29,680
就它主要是描述深度学习这个模型

256
00:09:29,680 --> 00:09:31,280
会带有图的结构

257
00:09:31,280 --> 00:09:34,000
而传统编译器会相对 low level 一点

258
00:09:34,000 --> 00:09:36,680
主要是去描述基本的指令运算

259
00:09:38,880 --> 00:09:42,640
第二个区别就是优化的策略是不一样的

260
00:09:42,640 --> 00:09:44,320
因为 AI 编译器刚才说了

261
00:09:44,320 --> 00:09:45,840
它是面向 high level 的

262
00:09:45,840 --> 00:09:48,160
它的优化是图算的优化

263
00:09:48,520 --> 00:09:50,920
既然引入了领域的特殊的支持

264
00:09:50,920 --> 00:09:53,960
所以它这里面的优化的方式会非常不一样

265
00:09:53,960 --> 00:09:57,760
另外 AI 编译器可能会用到非常低比特的一个计算

266
00:09:59,360 --> 00:10:00,800
传统的编译器在执行的时候

267
00:10:00,960 --> 00:10:03,440
就不会去改变变量的类型和精度

268
00:10:03,480 --> 00:10:05,200
不然会影响结果

269
00:10:08,360 --> 00:10:08,800
好了

270
00:10:08,800 --> 00:10:10,160
今天讲了两个内容

271
00:10:10,160 --> 00:10:12,280
第一个内容就是为什么需要编译器

272
00:10:12,920 --> 00:10:15,600
分别从 AI 的硬件风起云涌

273
00:10:15,760 --> 00:10:17,000
AI 的编译器碎片化

274
00:10:17,000 --> 00:10:18,360
还有算法越来越多

275
00:10:18,360 --> 00:10:19,640
AI 框架越来越多

276
00:10:20,400 --> 00:10:23,080
所以这个时候整个行业其实是需要一个

277
00:10:23,080 --> 00:10:25,640
开源开放模块化的 AI 编译器

278
00:10:25,680 --> 00:10:27,680
去解决一些共性的问题

279
00:10:28,960 --> 00:10:31,760
第二个讲了传统编译器和 AI 编译器

280
00:10:31,800 --> 00:10:33,440
之间的一个具体的区别

281
00:10:34,920 --> 00:10:36,520
卷的不行了卷的不行了

282
00:10:36,520 --> 00:10:38,240
记得一键三连加关注哦

283
00:10:38,480 --> 00:10:41,400
所有的内容都会开源在下面这条链接里面

284
00:10:42,000 --> 00:10:42,720
拜了个拜

