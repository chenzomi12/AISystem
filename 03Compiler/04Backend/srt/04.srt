1
00:00:00,015 --> 00:00:05,056
【字幕生成: 奔崩字幕校对: 奔崩】
（进——片——头）

2
00:00:05,056 --> 00:00:07,400
Hello，大家好，我是 ZOMI

3
00:00:07,400 --> 00:00:10,000
今天我要给大家带来的就是

4
00:00:10,000 --> 00:00:13,080
AI 编译器后端优化的循环优化

5
00:00:13,640 --> 00:00:14,920
具体是指

6
00:00:14,920 --> 00:00:17,680
算子调度里面的循环优化

7
00:00:17,680 --> 00:00:19,874
也就是针对循环进行

8
00:00:19,874 --> 00:00:23,480
展开、分块、重排、融合还有拆分

9
00:00:23,480 --> 00:00:26,560
这几个内容进行详细的展开

10
00:00:26,760 --> 00:00:29,040
这几个内容主要是围绕一个话题

11
00:00:29,040 --> 00:00:32,000
就是 loop 循环

12
00:00:33,400 --> 00:00:34,920
而不管是循环优化

13
00:00:34,920 --> 00:00:36,880
指令优化、存储优化也好

14
00:00:36,880 --> 00:00:39,360
它都是作为我们 ops optimizer

15
00:00:39,360 --> 00:00:40,360
就是

16
00:00:40,960 --> 00:00:42,360
后端优化里面

17
00:00:42,360 --> 00:00:44,520
算子优化这一个部分

18
00:00:45,880 --> 00:00:48,080
现在我们详细的去展开

19
00:00:48,080 --> 00:00:49,440
loop optimization

20
00:00:49,440 --> 00:00:51,720
里面的一些细节的内容

21
00:00:53,080 --> 00:00:56,120
首先第一个就是循环展开

22
00:00:56,200 --> 00:00:58,040
循环展开很明确

23
00:00:58,040 --> 00:01:00,800
就是我们需要对循环进行展开

24
00:01:00,800 --> 00:01:02,320
以便我们每一次迭代

25
00:01:02,480 --> 00:01:05,440
都可以加载或者处理更多的数据

26
00:01:05,640 --> 00:01:07,120
这个时候为的就是

27
00:01:07,120 --> 00:01:09,680
使得我们每一个时钟周期的流水线上

28
00:01:09,680 --> 00:01:11,760
尽可能的在芯片上面

29
00:01:11,760 --> 00:01:13,560
满负荷的去计算

30
00:01:14,000 --> 00:01:17,000
实际上在芯片的时钟周期的流水线当中

31
00:01:17,000 --> 00:01:18,880
我们可能很大程度

32
00:01:19,000 --> 00:01:21,600
会因为指令的顺序的排布不合理

33
00:01:21,600 --> 00:01:23,560
导致 NPU 或者 CPU

34
00:01:23,560 --> 00:01:25,240
GPU 的处理器空转

35
00:01:25,240 --> 00:01:27,280
影响我们整个流水线的效率

36
00:01:27,480 --> 00:01:29,600
这个时候 AI 编译器

37
00:01:29,600 --> 00:01:31,320
就可以为指令调度

38
00:01:31,320 --> 00:01:33,800
带来更大的收益空间

39
00:01:34,240 --> 00:01:37,200
我们现在来看看什么叫循环展开

40
00:01:37,200 --> 00:01:38,720
下面我们有一个例子

41
00:01:38,720 --> 00:01:39,920
有两个迭代

42
00:01:40,160 --> 00:01:41,920
第一个迭代是 for j

43
00:01:41,920 --> 00:01:43,800
第二个迭代是 for i

44
00:01:44,000 --> 00:01:46,240
这个时候我的计算比较简单

45
00:01:46,240 --> 00:01:48,720
A(j) = A(j) + B(i)

46
00:01:48,960 --> 00:01:51,600
这个时候其实我对循环进行展开

47
00:01:51,600 --> 00:01:55,280
现在我对 j 这一个循环进行展开

48
00:01:55,280 --> 00:01:56,880
j 在迭代的时候

49
00:01:56,880 --> 00:01:59,120
在循环的时候跳两个位

50
00:01:59,120 --> 00:02:01,320
然后我在计算的时候

51
00:02:01,320 --> 00:02:02,680
多一次计算

52
00:02:02,680 --> 00:02:03,720
先算 A(j)

53
00:02:03,720 --> 00:02:05,600
然后再算 A(j + 1)

54
00:02:05,600 --> 00:02:09,360
下一次就算 A(j + 2)和 A(j + 3)

55
00:02:09,360 --> 00:02:11,680
这种方式就叫做循环展开

56
00:02:14,280 --> 00:02:16,320
关于循环的第二个内容

57
00:02:16,320 --> 00:02:20,320
就是循环的分块 loop tiling

58
00:02:20,920 --> 00:02:23,000
其实我们在内存空间

59
00:02:23,120 --> 00:02:25,320
或者在处理器里面

60
00:02:25,320 --> 00:02:27,400
显存内存

61
00:02:27,400 --> 00:02:29,320
或者 cache 都是有限

62
00:02:29,320 --> 00:02:31,000
我们代码的访问量

63
00:02:31,000 --> 00:02:33,160
或者代码访问数据量过大的时候

64
00:02:33,480 --> 00:02:35,320
没有办法一次过把我们想要

65
00:02:35,320 --> 00:02:36,480
或者想要处理的数据

66
00:02:36,840 --> 00:02:39,360
直接加载到设备里面

67
00:02:39,600 --> 00:02:42,800
这个时候如果我们对循环进行分块

68
00:02:42,800 --> 00:02:45,080
可以有效的去提高我们 NPU

69
00:02:45,320 --> 00:02:46,800
或者 CPU 里面 cache

70
00:02:46,800 --> 00:02:48,680
上面的一个访存的效率

71
00:02:48,680 --> 00:02:51,280
从而改善我们整个数据的局部性

72
00:02:51,760 --> 00:02:52,680
说白了

73
00:02:52,680 --> 00:02:56,440
显存存储 cache 的空间是有限

74
00:02:56,440 --> 00:02:58,680
所以我们需要对循环

75
00:02:59,240 --> 00:03:02,080
循环里面的数据进行分块

76
00:03:02,800 --> 00:03:05,080
希望能够一次过处理的时候

77
00:03:05,240 --> 00:03:07,680
是刚好满足 cache 的大小

78
00:03:07,680 --> 00:03:10,040
让我们整个的吞吐量变大

79
00:03:10,600 --> 00:03:12,360
不过值得注意的有两个点

80
00:03:12,560 --> 00:03:13,760
第一个点就是分块

81
00:03:13,760 --> 00:03:15,840
如果我们应用在循环的外部

82
00:03:15,840 --> 00:03:16,800
就是我们 loop 的外部

83
00:03:17,080 --> 00:03:20,160
我们会增加计算的空间和时间的局部性

84
00:03:20,480 --> 00:03:22,560
这个一点是需要去注意

85
00:03:22,680 --> 00:03:24,640
当然了我们很多 AI 编译器

86
00:03:25,000 --> 00:03:26,920
其实我们了解这个循环分块

87
00:03:27,040 --> 00:03:28,520
或者其他循环的方式

88
00:03:28,520 --> 00:03:30,600
只是方便我们更好地去

89
00:03:30,920 --> 00:03:33,600
写 AI 编译器自动调度的策略

90
00:03:34,320 --> 00:03:36,560
另外一个值得注意的点就是分块

91
00:03:36,560 --> 00:03:39,000
应该与缓存块一起去使用

92
00:03:39,920 --> 00:03:42,320
这样可以提高流水线的效率

93
00:03:42,320 --> 00:03:43,360
那简单的来说

94
00:03:43,360 --> 00:03:45,800
就是我们分块分块的大小

95
00:03:45,800 --> 00:03:47,640
应该跟缓存块

96
00:03:47,640 --> 00:03:50,040
这个时候就提高了整个系统

97
00:03:50,040 --> 00:03:52,200
或者处理器的整体的效率

98
00:03:53,560 --> 00:03:56,560
而实现的思路其实比较简单

99
00:03:56,840 --> 00:03:59,320
但是我们后面会提出两个问题

100
00:03:59,320 --> 00:04:02,080
这两个问题也是值得大家一起去思考

101
00:04:02,400 --> 00:04:04,000
一般来说实现思路

102
00:04:04,000 --> 00:04:07,080
在 CPU 里面可能它会相对简单一点

103
00:04:07,800 --> 00:04:09,000
假设我们一个数据

104
00:04:09,160 --> 00:04:10,960
没有办法都放在 cache 里面的时候

105
00:04:11,120 --> 00:04:12,800
我们就会把大的数据

106
00:04:12,800 --> 00:04:14,120
分成一个个 tile

107
00:04:14,120 --> 00:04:16,560
就一个个块去进行访问

108
00:04:16,560 --> 00:04:18,440
令每一个块都可以满足

109
00:04:18,440 --> 00:04:21,200
我们处理器上面 cache 的一个大小

110
00:04:21,240 --> 00:04:23,560
具体的做法就是把一层

111
00:04:23,560 --> 00:04:24,920
就是内层的循环

112
00:04:24,920 --> 00:04:27,000
分成 outer loop 和 inner loop

113
00:04:27,000 --> 00:04:28,880
就分成两个不同的 loop

114
00:04:28,880 --> 00:04:31,440
把 outer loop 移到更外层里面

115
00:04:31,440 --> 00:04:33,320
从而确保 inner loop

116
00:04:33,320 --> 00:04:35,120
能够满足 cache

117
00:04:35,120 --> 00:04:37,000
虽然说起来有点拗口

118
00:04:37,000 --> 00:04:39,680
我们现在看一个具体的例子

119
00:04:41,120 --> 00:04:43,240
现在我们以一个简单的例子

120
00:04:43,240 --> 00:04:44,800
那里面有两个迭代

121
00:04:44,800 --> 00:04:47,280
一个迭代是 for j = 0, n

122
00:04:47,280 --> 00:04:50,440
第二个迭代是 for i = 1, m

123
00:04:50,920 --> 00:04:52,343
我需要去处理的就是

124
00:04:52,343 --> 00:04:54,240
A(i) += B(j)

125
00:04:54,240 --> 00:04:55,960
那我们进行分块之后

126
00:04:55,960 --> 00:04:57,080
大家可以看到

127
00:04:57,080 --> 00:04:59,240
我对 j 进行分块

128
00:04:59,240 --> 00:05:01,360
那这个我们叫做 outer loop

129
00:05:01,360 --> 00:05:04,600
这个 j_i 我们叫做 inner loop

130
00:05:04,600 --> 00:05:07,480
我们把一个循环进行了分块

131
00:05:07,480 --> 00:05:09,000
从 0 到 m

132
00:05:09,000 --> 00:05:12,600
我们把循环按 T 大小进行一个分块

133
00:05:12,600 --> 00:05:14,240
分给了 j_i

134
00:05:14,240 --> 00:05:18,440
那 j_i 就是从 j_o 到  j_o + T 进行处理

135
00:05:18,440 --> 00:05:19,960
那这一个数据的内容

136
00:05:19,960 --> 00:05:24,400
可能就是完完全全能够塞到处理器里面

137
00:05:24,400 --> 00:05:26,560
而不会导致我们在迭代的时候

138
00:05:26,560 --> 00:05:28,080
出现 cache mission

139
00:05:28,080 --> 00:05:30,480
然后系统或者芯片

140
00:05:30,480 --> 00:05:33,640
只能重新的去把数据进行调入调出

141
00:05:33,640 --> 00:05:36,840
然后把以前过去的数据又把它拿回来

142
00:05:36,840 --> 00:05:39,440
这种方式能够最大程度的去利用

143
00:05:39,440 --> 00:05:42,680
我们芯片的一个内存空间

144
00:05:42,680 --> 00:05:45,040
那下面有两个问题

145
00:05:45,040 --> 00:05:47,000
想跟大家探讨一下

146
00:05:47,000 --> 00:05:49,520
（变声期）
就是我们刚才讲的还是很简单

147
00:05:49,560 --> 00:05:51,240
但是一般的处理器

148
00:05:51,240 --> 00:05:54,520
例如 CPU GPU 或者 NPU 昇腾

149
00:05:54,520 --> 00:05:57,200
都会有多级的缓存

150
00:05:57,200 --> 00:06:00,440
那 Tiling 如何对应到多级的缓存里面呢

151
00:06:00,440 --> 00:06:02,600
这个问题是很有意思

152
00:06:02,600 --> 00:06:04,560
第二个问题就是 AI 编译器

153
00:06:04,560 --> 00:06:06,190
一般来说我们大部分时间

154
00:06:06,190 --> 00:06:08,000
都在处理张量的数据

155
00:06:08,000 --> 00:06:11,000
那张量的数据的排布本来就很复杂

156
00:06:11,000 --> 00:06:13,360
我们要迭代或者处理一个张量的数据

157
00:06:13,360 --> 00:06:17,320
就可能要非常多的 for 循环去迭代

158
00:06:17,360 --> 00:06:19,440
这个时候 AI 编译器或者我们

159
00:06:19,440 --> 00:06:22,880
即使是员工自己去写 Kernel 的算子也好

160
00:06:22,880 --> 00:06:25,280
面向第一个问题就是多级缓存

161
00:06:25,280 --> 00:06:27,040
还有我们复杂的张量

162
00:06:27,040 --> 00:06:29,240
这里面的如何去对应

163
00:06:29,240 --> 00:06:31,040
对应的难度有多高

164
00:06:31,040 --> 00:06:33,840
那这个是需要大家一起去思考的问题

165
00:06:33,840 --> 00:06:35,920
也是需要我们在实践当中

166
00:06:35,920 --> 00:06:38,040
去一起慢慢的解决的问题

167
00:06:39,480 --> 00:06:39,960
好了

168
00:06:39,960 --> 00:06:44,440
下面我们来看看第三个循环的一个调度策略

169
00:06:44,480 --> 00:06:45,960
就是循环重排

170
00:06:45,960 --> 00:06:47,600
loop reorder

171
00:06:47,600 --> 00:06:49,720
内外层循环的重排

172
00:06:49,720 --> 00:06:53,040
可以有效的去改善我们整个空间的布局性

173
00:06:53,040 --> 00:06:56,400
那这个空间更多的是指内存空间

174
00:06:56,400 --> 00:06:57,678
并且最大限度

175
00:06:57,678 --> 00:07:00,600
去利用了我们 cache 的一个数据

176
00:07:00,600 --> 00:07:03,760
另外一个点就是对循环进行重排

177
00:07:03,760 --> 00:07:06,400
可以有效的减少我们跨步并行访问的模式

178
00:07:06,400 --> 00:07:10,000
还有内存里面数据存储对齐的一个问题

179
00:07:10,000 --> 00:07:12,960
下面我们看看一个循环重排

180
00:07:13,120 --> 00:07:15,840
其实循环重排我们在上一个内容里面

181
00:07:15,840 --> 00:07:17,640
已经详细的去展开过了

182
00:07:17,640 --> 00:07:19,360
这里面我们再带过一下

183
00:07:19,360 --> 00:07:22,120
就我们假设现在有两个循环

184
00:07:22,120 --> 00:07:22,880
一个是 for i

185
00:07:22,880 --> 00:07:23,960
一个是 for j

186
00:07:23,960 --> 00:07:26,080
那这个时候我做一个简单的计算

187
00:07:26,080 --> 00:07:28,600
A(i, j) = B(i, j) * C(i, j)

188
00:07:28,600 --> 00:07:30,880
那我们循环里面都用到 i, j

189
00:07:30,880 --> 00:07:32,600
只是访问的矩阵不同

190
00:07:32,600 --> 00:07:35,760
但是假设我的 m 特别特别的大

191
00:07:35,760 --> 00:07:37,040
假设有一万

192
00:07:37,040 --> 00:07:39,160
那这个时候我们需要把这里面的数据

193
00:07:39,160 --> 00:07:40,640
全都塞到 cache 里面

194
00:07:40,680 --> 00:07:42,720
才能够让通信

195
00:07:42,720 --> 00:07:44,640
或者异步开销更小

196
00:07:44,640 --> 00:07:45,880
那这个其实是很难

197
00:07:45,880 --> 00:07:47,880
假设我的 cache 放不下怎么办呢

198
00:07:47,880 --> 00:07:49,800
于是我们可以这么去操作

199
00:07:49,800 --> 00:07:53,120
把一万挪到外层循环

200
00:07:53,120 --> 00:07:54,120
把这个 n 呢

201
00:07:54,120 --> 00:07:55,480
把我们以前的外层循环

202
00:07:55,480 --> 00:07:58,560
可能会比较小的挪到里面

203
00:07:58,560 --> 00:08:00,520
假设这个 n 只有 100

204
00:08:00,520 --> 00:08:03,240
那刚好对应 cache 的空间是相同

205
00:08:03,240 --> 00:08:05,640
每一次我就把所有的 cache 都拉进来

206
00:08:05,640 --> 00:08:06,480
然后去计算

207
00:08:06,480 --> 00:08:09,280
这个时候就提高了我们 cache 的命中率

208
00:08:09,320 --> 00:08:10,800
提高了 cache 的命中率了

209
00:08:10,800 --> 00:08:14,280
就有效的提高了我们整个芯片的使用率

210
00:08:14,280 --> 00:08:17,200
和流水线的一个满载负荷

211
00:08:17,200 --> 00:08:18,920
接下来我们看第四个内容

212
00:08:18,920 --> 00:08:22,400
就是循环融合 loop fusion

213
00:08:22,400 --> 00:08:23,880
循环融合呢很简单

214
00:08:23,880 --> 00:08:25,168
我们把相邻或者

215
00:08:25,168 --> 00:08:27,400
紧密相间的一些循环

216
00:08:27,400 --> 00:08:28,600
把它合并到一起

217
00:08:28,600 --> 00:08:30,040
就是可能会有两个循环

218
00:08:30,040 --> 00:08:32,320
我们把两个循环变成一个循环

219
00:08:32,320 --> 00:08:34,320
减少了我们循环的开销

220
00:08:34,320 --> 00:08:37,720
还有增加了我们计算的一个密集度

221
00:08:37,720 --> 00:08:38,600
那这种方式呢

222
00:08:38,600 --> 00:08:42,680
可以有效的改善我们整个软件的一个流水线

223
00:08:42,680 --> 00:08:43,400
另外的话

224
00:08:43,400 --> 00:08:46,320
数据结构的缓存局部性也会增加

225
00:08:46,320 --> 00:08:47,984
那我们看看循环融合

226
00:08:47,984 --> 00:08:50,640
具体做了哪些工作

227
00:08:50,640 --> 00:08:51,160
下面呢

228
00:08:51,160 --> 00:08:53,480
我们以一个 demo 来作为一个例子

229
00:08:53,480 --> 00:08:54,760
这里面有两个 for

230
00:08:54,760 --> 00:08:57,400
第一个 for 呢是 for i = 0, n

231
00:08:57,400 --> 00:09:00,320
那第二个 for 呢是 for i = 1, n - 1

232
00:09:00,320 --> 00:09:03,200
那我们可以看到两个 for 其实有一点区别

233
00:09:03,200 --> 00:09:05,520
第一个 for 呢是从 0 到 n

234
00:09:05,520 --> 00:09:08,160
第二个 for 呢是从 1 到 n-1

235
00:09:08,160 --> 00:09:09,920
那我们在计算的时候呢

236
00:09:09,920 --> 00:09:11,800
可能迭代的数据就不一样了

237
00:09:11,800 --> 00:09:13,237
但这里面的更多的是算

238
00:09:13,237 --> 00:09:16,360
A(i) 和 C(i)还有 D(i)

239
00:09:16,360 --> 00:09:17,120
我们可以看到

240
00:09:17,120 --> 00:09:19,840
因为我们第六行的 i 的遍历的次数呢

241
00:09:19,840 --> 00:09:22,520
跟我们第二个遍历的次数是不一样

242
00:09:22,520 --> 00:09:25,320
所以我们可能需要去进行一个补位

243
00:09:25,320 --> 00:09:26,360
那补完位之后呢

244
00:09:26,360 --> 00:09:28,200
我们再进行一个迭代

245
00:09:28,200 --> 00:09:30,520
for i 等于 1 到 n-1

246
00:09:30,520 --> 00:09:32,600
就是跟第六行对齐

247
00:09:32,600 --> 00:09:36,480
把一开始的 0 和 n 先把它算出来之后呢

248
00:09:36,480 --> 00:09:39,200
在我们循环迭代里面就 17 18 19

249
00:09:39,200 --> 00:09:41,240
再去算具体的值

250
00:09:41,240 --> 00:09:44,560
这种方式呢就可以有效的减少我们循环的次数

251
00:09:44,560 --> 00:09:47,760
增加我们软件的流水线的一个并行的效率

252
00:09:47,760 --> 00:09:49,560
当然了这里面值得注意的就是

253
00:09:49,560 --> 00:09:51,400
这里面的计算的数据啊

254
00:09:51,400 --> 00:09:53,639
也是需要跟 cache 满足

255
00:09:53,639 --> 00:09:55,280
最大的一个空间以内

256
00:09:55,280 --> 00:09:58,960
我们才能够提高我们数据的命中率

257
00:09:58,960 --> 00:09:59,480
好了

258
00:09:59,480 --> 00:10:03,480
最后呢就是第五个循环拆分 loop split

259
00:10:03,480 --> 00:10:05,240
那循环拆分呢很简单了

260
00:10:05,240 --> 00:10:08,320
说到拆分就是把一个循环或者多个循环

261
00:10:08,320 --> 00:10:10,760
拆分成更多个循环

262
00:10:10,760 --> 00:10:13,440
那这里面呢分为有条件的循环

263
00:10:13,440 --> 00:10:15,520
还有没条件的循环

264
00:10:15,520 --> 00:10:18,000
这个条件呢是控制流

265
00:10:18,000 --> 00:10:22,160
if else while 这种我们叫做条件循环

266
00:10:22,160 --> 00:10:24,360
那下面我们来看一个具体的例子

267
00:10:24,360 --> 00:10:30,000
那假设呢我现在有一个迭代叫做 for i = 0, n

268
00:10:30,000 --> 00:10:32,880
我们在 for 遍历的时候呢去算 a 和 c

269
00:10:32,960 --> 00:10:36,080
但是有个问题就是这里面呢有个控制流

270
00:10:36,080 --> 00:10:38,560
叫 temp[i] > data 的时候呢

271
00:10:38,560 --> 00:10:41,520
我的 d(i)去重新的赋值

272
00:10:41,520 --> 00:10:43,640
那我们在循环拆分之后呢

273
00:10:43,640 --> 00:10:46,720
我第一个迭代的时候这里面拆成两个 for

274
00:10:46,720 --> 00:10:47,840
两个 loop

275
00:10:47,840 --> 00:10:50,600
那第一个 loop 的时候呢比较简单

276
00:10:50,600 --> 00:10:51,800
那第一个迭代的时候呢

277
00:10:51,800 --> 00:10:53,240
我不管里面的 for 了

278
00:10:53,240 --> 00:10:54,680
在 GPU NPU

279
00:10:54,680 --> 00:10:57,400
在一些能够处理并行的处理器当中啊

280
00:10:57,400 --> 00:10:59,480
它是不善于去处理控制流

281
00:10:59,480 --> 00:11:01,976
更多的是善于做一些

282
00:11:01,976 --> 00:11:03,640
循环和并行的操作

283
00:11:03,640 --> 00:11:05,560
虽然我们把这个拆出来

284
00:11:05,560 --> 00:11:08,280
把一些能够快速的计算的工作呢

285
00:11:08,280 --> 00:11:09,760
快速的并行的工作呢

286
00:11:09,760 --> 00:11:11,480
交给我们第一个循环

287
00:11:11,480 --> 00:11:13,600
接着呢可能 15 到 17 行

288
00:11:13,600 --> 00:11:16,640
在我们真正的硬件上面呢执行的非常慢

289
00:11:16,640 --> 00:11:18,520
我们把它单独拿出来

290
00:11:18,520 --> 00:11:21,760
然后呢去单独的去判断单独的执行

291
00:11:21,760 --> 00:11:24,760
那这个时候呢就可以有效的加快我们整体

292
00:11:24,760 --> 00:11:27,080
处理器的运算的效率

293
00:11:27,120 --> 00:11:29,840
好了今天的内容呢就到这里为止

294
00:11:31,760 --> 00:11:36,040
今天呢主要是给大家汇报了一下我们 OPS Optimizer

295
00:11:36,040 --> 00:11:39,400
AI 编译器后端优化里面的一些循环展开

296
00:11:39,400 --> 00:11:41,400
循环分块、循环重排

297
00:11:41,400 --> 00:11:43,240
循环融合和拆分

298
00:11:43,240 --> 00:11:44,360
这五大个内容

299
00:11:44,360 --> 00:11:46,880
当然了这五大个内容你可以单独去使用

300
00:11:46,880 --> 00:11:50,560
但是呢我们将会在后面的章节里面去讲讲

301
00:11:50,560 --> 00:11:51,800
Auto Tuning

302
00:11:51,800 --> 00:11:53,240
还有 polyhedral

303
00:11:53,240 --> 00:11:56,920
怎么对它进行一个自动化的使用

304
00:11:56,920 --> 00:11:57,920
好了谢谢各位

305
00:11:58,038 --> 00:12:06,307
(片~尾~ 记得一键三连+关注下期视频再见)