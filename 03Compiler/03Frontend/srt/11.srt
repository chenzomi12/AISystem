1
00:00:00,000 --> 00:00:04,566
字幕生成：qiaokai 字幕校对：mkwei

2
00:00:06,533 --> 00:00:08,533
嗨大家好我是 ZOMI

3
00:00:08,600 --> 00:00:10,100
今天呢这是一个

4
00:00:10,866 --> 00:00:12,299
额外加的鸡腿

5
00:00:12,300 --> 00:00:14,600
AI 编译器系列的前端优化

6
00:00:14,600 --> 00:00:17,200
里面单独提了一个 summary

7
00:00:17,333 --> 00:00:19,499
summary 里面主要讲啥内容呢

8
00:00:20,266 --> 00:00:22,899
有一个同学问我前端这么多优化

9
00:00:22,900 --> 00:00:24,200
这么多不同的 pass

10
00:00:24,266 --> 00:00:26,266
到底哪个在先哪个在后

11
00:00:26,266 --> 00:00:27,499
有没有固定的顺序

12
00:00:27,500 --> 00:00:29,966
或者一些比较好的参考资料呢

13
00:00:35,566 --> 00:00:37,866
那这里面呢我想回答这个问题

14
00:00:37,966 --> 00:00:39,199
所以加了一节鸡腿

15
00:00:39,200 --> 00:00:40,933
首先我们搞清楚几个概念

16
00:00:40,933 --> 00:00:42,699
我们讲的前端优化

17
00:00:42,700 --> 00:00:45,200
图层优化还有计算图的优化呢

18
00:00:45,200 --> 00:00:46,766
都是相同的概念

19
00:00:46,766 --> 00:00:48,466
在 AI 编译器

20
00:00:48,666 --> 00:00:51,066
都是指的相同的一个概念

21
00:00:53,000 --> 00:00:54,933
在整个 AI 编译器里面呢

22
00:00:54,933 --> 00:00:56,299
 AI 框架

23
00:00:56,300 --> 00:00:58,400
前端对 Python 的代码解析

24
00:00:58,466 --> 00:00:59,899
变成一个计算图

25
00:00:59,900 --> 00:01:01,100
那这个计算图呢

26
00:01:01,100 --> 00:01:03,100
传给整个 AI 编译器呢

27
00:01:03,100 --> 00:01:04,733
我们叫做前端优化

28
00:01:04,733 --> 00:01:06,566
也可以叫做图层优化

29
00:01:06,566 --> 00:01:08,266
或者计算图的优化啊

30
00:01:08,266 --> 00:01:10,599
这里面呢先不要管右边的这些内容

31
00:01:10,600 --> 00:01:11,733
可能会有错误

32
00:01:11,766 --> 00:01:12,266
但是呢

33
00:01:12,266 --> 00:01:14,933
我们现在处在红色框所在的位置

34
00:01:15,000 --> 00:01:17,166
这些 pass 它是有一定的顺序

35
00:01:17,200 --> 00:01:19,466
但是呢没有一个完全固定的顺序

36
00:01:20,000 --> 00:01:22,533
我们往下看一下正式的一个目录

37
00:01:22,600 --> 00:01:25,733
当时设计的时候呢分开了左右两边

38
00:01:25,733 --> 00:01:26,733
那左边呢

39
00:01:26,733 --> 00:01:29,999
更关注的就是神经网络相关的优化

40
00:01:30,000 --> 00:01:32,333
就跟神经网络更相关

41
00:01:32,333 --> 00:01:35,066
而这里面呢其实是有一定的顺序

42
00:01:35,066 --> 00:01:37,166
但这些顺序呢不一定对

43
00:01:37,166 --> 00:01:39,466
所以呢是给大家做一个参考

44
00:01:40,166 --> 00:01:42,666
首先第一步就是计算图传进来之后呢

45
00:01:42,666 --> 00:01:44,566
其实我们有非常多的散的算子

46
00:01:44,566 --> 00:01:45,666
或者小的算子

47
00:01:45,766 --> 00:01:48,499
最重要的一个加速功能就是融合算子

48
00:01:48,500 --> 00:01:50,733
把一些小的算子变成一个大算子

49
00:01:50,733 --> 00:01:51,699
所以算子融合了

50
00:01:51,700 --> 00:01:54,400
一般来说我都会把它排在前面

51
00:01:54,600 --> 00:01:56,166
融合了新的算子之后呢

52
00:01:56,166 --> 00:01:59,133
我们就会产生新的算子新的大算子

53
00:01:59,200 --> 00:02:01,466
而新的算子不同的算子之间

54
00:02:01,533 --> 00:02:03,866
它的数据内存排布是不同

55
00:02:03,866 --> 00:02:05,866
所以接着呢有了新的算子之后

56
00:02:05,866 --> 00:02:07,866
我们需要对数据内存排布

57
00:02:07,933 --> 00:02:09,166
进行一个转换

58
00:02:09,400 --> 00:02:10,866
使得我们这个计算图呢

59
00:02:10,866 --> 00:02:12,533
是符合真正运行的时候

60
00:02:12,533 --> 00:02:14,799
计算图有了真正运行

61
00:02:14,800 --> 00:02:16,466
能够运行的计算图之后呢

62
00:02:16,466 --> 00:02:18,933
就需要对这个计算图的动态内存

63
00:02:18,966 --> 00:02:20,099
和静态内存

64
00:02:20,266 --> 00:02:21,933
进行一个合理的分配

65
00:02:22,100 --> 00:02:24,700
于是呢我们就来到了内存分配

66
00:02:24,700 --> 00:02:26,966
memory allocation 这个内容

67
00:02:26,966 --> 00:02:30,166
所以说算子融合布局转换内存分配

68
00:02:30,166 --> 00:02:32,799
这三个呢都是跟神经网络相关

69
00:02:32,800 --> 00:02:35,566
而这三个呢其实是有一定的关联顺序

70
00:02:38,066 --> 00:02:38,966
下面我们来看看

71
00:02:38,966 --> 00:02:41,966
刚才讲的更多的是一个训练的场景

72
00:02:41,966 --> 00:02:43,733
其实在推理场景里面呢

73
00:02:43,733 --> 00:02:46,399
因为我们训练的框架可以用 PyTroch

74
00:02:46,400 --> 00:02:47,333
可以用 MindSpore

75
00:02:47,366 --> 00:02:48,466
可以用 TensorFlow

76
00:02:48,800 --> 00:02:51,700
不同的 AI 框架呢有不同的算子的定义

77
00:02:51,800 --> 00:02:53,666
在推理框架里面呢

78
00:02:53,666 --> 00:02:56,199
可能就会多了这么一层算子替换

79
00:02:56,300 --> 00:02:58,066
有时候算子的替换呢

80
00:02:58,133 --> 00:03:01,066
也可以在我们训练的 AI 编译器里面实现

81
00:03:01,733 --> 00:03:03,999
所以说他们之间没有一个明确的 gap

82
00:03:04,000 --> 00:03:06,800
和定义但是呢有一定的规律顺序

83
00:03:06,866 --> 00:03:09,733
那接着我们看看右边这一部分

84
00:03:09,733 --> 00:03:12,333
右边这部分呢我们看到的常量折叠呀

85
00:03:12,366 --> 00:03:15,133
公共子表达式消除死代码消除

86
00:03:15,133 --> 00:03:16,166
代数简化

87
00:03:16,366 --> 00:03:17,366
这些内容呢

88
00:03:17,366 --> 00:03:20,799
更偏向于我们对代码层面对计算层面

89
00:03:20,800 --> 00:03:21,900
对数学层面

90
00:03:21,900 --> 00:03:24,466
对代数层面进行的一些优化

91
00:03:24,500 --> 00:03:25,666
那这些优化呢

92
00:03:25,666 --> 00:03:28,866
跟传统编译器的概念呢更加相像

93
00:03:29,133 --> 00:03:31,766
也是把传统编译器一些优化的 pass 呢

94
00:03:31,766 --> 00:03:33,733
往计算图上面去套

95
00:03:33,733 --> 00:03:35,933
或者往我们计算图上面去迁移

96
00:03:35,966 --> 00:03:38,966
那这种优化的 pass 呢是往后排

97
00:03:40,500 --> 00:03:41,166
常量折叠

98
00:03:41,166 --> 00:03:42,466
我把它往前排

99
00:03:42,466 --> 00:03:44,199
是因为我们在推理场景里面呢

100
00:03:44,200 --> 00:03:45,400
经常会用到

101
00:03:45,400 --> 00:03:47,366
而且使用的概率非常高

102
00:03:47,366 --> 00:03:49,066
有可能我能够容忍

103
00:03:49,066 --> 00:03:51,533
一些公共子表达是没有消除掉

104
00:03:51,533 --> 00:03:54,266
但是呢常量折叠确实给性能

105
00:03:54,266 --> 00:03:55,866
带来很大的收益

106
00:03:55,866 --> 00:03:57,999
而且它跟神经网络呢其实是

107
00:03:58,300 --> 00:03:59,533
呃比较相关

108
00:03:59,533 --> 00:04:00,266
但它属于

109
00:04:00,266 --> 00:04:02,333
代数或者计算层面的一个优化

110
00:04:02,333 --> 00:04:04,199
所以把它摆在第一的位置

111
00:04:05,500 --> 00:04:06,266
接下来呢

112
00:04:06,266 --> 00:04:08,199
更多的是公共子表达式消除

113
00:04:08,200 --> 00:04:09,933
和代数的简化

114
00:04:09,933 --> 00:04:12,399
这两个呢其实没有明确的上下关系

115
00:04:12,400 --> 00:04:14,000
他们两个可以互相调用

116
00:04:14,066 --> 00:04:17,133
放在最后的应该是死代码的消除

117
00:04:17,133 --> 00:04:19,699
那死代码的消除我觉得是必须要有

118
00:04:19,700 --> 00:04:21,966
而且放在最后可能会更加合理

119
00:04:21,966 --> 00:04:24,133
把一些没有用的冗余的代码

120
00:04:24,166 --> 00:04:25,499
我们把它干掉

121
00:04:25,700 --> 00:04:27,333
虽然叫死代码消除

122
00:04:27,333 --> 00:04:28,099
但实际上

123
00:04:28,100 --> 00:04:30,266
它消除的是计算的节点

124
00:04:32,266 --> 00:04:34,499
现在了解完我们整个 AI 编译器

125
00:04:34,500 --> 00:04:35,700
的前端优化之后呢

126
00:04:35,700 --> 00:04:36,966
我们将会在后面

127
00:04:36,966 --> 00:04:40,466
去详细的展开 AI 编译器的后端的优化

128
00:04:40,466 --> 00:04:43,333
去了解一下我们后端到底有哪些

129
00:04:43,333 --> 00:04:44,566
好玩的东西

130
00:04:45,166 --> 00:04:46,799
有哪些核心的基础点

131
00:04:46,800 --> 00:04:48,000
好了谢谢各位

132
00:04:48,100 --> 00:04:49,000
拜了个拜

133
00:04:49,166 --> 00:04:50,933
卷的不行了卷的不行了

134
00:04:50,933 --> 00:04:52,666
记得一键三连加关注哦

135
00:04:52,733 --> 00:04:54,099
所有的内容都会开源

136
00:04:54,100 --> 00:04:55,900
在下面这条链接里面

137
00:04:56,333 --> 00:04:57,266
拜了个拜

