<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/microsoft/AI-System/blob/main/LICENSE)版权许可-->

# 1.3 深度学习系统组成与生态

就如 Jeff Dean 所描述的那样--过去是深度学习计算机系统和应用的黄金十年 “[A Golden Decade of Deep Learning: Computing Systems & Applications](https://direct.mit.edu/daed/article/151/2/58/110623/A-Golden-Decade-of-Deep-Learning-Computing-Systems)”[<sup>[1]</sup>](#goldenage)。

通过之前深度学习的发展介绍，以及模型，硬件与框架的趋势介绍，我们已经了解了深度学习系统的重要性。那么本章将介绍深度学习系统的设计目标，组成和生态，让读者形成人工智能系统的知识体系，为后续展开每个章节的内容做好铺垫。

- [1.3 深度学习系统组成与生态](#13-深度学习系统组成与生态)
  - [1.3.1 深度学习系统的设计目标](#131-深度学习系统的设计目标)
  - [1.3.2 深度学习系统的大致组成](#132-深度学习系统的大致组成)
  - [1.3.3 深度学习系统生态](#133-深度学习系统生态)
  - [小结与讨论](#小结与讨论)
  - [参考文献](#参考文献)

## 1.3.1 深度学习系统的设计目标

深度学习系统的设计目标我们可以总结为以下几个部分。

- 提供更加高效的编程语言、框架和工具：
  - 设计更具表达能力和简洁的神经网络计算原语和编程语言。让用户能够提升开发效率，屏蔽底层细节，更灵活的原语支持。当前深度学习模型除了特定领域模型的算子和流程可以复用（例如，语言模型在自然语言处理领域被广泛作为基础结构），其新结构新算子的设计与开发仍遵循试错（Trial And Error）的方式进行，那么如何灵活表达新的算子，算子间的组合形式，屏蔽经典熟知的算子与基础模型，是算法工程师所需要语言，库与框架层所提供的功能支持。
  - 更直观的编辑、调试和实验工具。让用户可以完整的开发，测试，调整诊断与修复和优化程序，提升所开发深度学习程序的性能与鲁棒性。训练过程不是一蹴而就，其中伴随着不收敛，NaN，内存溢出等算法问题与系统缺陷（Bug），工具与系统本身如何在设计之初就考虑到这点，提供良好的可观测性，可调试性，允许用户注册自定义扩展等支持是需要工具与系统设计者所需要在系统设计之初就需要提上日程的，否则之后更多是缝缝补补造成不好的开发体验与不能满足的需求，对用户来说就像使用一个黑盒且单片的工具。
  - 支持深度学习生命周期中的各个环节：模型压缩、推理、安全、隐私保护等。不仅能构建深度学习模型，能够支持全生命周期的深度学习程序开发，并在系统内对全生命周期进行分析与优化。当前的深度学习工程化场景，已经不是灵感一现单一的优化就能迅速取得领先优势，更多的是能否有完善的基础设施，快速复现社区工作，批量验证新的想法进行试错，所以一套好的完善的全流程的生命周期管理能够大幅度提升深度学习算法层面的生产力。
- 提供全面多样的深度学习任务需求的系统支持：
  - 除了传统的深度学习训练与推理的支持，还能支持强化学习、自动化机器学习等新的训练范式。除了推理需求之外，训练作业中新的范式层出不穷，例如，需要不断和环境或模拟器交互以获取新数据的强化学习方式，批量大规模提交搜索空间的自动化机器学习方式等，这些新的范式造成对之前单一支持单模型之外，在多模型层面，训练与推理任务层面产生了新的系统抽象与资源，作业管理需求。
  - 提供更强大和可扩展的计算能力。让用户的深度学习程序可扩展并部署于可以并行计算的节点或者集群，应对大数据和大模型的挑战。因为当前深度学习模型不断通过大模型层数更多的模型产生更好的算法层面的效果，促使系统需要支持更大的模型，同时由于企业 IT 基础设施不但完善，能够不断沉淀新的数据，也会伴随着大数据的问题。大模型与大数据促使存储与计算层面系统在摩尔定律失效的大背景下迫切需要通过并行与分布式计算的范式扩展算力与存储的支持。
  - 自动编译优化算法，包括不限于：
    - 自动推导计算图：尽可能的通过符号执行或即时编译技术，获取更多的计算图信息，进而数据驱动方式做定制化的优化。
    - 根据不同体系结构自动并行化：面对部署场景的多样化体系结构，训练阶段异构硬件的趋势，框架让用户透明的进行任务放置，并行化，以期以最为优化的方式在指定硬件配置下，并行化与减少 I/O，逼近硬件提供的性能上限。
    - 自动分布式化，并扩展到多个计算节点：面对云与集群场景，如何自动将任务扩展与部署，进而支撑分布式计算，弹性计算，让用户按需使用资源，也是云原生背景下，人工智能系统所需要考虑和支持的。
    - 持续优化：由于深度学习训练作业是迭代且周期较长，给系统以内省优化的机会，即不断监控，不断优化当前系统配置与运行时策略，以期弥补纯静态优化获取信息不足，运行时干扰造成的相比最优化的策略的差距。
- 探索并解决新挑战下的系统设计、实现和演化的问题。例如：动态性的支持，利用稀疏性进行加速优化，混合精度训练与部署，混合训练范式（强化学习），多任务（自动化机器学习）等。
- 提供在更大规模的企业级环境的部署需求：
  - 多租环境的训练部署需求：面对多组织，多工程师共享集群资源，以及大家迫切使用 GPU 资源的日益增长的需求，如何提供公平，稳定，高效的多租环境也是平台系统需要首先考虑的。
  - 跨平台的推理部署需求：面对割裂的边缘侧硬件与软件栈，如何让模型训练一次，跨平台部署到不同软硬件平台，也是推理场景需要解决的重要问题。
  - 安全与隐私的需求：由于深度学习模型类似传统程序的功能，接受输入，处理后产生输出，但是相比传统程序，其解释性差，造成更容易产生安全问题，容易被攻击。同时模型本身的重要信息为权重，我们也要注意模型本身的隐私保护。同时如果是企业级环境或公有云环境，会有更高的安全和隐私保护要求。

有了宏观的目标，我们下一步进一步了解，当前的整个生态中整体的人工智能系统的技术栈是如何构成的，整个技术栈中各类人工智能系统处于哪个抽象层次，互相之间的关系是什么。

## 1.3.2 深度学习系统的大致组成

如图1-3-1所示，我们大致可以将深度学习系统分为以下方向：

- 开发体验层：负责提供用户前端的编程语言，接口和工具链。本层尽可能让用户表达目标任务与算法，尽量少让用户关注底层实现（例如，通过声明式编程的方式）是提升开发体验的较好的手段，但是过度的抽象会丧失灵活性的表达，在模型发展较快迭代频繁的时期用户还需要体验层兼顾灵活性和可调试性。开发体验层会调用，编排底层框架的接口提供更加简洁的用户开发体验。包括并不限于以下领域：
  - 模型构建：卷积，循环神经网络，控制流等基本结构和算子支持与实现。语言的基本语法和框架的 API 接口提供基本算子的支持，当前主要以在 Python 语言内内嵌调用深度学习框架的方式进行深度学习模型的开发，但是也出现控制流在原生语言层与模型中间表达割裂等问题。
  - 算法实现：同步与异步优化算法等。算法一般被封装为框架的配置或 API 供用户选择，有些框架也提供拦截接口给用户一定程度灵活性定制自定义算法。
  - 流水线和工作流支持：高性能数据加载器等。流水线和工作流是实现模块解耦复用，可视化编程的前提，通过复用与可视化编程可以大幅降低组织内作业书写的门槛。
  - 实验规划与配置：批量超参数调优与模型结构搜索等。由于当前模型试错（Trial And Error）的开发模式，让算法工程师在设计模型过程中有大量的超参数与模型结构需要尝试，自动化机器学习工具应运而生。
  - 工具链: 模型转换，调试，可视化，类型系统等。就像传统的软件工程中调试器，可视化，类型系统等工具链的支撑，让整个开发过程中，跨平台，跨平台，问题诊断，缺陷验证等得以高效实现，目前深度学习系统领域也不断有类似工具产生以支持整个深度学习工程化实践。
  - 生命周期管理：数据读取，训练与推理等流程开发与管理。机器学习领域的 DevOps 也就是 MLOps 的基础工具支持。其可以让重复模块被复用，同时让底层工具有精确的信息进行模块间的调度与多任务的优化，同时让各个环节模块化解耦，独立和更为快速的演进。
- 框架层：负责静态程序分析与计算图构建，编译优化等。框架本身通过提供供用户编程的 API 获取用户表达的模型，数据读取等意图，在静态程序分析阶段完成尽可能的自动前向计算图构建，自动求导补全反向传播计算图，计算图整体编译优化，算子内循环编译优化等。包括并不限于以下领域：
  - 计算图构建：静态，动态计算图构建等。不同的框架类型决定了其使用静态还是动态图进行构建，静态图有利于获取更多信息做全图优化，动态图有利于调试。
  - 自动求导：高效与高精度自动求导等。由于深度学习模型中大部分算子较为通用，框架提前封装好算子的自动求导函数，待用户触发训练过程自动透明的进行全模型的自动求导，以支持梯度下降等训练算法需要的权重梯度数据的获取。
  - 中间表达构建：多层次中间表达等。通过构建深度学习模型的中间表达及多层中间表达，让模型本身可以更好的被编译器编译生成高效的后端代码。
  - 编译优化：内核融合等。编译器或框架根据算子的语义，对适合进行内核融合（例如，多个算子和并为一个算子）进行融合，降低内核启动与访存代价。同时深度学习编译器还支持循环优化等类似传统编译器的优化策略和面向深度学习的优化策略（例如，牺牲一定精度的计算图等价代换等）。
- 运行时：负责系统的运行时的系统动态调度与优化。当获取的深度学习模型计算图部署于单卡，多卡或分布式的环境，运行期的框架需要对整体的计算图按照执行顺序调度算子与任务的执行，多路复用资源，做好内存等资源的分配与释放。包括并不限于以下部分。
  - 优化器：运行时即时（Just-in-Time）优化，内省（Introspective）优化等。运行时根据硬件，隐藏的软件栈信息，数据分布等只能运行时所获取的信息，进一步对模型进行优化。
  - 调度器：算子并行与调度。根据设备提供的软件栈和硬件调度策略，以及模型的算子间并行机会，进行类装箱的并行调度。
  - 执行器：多线程等。算子执行过程中，如果特定设备没有做过多的运行时调度与干预，框架可以设计高效的运行时算子内的线程调度策略。
- 资源管理与硬件体系结构：负责程序的执行，互联与加速。在更广的层面，作业与作业间需要平台提供调度，运行期资源分配与环境隔离。包括并不限于以下部分：
  - 硬件接口抽象：GPU，CPU，FPGA 和 ASIC 等。统一的硬件接口抽象可以复用编译优化策略，让优化与具体底层设备和体系结构适当解耦。
  - 资源池化管理与调度：异构资源集群管理等。将服务器资源池化，通过高效的调度器结合深度学习作业特点和异构硬件拓扑进行高效调度。
  - 可扩展的网络栈：RDMA，InifiBand，NVLink 等。提供更高效的加速器到加速器的互联（例如，NVLink 等），更高的带宽，更灵活的通信原语与高效的通信聚合算法（例如，AllReduce 算法）。

<center><img src="./img/3/3-3-1-dl-sys-stack.png" /></center>
<center>图 1.3.1 深度学习系统的大致组成</center>

我们将图 1.3.1 中的大致组成可以进一步细化为图 1.3.2 深度学习系统详图，由于篇幅所限其中还有很多系统技术点与方向没有罗列，我们将在后续对应章节详细介绍。我们可以看到深度学习系统整体的技术栈包罗万象且复杂，且由硬件到软件层有多个层次，形成系统化和层次化看系统的视角对未来理解程序是如何在底层系统执行，并做系统性能预估与技术选型至关重要。

<center><img src="./img/3/3-3-3-deeplearningsysstack.png" /></center>
<center>图 1.3.2 深度学习系统详图</center>

## 1.3.3 深度学习系统生态

除了以上重要的深度学习系统构成之外，随着人工智能应用越来越广泛，我们还可以看到更广泛的人工智能系统生态的构成。如图 1.3.3 所示，其中包含以下领域：

- 核心系统软硬件：通过核心系统软硬件，底层的基础架构已经可以给上层提供算力，存储，网络等资源池，可以按需给需要执行的深度学习作业隔离出指定规格的资源，执行深度学习作业，类似传统操作系统已经完成底层硬件的抽象与资源隔离，只需要用户的应用提交到系统中被执行和管理。
  - 深度学习任务运行和优化环境：提供更高的运行时性能，资源隔离与调度。当深度学习作业启动，深度学习框架或运行时提供更好的算子与任务调度，内存管理，I/O 管理，甚至未来随着作业愈发复杂，提供作业的多路复用（Multiplexing）等支持，打破设备商运行时库封装的局限性。
  - 通用资源管理和调度系统：提供更公平，高效率和稳定的平台支持。性能并不是系统设计本身的唯一考虑因素，在多租环境，还要兼顾公平，效率和稳定性，为用户提供更加可靠好用的平台。
  - 新型硬件及相关高性能网络和计算栈：随着加速器技术不断发展，网络互连技术提供更高的带宽，硬件层提供更高的算力与带宽支持模型训练与推理。系统需要更加灵活的支持在不同的硬件和规格假设下，不同作业如何静态与动态结合的自动优化与高性能执行。同时由于硬件的发展趋势不同，潜在可能会让性能瓶颈产生变化，系统设计较早判断并对应设计会产生新的系统设计机会。
- 深度学习算法和框架：通过深度学习算法与框架，用户可以表达模型设计和训练配置等需求，就像给提供了一套特定领域的“编程语言”，并且提供了相应的编译器及工具链可以翻译成运行时软硬件环境可以执行的指令。
  - 广泛用途的高效新型通用 AI 算法：提供更多样的模型支持，推进和支持模型效果的提升。支持新的算子（例如，控制流等），更加灵活的模型结构（例如，图模型等），模型的融合（例如，多专家系统等）支持。
  - 多种深度学习框架的支持与进化：由于多种框架与工具的存在，如何为用户提供更多样的框架的统一支持与优化对提升用户体验，复用已有代码有很强的实用价值。
  - 深度神经网络编译架构及优化：在编译期，通过静态分析与优化的方法，提供更优化的编译支持，提升模型的性能，正确性等。类似传统编译器，深度学习模型的计算图可以通过融合等手段优化，算子内可以应用大量循环优化。同时面向深度学习模型本身的特点，也逐渐有工作利用一些等价和非等价计算图转换进行优化。
- 更广泛的人工智能系统生态：随着深度学习高速发展，更大的搜索空间，运行时才能获取的数据，模型安全与隐私，部署推理的多样化需求变得日益迫切，我们需要考虑除训练以外更多的人工智能系统问题。
  - 机器学习新模式（例如，强化学习）：提供新训练范式的灵活执行，部署与同步支持等。例如，由于训练数据可能需要以与环境交互的过程中才能获取，造成需要通过强化学习等新的训练范式进行模型训练，需要设计新的系统以支持灵活的训练范式。
  - 自动机器学习（例如自动化机器学习）：当用户想试错（Trial And Error）的搜索空间达到一定量级，用户通过自动化机器学习工具与算法可以更高效的进行模型的探索与训练。自动化机器学习系统可以提供多任务的高效管理与调度支持，支持搜索空间定义的程序语言等。
  - 安全（Security）与隐私（Privacy）：数据与模型，类似传统的信息安全要保护的数据与程序，除了数据本身，模型类似传统程序本身的安全与隐私问题提出了新的挑战。我们需要思考人工智能模型与应用的安全与隐私保护支持。
  - 模型推理（Inference）、压缩（Compression）与优化：如果我们不需要训练，只需要执行前向传播过程，则是用户开始使用模型进行推理，基于深度学习特有性质进行高效的模型部署推理是除我们关注的训练之外的很重要的系统问题。模型推理相比训练有更低的延迟要求，更严苛的资源供给，不需要求解梯度和训练，有更低的精度要求等等，面对新的假设，如何设计面向推理的系统提出了新的机会。同时深度学习模型本身可以通过模型压缩，量化等手段精简计算量与内存消耗，加速模型的部署。

<center><img src="./img/3/3-3-2-dl-ecosystem.png"  /></center>
<center>图 1.3.3 深度学习系统生态</center>

我们将在后续章节围绕核心系统软硬件，深度学习算法和框架，以及更广泛的人工智能系统生态中的重要内容展开介绍。

## 小结与讨论

本章我们主要围绕深度学习系统的组成和生态进行介绍，在初学人工智能系统我们可能会只关注框架，但当我们把系统放眼到整个基础架构，我们会发现当前深度学习系统涉及很多方面，类似传统的操作系统（异构资源管理系统），编译器（深度学习编译优化），Web 服务（推理系统），软件安全（模型安全）等问题在深度学习系统的场景中仍然会遇到，一些经典的理论与系统设计在今天仍然发挥着重要的影响。

在接下来的章节我们将通过一个实例介绍整体的深度学习系统的技术栈，快速了解深度学习系统的核心作用。

请读者思考深度学习系统中有哪些新挑战和问题是传统系统所不具备的？

## 参考文献

<div id="goldenage"></div>

1. [Jeffrey Dean; A Golden Decade of Deep Learning: Computing Systems & Applications. Daedalus 2022; 151 (2): 58–74.](https://direct.mit.edu/daed/article/151/2/58/110623/A-Golden-Decade-of-Deep-Learning-Computing-Systems)