1
00:00:00,000 --> 00:00:04,925
字幕生成：Galaxies     字幕校对：NaHS

2
00:00:04,925 --> 00:00:08,040
Hello 大家好 我是那个不能再吃了不能再吃了

3
00:00:08,040 --> 00:00:10,840
再吃就吃不下甜品的ZMOI了

4
00:00:10,840 --> 00:00:14,960
在这一节里面终于脱离了Kernel 优化里面的卷积优化

5
00:00:14,960 --> 00:00:16,440
那节确实剪的挺痛苦的

6
00:00:16,440 --> 00:00:19,040
里面的图画都我好心酸哦

7
00:00:19,040 --> 00:00:20,560
今天来到一个新的内容

8
00:00:20,560 --> 00:00:22,200
就是内存的布局

9
00:00:22,200 --> 00:00:24,920
内存布局这个内容确实非常重要

10
00:00:24,920 --> 00:00:26,280
不管Kernel 优化也好

11
00:00:26,280 --> 00:00:28,440
只是对数据进行重排

12
00:00:29,440 --> 00:00:31,040
来到一个新的内容

13
00:00:31,040 --> 00:00:32,600
内存的布局

14
00:00:32,600 --> 00:00:34,120
其实在上一节内容里面

15
00:00:34,120 --> 00:00:35,840
讲到的算法的优化

16
00:00:35,840 --> 00:00:37,240
不管是哪种算法的优化

17
00:00:37,240 --> 00:00:40,520
其实都是离不开内存布局的加持

18
00:00:40,520 --> 00:00:42,160
那在这一节里面

19
00:00:42,160 --> 00:00:45,280
主要是看一下内存的布局有哪些不一样

20
00:00:45,280 --> 00:00:49,720
会去讲具体内存布局怎幺去配合Kernel 优化的

21
00:00:49,720 --> 00:00:52,320
下面看一下整个的Kernel 优化

22
00:00:52,320 --> 00:00:54,480
还是在这一个内容里面

23
00:00:54,480 --> 00:00:58,120
而内存的布局也是在这一节内容里面

24
00:00:58,120 --> 00:01:00,120
下面看一下第一个概念

25
00:01:00,120 --> 00:01:02,480
就是内存 memory

26
00:01:02,480 --> 00:01:04,200
memory 有什幺不一样

27
00:01:04,200 --> 00:01:08,600
首先左边的这个图就是 CPU 的一个具体的

28
00:01:08,600 --> 00:01:10,400
或者一个通用的架构

29
00:01:10,400 --> 00:01:14,680
右边的这个图就是 GPU 的一个常用的架构

30
00:01:14,680 --> 00:01:17,920
可以简单的看一下上面两句话

31
00:01:17,920 --> 00:01:21,520
像 RAM 这种的储存是比较大的存储空间

32
00:01:21,520 --> 00:01:25,440
但是读取或者存储的速度是比较慢的

33
00:01:25,480 --> 00:01:27,680
那像 CPU 或者 MPU 里面的 cache

34
00:01:27,680 --> 00:01:30,240
就上面的在 CPU 里面的 cache

35
00:01:30,240 --> 00:01:32,360
存储的速度就要快很多

36
00:01:32,360 --> 00:01:34,360
但是整体的规模就比较少了

37
00:01:34,360 --> 00:01:35,760
而且造价比较贵

38
00:01:35,760 --> 00:01:38,280
因此可以适当的去使用

39
00:01:38,280 --> 00:01:41,840
CPU 或者 MPU 里面的 cache 是非常的重要的

40
00:01:41,840 --> 00:01:45,720
每一次从 RAM 里面或者组存里面去获取数据

41
00:01:45,720 --> 00:01:48,400
CPU 就会将这些数据就把 memory

42
00:01:48,400 --> 00:01:49,920
global memory 这些数据

43
00:01:49,920 --> 00:01:52,360
真正的搬运到 CPU 里面的 cache

44
00:01:52,400 --> 00:01:56,120
就离计算单元更近的 cache 里面

45
00:01:56,120 --> 00:01:58,920
以便更好地利用访存的局部性

46
00:01:58,920 --> 00:02:00,600
提升整体的命中率

47
00:02:00,600 --> 00:02:02,600
包括 GPU 也是一样的

48
00:02:02,600 --> 00:02:05,280
从 host 的一些 global memory 里面

49
00:02:05,280 --> 00:02:08,000
把一些数据读到 L2 的 cache 里面

50
00:02:08,000 --> 00:02:10,960
通过这种方式一级一级地递增

51
00:02:10,960 --> 00:02:13,200
提供整体的命中率

52
00:02:13,200 --> 00:02:14,960
那可以看到了这里面

53
00:02:14,960 --> 00:02:18,040
GPU 会通过 PCIe 桥或者 NVLink

54
00:02:18,040 --> 00:02:21,200
跟 GPU 之间互联互通

55
00:02:21,240 --> 00:02:23,960
而 global memory 其实就是一个事情

56
00:02:23,960 --> 00:02:26,360
这里面就有了一个异构的架构

57
00:02:26,360 --> 00:02:28,720
一个是 CPU 一个是 GPU

58
00:02:28,720 --> 00:02:31,400
CPU 里面有少量的核

59
00:02:31,400 --> 00:02:32,960
所以它叫做 SIMD

60
00:02:32,960 --> 00:02:36,400
而 GPU 里面有大量的线程处 SM

61
00:02:36,400 --> 00:02:40,720
所以它大部分使用的是一个 SIMT 的架构

62
00:02:40,720 --> 00:02:42,120
那下面可以看到

63
00:02:42,120 --> 00:02:45,320
不管是哪种方式都有多级的缓存

64
00:02:45,320 --> 00:02:47,600
如何更好的利用多级的缓存

65
00:02:47,600 --> 00:02:49,480
是一个很重要的概念

66
00:02:49,520 --> 00:02:51,320
那下面回顾一下

67
00:02:51,320 --> 00:02:53,840
在之前其实已经简单的讲过了

68
00:02:53,840 --> 00:02:57,720
对内存确实需要进行一个对齐的

69
00:02:57,720 --> 00:03:00,840
实际上内存的对齐是以字节为单位的

70
00:03:00,840 --> 00:03:02,960
就是最小的存储单位

71
00:03:02,960 --> 00:03:04,520
一个变量的内存地址

72
00:03:04,520 --> 00:03:06,760
刚好等于它的长度的整倍数

73
00:03:06,760 --> 00:03:09,320
那这种叫做自然对齐

74
00:03:09,320 --> 00:03:11,880
像在 32 位的 CPU 里面

75
00:03:11,880 --> 00:03:15,440
一个 UINT32 的数据

76
00:03:15,440 --> 00:03:18,400
它的内存地址假设是 0x2004

77
00:03:18,440 --> 00:03:20,480
那这种就属于自然对齐

78
00:03:20,480 --> 00:03:22,680
可以看到 4 跟 32 的这个数据

79
00:03:22,680 --> 00:03:26,040
和这个字节单位是相同的

80
00:03:26,040 --> 00:03:29,160
而内存空间按字节进行划分

81
00:03:29,160 --> 00:03:32,080
对齐的好处就是可以从内存里面的

82
00:03:32,080 --> 00:03:34,640
任意一个地址上面进行读取

83
00:03:34,640 --> 00:03:36,240
都是没有问题的

84
00:03:36,240 --> 00:03:38,800
那下面了解完整体的内存

85
00:03:38,800 --> 00:03:40,600
在硬件上面是怎幺实现的

86
00:03:40,600 --> 00:03:41,680
或者怎幺去布局的

87
00:03:41,680 --> 00:03:43,760
还有它的一个对齐的方式

88
00:03:43,760 --> 00:03:45,600
下面看一下具体的内容

89
00:03:45,600 --> 00:03:48,040
就 Tensor 内存的布局

90
00:03:48,040 --> 00:03:49,360
因为在神经网络里面

91
00:03:49,360 --> 00:03:51,080
大量的流动的数据

92
00:03:51,080 --> 00:03:54,320
都是以 Tensor 作为基本单位的

93
00:03:54,320 --> 00:03:55,320
而 Tensor 这个概念

94
00:03:55,320 --> 00:03:56,920
其实在前面几页里面

95
00:03:56,920 --> 00:03:58,880
已经给大家都已经讲烂了

96
00:03:58,880 --> 00:04:02,040
这里面我就简单的翻一翻了

97
00:04:03,040 --> 00:04:05,640
Tensor 是神经网络里面的

98
00:04:05,640 --> 00:04:07,000
一个基本的数据结构

99
00:04:07,000 --> 00:04:09,120
里面就包括里面的 Shape 了

100
00:04:09,120 --> 00:04:10,600
当然还有 Data Type

101
00:04:10,600 --> 00:04:12,800
Shape 和 Data Type 都是很重要的

102
00:04:12,800 --> 00:04:13,920
Shape 就决定了

103
00:04:13,920 --> 00:04:16,120
我到底是一个什幺方式组成

104
00:04:16,120 --> 00:04:17,520
而 Data Type 就决定了

105
00:04:17,520 --> 00:04:18,480
每一个元素

106
00:04:18,480 --> 00:04:20,240
到底属于什幺一个形状

107
00:04:20,240 --> 00:04:23,240
最后就按内存的地址进行排布了

108
00:04:23,240 --> 00:04:24,760
而真正的索引的时候

109
00:04:24,760 --> 00:04:26,400
会根据 Tensor 的 Shape

110
00:04:26,400 --> 00:04:27,720
进行一个索引

111
00:04:27,720 --> 00:04:29,800
而索引每次索引多少内容

112
00:04:29,800 --> 00:04:31,200
或者多少一个字节

113
00:04:31,200 --> 00:04:33,600
就是按 Data Type 来进行决定的

114
00:04:33,600 --> 00:04:35,440
所以这两个数值非常重要

115
00:04:35,440 --> 00:04:36,480
那在张量里面

116
00:04:36,480 --> 00:04:37,320
可以看到

117
00:04:37,320 --> 00:04:38,200
一维的张量

118
00:04:38,200 --> 00:04:39,200
确实就一条数据

119
00:04:39,200 --> 00:04:39,920
二维的张量

120
00:04:39,920 --> 00:04:41,800
就是类似于一张黑白的图片

121
00:04:41,800 --> 00:04:42,640
三维的张量

122
00:04:42,640 --> 00:04:44,120
就是彩色的图片

123
00:04:44,120 --> 00:04:45,120
四维的张量

124
00:04:45,120 --> 00:04:46,560
就是很多个三维的张量

125
00:04:46,600 --> 00:04:49,120
堆叠起来前面就多了一个 n

126
00:04:49,120 --> 00:04:50,800
就是 Batch Size 大小

127
00:04:50,800 --> 00:04:51,200
当然了

128
00:04:51,200 --> 00:04:51,800
点语里面

129
00:04:51,800 --> 00:04:53,440
可能还会有五维的张量

130
00:04:53,440 --> 00:04:54,480
那当然六维的张量

131
00:04:54,480 --> 00:04:56,200
其实我现在还没想到太多

132
00:04:56,200 --> 00:04:59,160
之后除非自己硬件进行一个切分

133
00:04:59,160 --> 00:05:01,520
在达芬奇或者在昇腾硬件里面

134
00:05:01,520 --> 00:05:02,360
做了一个切分

135
00:05:02,360 --> 00:05:04,040
就变成把五维变成六维

136
00:05:04,040 --> 00:05:06,000
方便硬件进行计算

137
00:05:06,000 --> 00:05:07,120
但实际上你怎幺切

138
00:05:07,120 --> 00:05:09,120
还是内存数据的排布不一样

139
00:05:09,120 --> 00:05:10,480
而图像一般

140
00:05:10,480 --> 00:05:12,240
图像张量化表示

141
00:05:12,240 --> 00:05:14,600
就是 nchw

142
00:05:14,640 --> 00:05:17,160
那 chw 就是一张彩色图片

143
00:05:17,160 --> 00:05:18,160
再加一个 n

144
00:05:18,160 --> 00:05:19,760
就是一个 Batch Size

145
00:05:19,760 --> 00:05:21,160
就很多张图片

146
00:05:21,160 --> 00:05:22,240
那自然语言处理

147
00:05:22,240 --> 00:05:24,680
可能 NLP 领域会比较特别

148
00:05:24,680 --> 00:05:26,080
会有 Sequenced

149
00:05:26,080 --> 00:05:27,120
就一句话

150
00:05:27,120 --> 00:05:28,000
然后一句话里面

151
00:05:28,000 --> 00:05:29,440
又有多少个 Rost

152
00:05:29,440 --> 00:05:30,320
多少个 Token

153
00:05:30,320 --> 00:05:32,320
或者多少个单词

154
00:05:32,320 --> 00:05:34,400
那一共有多少段

155
00:05:34,400 --> 00:05:35,040
这句话

156
00:05:35,040 --> 00:05:36,640
就是 nsw

157
00:05:36,640 --> 00:05:38,080
是自然语言处理的方式

158
00:05:38,080 --> 00:05:39,680
当然还有 C 书的张量

159
00:05:39,680 --> 00:05:40,840
有点语和图

160
00:05:40,840 --> 00:05:42,400
GNN 这种方式的表达

161
00:05:42,400 --> 00:05:43,400
所以张量的表示

162
00:05:43,400 --> 00:05:44,960
还是非常的复杂的

163
00:05:47,240 --> 00:05:48,240
在 Tensor 的值

164
00:05:48,400 --> 00:05:49,320
存在内存里面

165
00:05:49,480 --> 00:05:50,640
是很有意思的

166
00:05:50,640 --> 00:05:51,880
它有两种方式

167
00:05:51,880 --> 00:05:54,040
第一种是以 row major 的方式

168
00:05:54,040 --> 00:05:56,320
第二种是以 column major 的方式

169
00:05:56,320 --> 00:05:58,280
就是你到底是以行

170
00:05:58,280 --> 00:05:59,960
作为主要的索引顺序

171
00:06:00,240 --> 00:06:02,480
还是以列作为主要的索引顺序

172
00:06:03,000 --> 00:06:05,040
这里面的绿色的图就画错了

173
00:06:05,040 --> 00:06:07,760
按行就是按 Z 的方式进行取的

174
00:06:07,760 --> 00:06:09,080
可以看到都是 Z

175
00:06:09,080 --> 00:06:11,680
而按列就是以 N 的方式进行取的

176
00:06:11,720 --> 00:06:13,680
N 就是这种方式进行取

177
00:06:13,680 --> 00:06:15,080
所以说 Tensor

178
00:06:15,360 --> 00:06:17,160
根据排列的顺序的区别

179
00:06:17,360 --> 00:06:20,520
分为行组存和列组存

180
00:06:20,520 --> 00:06:21,800
两种风格

181
00:06:21,800 --> 00:06:22,720
取数据的时候

182
00:06:22,960 --> 00:06:25,160
是按 Z 形式来取

183
00:06:25,160 --> 00:06:27,040
还是按 N 形式来取

184
00:06:27,040 --> 00:06:28,640
这个就是最通常的

185
00:06:28,640 --> 00:06:30,520
NZ 和 ND 的方式

186
00:06:32,960 --> 00:06:34,280
下面看一下

187
00:06:34,280 --> 00:06:37,040
NCHW 这种数据的存储方式

188
00:06:37,040 --> 00:06:40,200
首先会往 W 先取数据

189
00:06:40,200 --> 00:06:41,240
就 1 2 3 先取

190
00:06:41,360 --> 00:06:42,640
然后再取 H 的数据

191
00:06:42,640 --> 00:06:43,520
就 4 5 6 了

192
00:06:43,520 --> 00:06:45,040
然后再取第三个维度

193
00:06:45,040 --> 00:06:46,480
C 的维度

194
00:06:46,480 --> 00:06:47,360
就是 6 7 8 9

195
00:06:47,360 --> 00:06:48,760
后面绿色的模块

196
00:06:48,760 --> 00:06:51,360
最后再取 N 就不断的累加

197
00:06:51,360 --> 00:06:52,160
这种方式就是

198
00:06:52,160 --> 00:06:55,080
NHW 的数据存储的方式

199
00:06:55,080 --> 00:06:58,040
这种方式其实很好的一个计算

200
00:06:58,160 --> 00:06:59,640
就是 Max Pooling

201
00:06:59,640 --> 00:07:02,000
首先要需要对这幺简单的一个信道

202
00:07:02,320 --> 00:07:04,600
进行一个取最大值

203
00:07:04,600 --> 00:07:06,320
像 NCHW 这种计算

204
00:07:06,560 --> 00:07:08,160
是和 GPU 进行运算了

205
00:07:08,160 --> 00:07:09,640
因为 GPU 的内存带宽大

206
00:07:09,640 --> 00:07:10,920
而且并行能力强

207
00:07:12,240 --> 00:07:14,280
下面看一下

208
00:07:14,280 --> 00:07:15,600
另外一种数据的存储方式

209
00:07:15,600 --> 00:07:16,760
就是 NHWC

210
00:07:16,880 --> 00:07:18,600
这种方式确实讲烂了

211
00:07:18,600 --> 00:07:21,160
NHWC 就是先取 C 信道了

212
00:07:21,160 --> 00:07:22,680
所以会取 173

213
00:07:22,680 --> 00:07:23,880
先取 173

214
00:07:23,880 --> 00:07:27,160
然后再取 2814

215
00:07:27,160 --> 00:07:28,880
这种方式就先取 C

216
00:07:28,880 --> 00:07:29,760
再取 W

217
00:07:29,760 --> 00:07:30,560
再取 H

218
00:07:30,560 --> 00:07:31,680
然后再取 N

219
00:07:31,680 --> 00:07:34,240
就内存的读取的方式不太一样了

220
00:07:34,800 --> 00:07:37,320
像这种方式更适合卷积一乘一

221
00:07:37,320 --> 00:07:38,760
这种计算操作

222
00:07:38,760 --> 00:07:40,480
更适合一些多核的 CPU

223
00:07:40,480 --> 00:07:42,160
进行一个运算的

224
00:07:42,160 --> 00:07:43,760
CPU 的内存带宽比较小

225
00:07:46,040 --> 00:07:46,840
下面看一下

226
00:07:46,840 --> 00:07:48,840
不同的框架的默认的选择方式

227
00:07:48,840 --> 00:07:50,000
因为不同的 AI 框架

228
00:07:50,000 --> 00:07:51,640
可能会有不同的方式

229
00:07:51,640 --> 00:07:53,840
那现在以 NPU 与 GPU 为基础的

230
00:07:53,840 --> 00:07:55,240
像 PyTorch 或者 Mindspot

231
00:07:55,600 --> 00:07:59,880
默认就是 NCHW 的这种数据的存储格式

232
00:07:59,880 --> 00:08:02,440
那 Tensorflow 其实一开始是默认使用

233
00:08:02,440 --> 00:08:05,480
NHWC 的这种数据的存储方式的

234
00:08:05,480 --> 00:08:07,040
而面向移动端

235
00:08:07,280 --> 00:08:09,160
特别是推理引擎

236
00:08:09,400 --> 00:08:12,800
推理引擎更多的也是采用 NHWC 的

237
00:08:12,800 --> 00:08:15,000
为什幺推理引擎大部分采用这种格式呢

238
00:08:15,000 --> 00:08:18,240
因为很多推理引擎都会跑在手机上面

239
00:08:18,240 --> 00:08:21,080
手机上面大部分都是以 ARM 作为

240
00:08:21,080 --> 00:08:24,720
或者是 ARM CPU 作为一个主要的计算单元

241
00:08:24,720 --> 00:08:25,600
或计算单位

242
00:08:25,600 --> 00:08:28,080
所以一般默认都会使用 NHWC

243
00:08:28,080 --> 00:08:29,160
而以 GPU 为主

244
00:08:29,160 --> 00:08:31,440
就会使用大量的 NCHW

245
00:08:31,440 --> 00:08:32,760
它的并行能力特别好

246
00:08:32,760 --> 00:08:34,720
希望尽可能的去利用它的

247
00:08:34,720 --> 00:08:36,640
并行的操作的能力

248
00:08:36,640 --> 00:08:37,440
那这个时候

249
00:08:37,440 --> 00:08:38,640
不同的 AI 框架

250
00:08:38,640 --> 00:08:40,240
或者你面向不同的场景

251
00:08:40,240 --> 00:08:42,600
你会对数据的默认的内存排布

252
00:08:42,600 --> 00:08:44,080
会有不同的需求

253
00:08:44,080 --> 00:08:45,320
那下面可以看一下

254
00:08:45,320 --> 00:08:46,960
它里面最大的区别

255
00:08:46,960 --> 00:08:50,360
就是 NCHW 主要是对每个信道

256
00:08:50,360 --> 00:08:52,160
单独做运算的时候

257
00:08:52,160 --> 00:08:53,600
会特别的快

258
00:08:53,600 --> 00:08:55,080
因为你数据都已经排好了

259
00:08:55,080 --> 00:08:56,440
我单独做运算就特别快

260
00:08:56,840 --> 00:08:58,880
像 NHWC 这种方式

261
00:08:59,000 --> 00:09:01,280
就特别适合于那些不同信道

262
00:09:01,280 --> 00:09:03,320
对于同一像素做运算

263
00:09:03,320 --> 00:09:04,680
例如卷积这种方式

264
00:09:04,680 --> 00:09:05,920
确实也是特别好

265
00:09:05,960 --> 00:09:09,000
所以说不同的数据的排布方式

266
00:09:09,000 --> 00:09:10,520
对于 Kernels 的优化

267
00:09:10,520 --> 00:09:12,880
是非常的讲究

268
00:09:15,680 --> 00:09:17,120
下面看一下一个新的

269
00:09:17,120 --> 00:09:19,920
或者特别有意思的数据的存储格式

270
00:09:19,920 --> 00:09:23,400
NCHWX 多了个X 

271
00:09:23,400 --> 00:09:26,360
那这个 X 就其实往后看

272
00:09:26,360 --> 00:09:28,720
N 就是 batch size 的大小了

273
00:09:28,720 --> 00:09:31,840
这里面的 C 就不是完完全全真正的 C

274
00:09:31,840 --> 00:09:35,640
而是 channel 数除以 X 除以多少个

275
00:09:35,680 --> 00:09:37,560
然后 HW 都不用说了

276
00:09:37,560 --> 00:09:39,560
而 X 你可以默认是 4

277
00:09:39,560 --> 00:09:42,240
32 或 64 位都可以

278
00:09:42,240 --> 00:09:43,400
就很有意思

279
00:09:43,400 --> 00:09:45,920
那这种方式其实在达芬奇架构里面

280
00:09:45,920 --> 00:09:48,880
叫做 NCHWC0

281
00:09:48,880 --> 00:09:50,960
那可能在 MNN 里面

282
00:09:50,960 --> 00:09:54,320
它叫做 NCHWC1

283
00:09:54,320 --> 00:09:55,880
那这种方式不管怎幺样

284
00:09:55,880 --> 00:09:58,800
 X 基本上就从 C 里面切换出来

285
00:09:58,800 --> 00:10:01,080
那具体在数据内存排布是怎幺样的

286
00:10:01,080 --> 00:10:02,960
直接看下面的这个图

287
00:10:03,000 --> 00:10:06,320
假设这个图还是刚才模拟的图

288
00:10:06,320 --> 00:10:10,840
数据还是按 X 进行排布

289
00:10:10,840 --> 00:10:12,320
那这个时候就很有意思了

290
00:10:12,320 --> 00:10:14,880
会 1 2 3 4

291
00:10:14,880 --> 00:10:16,600
假设 X 是 4 的时候

292
00:10:16,600 --> 00:10:19,600
就会把四个数先取出来

293
00:10:19,600 --> 00:10:22,600
1 7 13 还有这个 X

294
00:10:22,600 --> 00:10:26,920
然后再取 2 8 14 X 这个数

295
00:10:26,920 --> 00:10:28,000
通过这种方式

296
00:10:28,000 --> 00:10:33,240
每次只读取整个章量里面的一部分进行处理

297
00:10:33,240 --> 00:10:35,920
非常适合内存的排布

298
00:10:35,920 --> 00:10:37,040
因为之前讲到了

299
00:10:37,040 --> 00:10:40,400
内存的 Cache 分 L1 L2 L0 是吧

300
00:10:40,400 --> 00:10:42,520
所以 L0 最接近 CPU

301
00:10:42,520 --> 00:10:45,240
而 L0 确实是数量最小的

302
00:10:45,240 --> 00:10:46,640
每次在分片的时候

303
00:10:46,640 --> 00:10:48,240
就取够的数据

304
00:10:48,240 --> 00:10:49,280
取得刚刚好

305
00:10:49,280 --> 00:10:50,440
然后计算完之后

306
00:10:50,440 --> 00:10:52,200
下一次再取下一批

307
00:10:52,200 --> 00:10:53,800
这个时候就很好的

308
00:10:53,800 --> 00:10:57,160
充分的利用了内存空间的方案了

309
00:10:59,000 --> 00:11:00,160
下面就具体看一下

310
00:11:00,160 --> 00:11:04,360
NCHW-X 其实更好地适配于 SIMT 这种架构

311
00:11:04,360 --> 00:11:08,960
例如 NCHW-4 可以针对 ARM 的 INT8 的数据类型

312
00:11:08,960 --> 00:11:12,960
充分的利用了 CUDA 里面的 DP4A 这个模块

313
00:11:12,960 --> 00:11:15,320
或者这个指令进行一个计算的

314
00:11:15,320 --> 00:11:16,600
进行一个加速的

315
00:11:16,600 --> 00:11:17,520
另外的话

316
00:11:17,520 --> 00:11:21,000
NCHW-32 NCHW-64

317
00:11:21,000 --> 00:11:23,800
分别可以对 INT8 和 INT4 的数据

318
00:11:23,800 --> 00:11:28,200
更好的利用里面的 Tensor Core 去进行一个计算的

319
00:11:28,200 --> 00:11:30,080
所以说像这种方式

320
00:11:30,080 --> 00:11:32,400
最重要的就是对 Cache 更加友好

321
00:11:32,400 --> 00:11:34,000
减少 Cache missing

322
00:11:34,000 --> 00:11:35,200
提高命中率

323
00:11:35,200 --> 00:11:37,400
这个时候是非常的重要

324
00:11:37,400 --> 00:11:41,000
访存实在确实比计算要慢

325
00:11:41,000 --> 00:11:42,200
因为计算的时候

326
00:11:42,200 --> 00:11:43,880
IOU 算的非常的快

327
00:11:43,880 --> 00:11:47,000
但是很多时候是数据搬运来不及

328
00:11:47,000 --> 00:11:48,600
数据的通讯特别慢

329
00:11:48,600 --> 00:11:50,400
数据的 Cache missing

330
00:11:50,400 --> 00:11:53,000
阻碍了整个运算的效率

331
00:11:53,000 --> 00:11:54,600
这对整个工程实现

332
00:11:54,600 --> 00:11:57,000
确实是非常的恶心

333
00:11:59,000 --> 00:12:00,600
今天的内容就到这里为止

334
00:12:00,600 --> 00:12:02,600
在内存布局这里面

335
00:12:02,600 --> 00:12:05,000
今天了解了三个重要的概念

336
00:12:05,000 --> 00:12:08,600
第一个就是 CPU 和 GPU 的内存的布局

337
00:12:08,600 --> 00:12:10,800
它的 Cache 到底是怎幺样的一个排布方式

338
00:12:10,800 --> 00:12:12,400
接着了解了一下

339
00:12:12,400 --> 00:12:15,400
张亮 Tensor 的 NCHW 和 NCHW-C

340
00:12:15,400 --> 00:12:17,800
具体的排布方式和它适应的场景

341
00:12:17,800 --> 00:12:22,600
最后引用了一个 NCHW-X 这种方式

342
00:12:22,600 --> 00:12:25,600
去看一下不同的为什幺会有这幺一个 X 出来

343
00:12:25,600 --> 00:12:27,600
而这个 NCHW-C

344
00:12:27,600 --> 00:12:29,200
就是对应于华为

345
00:12:29,200 --> 00:12:31,800
升腾达芬奇加工里面的一种数据的格式

346
00:12:31,800 --> 00:12:33,400
而 NCHW-4

347
00:12:33,400 --> 00:12:35,000
就对应于像阿里MNN

348
00:12:35,000 --> 00:12:36,400
或者华为MindSpore

349
00:12:36,400 --> 00:12:39,000
这种数据的存储的方式

350
00:12:39,000 --> 00:12:40,600
好了 今天的内容到这里为止

351
00:12:40,600 --> 00:12:42,400
谢谢各位 拜拜

352
00:12:42,400 --> 00:12:44,000
卷的不行了 卷的不行了

353
00:12:44,000 --> 00:12:45,800
记得一键三连加关注哦

354
00:12:45,800 --> 00:12:47,400
所有的内容都会开源在

355
00:12:47,400 --> 00:12:49,400
下面这条链接里面

356
00:12:49,400 --> 00:12:50,600
拜拜

