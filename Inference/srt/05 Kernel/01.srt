1
00:00:00,000 --> 00:00:04,520
字幕生成：Galaxies     字幕校对：NaHS

2
00:00:06,120 --> 00:00:08,880
哈喽大家好我就是那个上今天的班

3
00:00:08,915 --> 00:00:11,295
睡昨天的觉的ZOMI

4
00:00:11,295 --> 00:00:13,920
今天来到一个新的内容

5
00:00:13,920 --> 00:00:16,620
推理引擎里面的Kernel优化

6
00:00:16,620 --> 00:00:20,600
专门针对推理引擎里的Kernel优化

7
00:00:20,875 --> 00:00:23,767
毫不意外每次在一个新的内容之前

8
00:00:23,767 --> 00:00:26,011
都会做一个全面的一个介绍

9
00:00:26,011 --> 00:00:28,400
介绍一下接下来要去讲

10
00:00:28,400 --> 00:00:30,720
或者要给大家分享和汇报哪些内容

11
00:00:30,720 --> 00:00:34,000
首先看一下其实前面讲了很多内容了

12
00:00:34,000 --> 00:00:37,811
推理系统，再到推理引擎里面的小型化

13
00:00:37,811 --> 00:00:41,000
优化压缩还有推理的转换和优化

14
00:00:41,000 --> 00:00:44,278
接下来真正来到一些执行方面的内容就

15
00:00:44,278 --> 00:00:46,480
是第一个Kernel的优化

16
00:00:46,480 --> 00:00:50,960
那Kernel优化会分开四个内容给大家去汇报的

17
00:00:50,960 --> 00:00:53,800
第一个就是具体的算法的优化

18
00:00:53,800 --> 00:00:58,560
针对推理引擎的卷积Kernel算子进行层面的优化

19
00:00:58,560 --> 00:01:03,600
接着看一下内存布局对于Kernle优化的作用还有它的意义

20
00:01:03,600 --> 00:01:06,805
最后呢会去看一下汇编的优化，特别是在指令和汇编层面怎么去进行优化

21
00:01:06,805 --> 00:01:10,680
特别是在指令和汇编层面怎么去进行优化

22
00:01:10,680 --> 00:01:14,880
然后呢讲完这个内容之后呢真正的去到了调度的优化

23
00:01:14,880 --> 00:01:19,160
调度的优化呢就是把上面的这些优化呢全部都用起来

24
00:01:19,360 --> 00:01:22,688
在推理引擎执行之前，进行一个调度的优化

25
00:01:22,688 --> 00:01:25,240
把Kernel进行排好把内存排好

26
00:01:25,240 --> 00:01:30,880
把汇编指令的编译好，然后再到Runtime的执行

27
00:01:30,880 --> 00:01:34,320
那Runtime呢就是把具体的Kernel调起来

28
00:01:35,520 --> 00:01:39,125
下面呢重新的回到推理引擎的整体架构

29
00:01:39,125 --> 00:01:40,875
可以看到之前的内容啊

30
00:01:40,875 --> 00:01:45,280
是的之前的内容主要是集中在上面的这个模块

31
00:01:45,280 --> 00:01:49,334
中间呢通过一个统一的IR进行一个串通

32
00:01:49,334 --> 00:01:54,459
把模型的转换、图的优化、模型的压缩包括端云协同的一些学习

33
00:01:54,459 --> 00:01:57,160
都建立在一个统一的IR里面

34
00:01:57,160 --> 00:01:57,267
接下来到了下面的这个内容,那下面这个内容呢

35
00:01:57,267 --> 00:02:01,697
接下来到了下面的这个内容,那下面这个内容呢

36
00:02:01,697 --> 00:02:07,297
分开两个颜色，第一个颜色呢就是粉粉嫩嫩的Runtime

37
00:02:07,297 --> 00:02:10,680
第二个颜色呢就是橙色的Kernel

38
00:02:10,680 --> 00:02:15,538
在Runtime部分呢其实大部分去用的时候都是Runtime去用的

39
00:02:15,538 --> 00:02:22,107
但是呢会写很多不同的算子，那这些算子呢都是在Kernel层里面去承载的

40
00:02:22,107 --> 00:02:28,117
而Kernel层你可以看到里面是东西或者内容呢确实是非常非常的多

41
00:02:28,807 --> 00:02:32,615
现在呢打开一下Kernel层里面的内容

42
00:02:32,615 --> 00:02:38,688
那往左边的看一下其实Kernel层呢它主要是高性能的算子层

43
00:02:38,688 --> 00:02:40,960
大家都可以直接这么认为

44
00:02:41,387 --> 00:02:44,462
接着呢在Kernel层会做很多新的事情

45
00:02:44,462 --> 00:02:47,696
第一个需要对这些算子Kernel进行优化

46
00:02:47,696 --> 00:02:49,527
然后执行这些算子Kernel

47
00:02:49,527 --> 00:02:52,321
还有对这些算子Kernel进行调度

48
00:02:52,321 --> 00:02:54,496
那它主要的作用是在这上面

49
00:02:54,496 --> 00:02:58,659
那下面呢再认真地看看这个架构图

50
00:02:59,850 --> 00:03:03,425
在这个架构图里面呢我分开两个虚框

51
00:03:03,425 --> 00:03:06,025
一个呢叫做人工的高性能算子

52
00:03:06,300 --> 00:03:09,866
另外一个呢叫做高性能的算子库

53
00:03:09,866 --> 00:03:13,238
有两个东西，那两个东西区别还是蛮大的

54
00:03:13,238 --> 00:03:18,413
首先看一下像在X86或者ARM的CPU里面

55
00:03:18,413 --> 00:03:22,462
大部分像NEON指令集呢基本上都会用NEON来去实现的

56
00:03:22,462 --> 00:03:28,931
而一些在X86里面，可能会使用一些AVX的指令去实现算子

57
00:03:28,931 --> 00:03:33,918
那在GPU里面呢会使用cuda、OpenCL、Vulkan还有Metal

58
00:03:33,918 --> 00:03:38,396
去实现一些人工定义的高性能的算子

59
00:03:38,396 --> 00:03:42,646
至于在一些MPU里面呢，可能在华为昇腾会用TIK

60
00:03:42,646 --> 00:03:48,496
还有在一些边缘推理芯片里面呢也会用到TVM去生成一些算子

61
00:03:48,496 --> 00:03:51,593
那这个呢就是高性能的人工的算子库

62
00:03:51,593 --> 00:03:55,241
大部分呢都是先写好一个人工定义的算子

63
00:03:55,241 --> 00:03:57,666
然后去进行一个极致的优化

64
00:03:57,666 --> 00:04:01,127
优化完成之后呢其实有很多同类型的算子

65
00:04:01,127 --> 00:04:06,700
可以把它封装起来，变成例如cuDNN、MKLDNN

66
00:04:06,700 --> 00:04:08,258
就变成一个高性能的算子库

67
00:04:08,258 --> 00:04:10,917
给Wintime去调度的

68
00:04:10,917 --> 00:04:13,967
当然Runtime也可以直接调人工实现的算子

69
00:04:13,967 --> 00:04:18,142
具体怎么调就要看Runtime的策略了

70
00:04:19,542 --> 00:04:23,367
讲完整体的架构图之后呢来看看推理流程

71
00:04:23,367 --> 00:04:26,992
那推理流程呢其实之前也讲过了

72
00:04:26,992 --> 00:04:30,158
在整体推理流程里面呢，整个推理引擎

73
00:04:30,158 --> 00:04:34,158
它不仅只有Engine这个引擎，它包括离线模块

74
00:04:34,158 --> 00:04:41,583
而离线模块呢是把训练框架的网络模型转成自己的一个推理的模块

75
00:04:41,583 --> 00:04:47,508
那这个推理模块呢会经过压缩也可以不经过压缩然后给到离线模块

76
00:04:47,508 --> 00:04:51,476
经过一些编译的优化或者图优化

77
00:04:51,476 --> 00:04:53,883
优化完成了就真正的在线执行

78
00:04:54,075 --> 00:04:57,775
那在线执行的这个执行推理引擎这里面呢叫做Runtime

79
00:04:58,115 --> 00:05:00,440
把一些算子调度起来

80
00:05:00,440 --> 00:05:04,360
而后面执行的就是算子就是Kernel层

81
00:05:04,360 --> 00:05:08,160
所以呢一般都会在第五这个位置去呈现

82
00:05:08,160 --> 00:05:10,605
而具体你们可能用的比较少

83
00:05:10,605 --> 00:05:12,520
大部分都是集成在推理引擎里面的

84
00:05:12,520 --> 00:05:12,605
很多底层的这些算子都通过Runtime去调起

85
00:05:12,605 --> 00:05:16,720
很多底层的这些算子都通过Runtime去调起

86
00:05:16,720 --> 00:05:23,280
一般呢通过Runtime::run()可以把整个推理引擎执行起来了

87
00:05:23,280 --> 00:05:27,920
所以说很多时候算子的开发同事Kernel优化的同事

88
00:05:28,000 --> 00:05:30,960
是非常的苦逼的因为他做的很多工作

89
00:05:30,960 --> 00:05:33,520
你感知不到那是没有他是不行的

90
00:05:33,520 --> 00:05:36,280
他需要做很多大量极致的优化

91
00:05:36,560 --> 00:05:39,000
今天的内容呢就到这里为止

92
00:05:39,000 --> 00:05:44,960
将会在后面详细地展开Kernel优化到底做了哪些不一样的东西

93
00:05:44,960 --> 00:05:47,440
Kernel优化有哪些更细节的内容

94
00:05:47,640 --> 00:05:49,400
谢谢各位摆了个拜

95
00:05:49,760 --> 00:05:53,160
卷得不行了卷得不行了记得一键三连加关注哦

96
00:05:53,160 --> 00:05:56,360
所有的内容都会开源在下面这条链接里面

97
00:05:56,760 --> 00:05:57,640
摆了个拜

