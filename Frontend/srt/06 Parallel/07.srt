1
00:00:00,140 --> 00:00:04,700
字幕生成: 粟君杰 字幕校对: 粟君杰
1
00:00:05,120 --> 00:00:06,100
哈喽，大家好
2
00:00:06,100 --> 00:00:07,300
我是ZOMI
3
00:00:07,300 --> 00:00:11,540
今天我们对分布式训练这个系列呢，来个总结
4
00:00:11,540 --> 00:00:12,320
可以看到
5
00:00:12,320 --> 00:00:15,200
其实我们之前呢，讲了非常多的内容
6
00:00:15,200 --> 00:00:17,900
那这些内容呢，还是比较散点的
7
00:00:17,900 --> 00:00:18,920
我们有架构呢
8
00:00:18,920 --> 00:00:19,640
有通讯呢
9
00:00:19,640 --> 00:00:20,619
有算法了
10
00:00:20,619 --> 00:00:22,689
还有大模型并行的一些策略
11
00:00:22,689 --> 00:00:24,999
但是我们往下看一看
12
00:00:24,999 --> 00:00:26,080
what
13
00:00:26,279 --> 00:00:31,019
怎么感觉每一个封面都长得差不多那个样子
14
00:00:34,199 --> 00:00:36,330
这里面呢，不好意思啊
15
00:00:36,330 --> 00:00:39,620
那个我看到我的阅读量确实有点少啊
16
00:00:39,620 --> 00:00:43,460
只有，基本上每个视频只有50多个浏览量了
17
00:00:43,460 --> 00:00:46,370
可能有部分视频还只有十几个浏览量
18
00:00:46,370 --> 00:00:48,500
基本上没人看了
19
00:00:48,500 --> 00:00:49,220
不过没关系
20
00:00:49,220 --> 00:00:50,779
我还是在坚持
21
00:00:51,520 --> 00:00:53,580
就是呢，每个视频长得差不多，每个内容都比较独立
22
00:00:54,930 --> 00:00:56,880
他们之间呢，是什么关系呢，
23
00:00:56,880 --> 00:01:01,090
今天呢，我们就来串一串这些内容
24
00:01:02,090 --> 00:01:10,619
首先是我们来回顾一下深度学习迎来大模型井喷式发展，我们可以看到现在啊大模型的文章特别好发
25
00:01:10,619 --> 00:01:14,050
而且大模型的泛化能力确实特别好
26
00:01:14,050 --> 00:01:15,730
从16年到17年
27
00:01:15,730 --> 00:01:17,170
Transformer出现之后呢
28
00:01:17,170 --> 00:01:21,580
大家就基于Transformer，不断的去引进的c v大模型
29
00:01:21,580 --> 00:01:23,210
多模态大模型
30
00:01:23,210 --> 00:01:26,780
当然自身的语言大模型也在不断的去演
31
00:01:26,780 --> 00:01:31,460
这里面呢，与传统的神经网络模型呢，就形成了一个断代的局面
32
00:01:31,540 --> 00:01:35,200
随着模型的层数和参数量急剧的膨胀
33
00:01:35,200 --> 00:01:38,990
所以我们需要分布式去训练我们的网络模型
34
00:01:38,990 --> 00:01:40,550
而大模型有哪些好处呢
35
00:01:40,550 --> 00:01:41,330
有三个
36
00:01:44,169 --> 00:01:45,369
引入了自监督学习，我的模型大
37
00:01:45,369 --> 00:01:46,839
我的数据量也要大
38
00:01:48,849 --> 00:01:50,720
不要人工标注那么多
39
00:01:50,720 --> 00:01:53,740
第二个呢，就是解决模型碎片化
40
00:01:53,740 --> 00:01:57,460
以前我在一个语言模型里面做十个翻译任务
41
00:01:57,460 --> 00:01:59,470
我需要十个模型
42
00:01:59,470 --> 00:02:04,250
现在呢，一个大模型就可以解决100多种语言翻译任务了
43
00:02:04,250 --> 00:02:09,680
第三个呢，就是模型的参数规模是非常非常的大的
44
00:02:09,680 --> 00:02:12,470
所以我们形成了一个从蓝色的这条线
45
00:02:12,470 --> 00:02:16,160
到红色的这条线形成了一个断带
46
00:02:17,380 --> 00:02:19,980
既然我们有大模型
47
00:02:19,980 --> 00:02:24,150
我们就引入了需要大量的集群和分布式训练的能力
48
00:02:24,150 --> 00:02:24,720
当然了
49
00:02:24,720 --> 00:02:26,040
在分布式训练之前呢，还会有一些规点，checkpoint，accumulate
50
00:02:30,180 --> 00:02:33,340
还有混合精度的一些功能
51
00:02:33,340 --> 00:02:36,220
接下来呢，我们将会从最底层的硬件
52
00:02:36,220 --> 00:02:38,260
然后再往上层不断的去走
53
00:02:38,260 --> 00:02:41,020
那最底层的肯定是我们的AI集群
54
00:02:41,020 --> 00:02:45,080
AI集群呢，我们以那个华为的Atlas系列作为一个例子
55
00:02:45,679 --> 00:02:50,079
从这个渲染图呢，我们可以看到在整个机房里面呢，有非常多的机柜
56
00:02:50,079 --> 00:02:52,740
每排机柜都有非常多的Atlas服务器
57
00:02:52,740 --> 00:02:54,960
所以在真正的服务器机房
58
00:02:54,960 --> 00:02:56,980
它是长这个样子的
59
00:02:56,980 --> 00:03:00,560
左右两边呢，这些都是我们的训练服务器
60
00:03:00,600 --> 00:03:01,560
当然了
61
00:03:01,560 --> 00:03:03,720
更好看的可能是这些渲染图
62
00:03:03,720 --> 00:03:06,990
我们看到的现在其实是我们的机器的屁股
63
00:03:06,990 --> 00:03:08,100
就是插网线
64
00:03:08,100 --> 00:03:10,660
插网口风扇排气的地方
65
00:03:10,660 --> 00:03:12,660
这里面呢，我们叫做热巢
66
00:03:12,660 --> 00:03:18,150
而另外一面呢，就是我们能看到的真实的产品的里面呢，叫做冷风巢
67
00:03:18,150 --> 00:03:19,800
实际上是通冷风的
68
00:03:19,800 --> 00:03:21,720
当然呢，没去过机房的人
69
00:03:21,720 --> 00:03:24,579
可能以为机房有可能是长这样的
70
00:03:24,579 --> 00:03:27,579
但是呢，实际上现在的机房啊，还是比较规约的
71
00:03:27,579 --> 00:03:29,079
网线都是一簇一簇
72
00:03:29,079 --> 00:03:29,860
做好了
73
00:03:29,860 --> 00:03:32,140
排线还是比较好看的
74
00:03:32,140 --> 00:03:34,000
有了AI集群之后呢
75
00:03:34,000 --> 00:03:38,330
我们不能简单地以为，假设我的集群的数量
76
00:03:38,330 --> 00:03:39,590
我的芯片的数量
77
00:03:39,590 --> 00:03:42,230
我的服务器的数量不断的增加
78
00:03:42,230 --> 00:03:45,590
我计算的性能和效率就会不断的提升，其实这里面有个概念叫做加速比
79
00:03:49,260 --> 00:03:53,780
当我们的集群的服务器的数量多到一定程度的时候
80
00:03:53,880 --> 00:03:55,740
计算性能的提升
81
00:03:55,740 --> 00:03:59,220
我们的边际收益呢，就会受到限制
82
00:03:59,220 --> 00:04:03,000
可能后面不断的增加我们的服务器集群
83
00:04:03,160 --> 00:04:08,370
实际系统的计算量和吞吐量呢，可能就已经维持在一个水平了
84
00:04:08,370 --> 00:04:10,950
那这个水平的收益呢，或者吞吐量呢，通过加速比这个公式来去计算的
85
00:04:14,730 --> 00:04:17,310
那这个内容呢，我们就会放在第四节
86
00:04:17,310 --> 00:04:18,870
用哪种服务器架构去讲，我们在AI集群中如何去提升加速比
87
00:04:22,460 --> 00:04:26,289
然后通过一个环跟实际物理的拓扑的步数
88
00:04:26,289 --> 00:04:28,959
提升我们整个系统的吞吐量
89
00:04:28,959 --> 00:04:33,640
使得AI集群的训练的性能和效率不断的得到提升
90
00:04:35,060 --> 00:04:37,420
既然了解完AI集群之后
91
00:04:37,420 --> 00:04:40,590
其实我们现在已经有了非常多的服务器
92
00:04:40,590 --> 00:04:42,210
有了这么多服务器啊
93
00:04:42,210 --> 00:04:45,320
服务器跟服务器之间呢，是需要进行通讯的
94
00:04:45,320 --> 00:04:48,860
我们会在第五节，讲如何实现集合通讯的
95
00:04:48,860 --> 00:04:55,450
而集合通讯最重要的或者最原始最硬核的就是硬件的一些通讯方式
96
00:04:55,450 --> 00:04:59,820
可以看到下面这个图呢，就是我们Atlas的一个正面图
97
00:04:59,820 --> 00:05:01,080
在机房里面呢
98
00:05:01,080 --> 00:05:04,380
我们大部分时间看到的都是服务器的这个屁股
99
00:05:04,380 --> 00:05:05,940
就像很多风扇口啊
100
00:05:05,940 --> 00:05:07,750
很多网络口啊
101
00:05:07,750 --> 00:05:10,360
而这个呢，机器和机器之间的通讯呢
102
00:05:10,360 --> 00:05:14,740
主要是依赖于TCP/IP或者RDMA的这种通讯的方式
103
00:05:14,740 --> 00:05:16,420
另外呢，在机器内呢
104
00:05:16,420 --> 00:05:19,000
一般我们都会在一台机器塞八张卡
105
00:05:19,000 --> 00:05:21,040
就是单机多卡的情况下呢
106
00:05:21,040 --> 00:05:24,270
那这时候呢，我们就需要用到机器内的通讯
107
00:05:24,270 --> 00:05:30,060
机器内的主要是通过内存共享PCIE还有NVLink的方式进行一个通讯的
108
00:05:30,060 --> 00:05:33,330
那NVLink呢，主要是卡跟卡之间通讯
109
00:05:33,330 --> 00:05:38,620
我们也会在第五节里面如何实现集群通讯里面去介绍
110
00:05:39,340 --> 00:05:40,950
有了通讯的硬件
111
00:05:40,950 --> 00:05:44,530
其实我们还需要在软件上面做很多工作
112
00:05:44,530 --> 00:05:46,930
所以在第五节的下里面呢
113
00:05:46,930 --> 00:05:50,280
我们去介绍通讯的原理到底是什么
114
00:05:50,500 --> 00:05:52,240
机器跟机器之间
115
00:05:52,240 --> 00:05:53,500
卡跟卡之间呢
116
00:05:53,500 --> 00:05:56,080
我们就要进行一个集合的通讯
117
00:05:56,080 --> 00:05:59,620
所以这里面呢我们就会介绍一个MPI，NCCL
118
00:05:59,620 --> 00:06:01,960
HCCL的通讯的方式
119
00:06:01,960 --> 00:06:03,400
通讯的原理
120
00:06:03,400 --> 00:06:08,180
最底层的通讯的逻辑，还是回到我们这个图里面呢
121
00:06:11,530 --> 00:06:14,470
那下面呢，我们来聊一聊大模型
122
00:06:14,470 --> 00:06:15,490
什么为之大
123
00:06:15,490 --> 00:06:17,289
怎么才能叫做大
124
00:06:23,810 --> 00:06:26,840
我们通过Transformer的下面这个结构啊
125
00:06:26,840 --> 00:06:29,450
可以输入一个长的序列
126
00:06:29,450 --> 00:06:33,140
甚至我们把图片呢，变成不同的batch
127
00:06:33,140 --> 00:06:34,730
放在我们的网络模型里面
128
00:06:34,730 --> 00:06:36,260
再做一个输入
129
00:06:36,280 --> 00:06:39,460
另外大模型呢，其实还炒了一个冷饭
130
00:06:39,460 --> 00:06:45,720
就是从90年代已经提出的MoE就是稀疏混合专家模型这个结构
131
00:06:45,720 --> 00:06:47,430
然后重新炒了一遍
132
00:06:47,430 --> 00:06:49,340
又结合了Transformer
133
00:06:49,400 --> 00:06:51,020
引入了MoE结构
134
00:06:51,020 --> 00:06:55,240
使得我们的网络模型呢，上到一个万亿规模的级别
135
00:06:55,240 --> 00:06:58,420
有了Transformer和MoE这两种结构呢
136
00:06:58,420 --> 00:07:02,280
我们就可以迎来了真正的大模型爆发的时代
137
00:07:02,580 --> 00:07:07,030
于是呢，在06的上我们去讲讲大模型有哪几种算法结构
138
00:07:07,030 --> 00:07:10,390
刚才我们已经简单的去介绍了几个概念的名词
139
00:07:10,390 --> 00:07:11,590
第一个是Transformer嘛
140
00:07:11,590 --> 00:07:13,090
第二个是MoE 
141
00:07:13,090 --> 00:07:14,890
但是有了这些结构以外啊
142
00:07:14,890 --> 00:07:17,920
它跟网络模型跟大模型之间是什么关系呢
143
00:07:17,920 --> 00:07:18,920
怎么拼接呢
144
00:07:18,920 --> 00:07:23,660
所以我们会在06的下里面去介绍一些SOTA的大模型
145
00:07:23,660 --> 00:07:28,360
那这些SOTA的大模型都是从17年到22年之间
146
00:07:28,360 --> 00:07:31,040
这些非常经典的大模型
147
00:07:31,360 --> 00:07:33,460
有了AI集群的硬件
148
00:07:33,460 --> 00:07:36,340
这些硬件之间的中间可以通讯
149
00:07:36,340 --> 00:07:38,740
然后呢，我们现在又有了算法
150
00:07:38,740 --> 00:07:40,300
接下来缺什么呢
151
00:07:40,300 --> 00:07:42,400
我这些算法要训练起来对吧
152
00:07:42,400 --> 00:07:45,420
那训练起来需要AI框架
153
00:07:45,420 --> 00:07:49,470
所以呢，在AI框架里面呢，就提出了分布式训练系统
154
00:07:49,470 --> 00:07:54,540
就是通过AI框架去实现分布式的训练过程
155
00:07:54,540 --> 00:07:59,280
所以我们会在第三节里面去讲到AI框架的分布式训练的功能
156
00:07:59,280 --> 00:08:00,780
分别用pytorch呢
157
00:08:00,780 --> 00:08:01,620
tensorflow
158
00:08:01,620 --> 00:08:08,440
还有MindSpore去讲讲AI框架里面是如何去支持分布式训练系统的
159
00:08:09,199 --> 00:08:11,829
下面呢，我们再简略的去打开一下
160
00:08:11,829 --> 00:08:14,500
刚才我们已经讲了大模型的算法
161
00:08:14,500 --> 00:08:18,520
我们还讲了AI集群里面如何进行一个通讯的方式
162
00:08:18,520 --> 00:08:22,360
那接下来就是AI框架要实现一个分布式训练的系统
163
00:08:22,360 --> 00:08:24,760
而他要实现分布式训练的系统呢
164
00:08:24,760 --> 00:08:27,190
就离不开两个很重要的内容
165
00:08:27,190 --> 00:08:29,660
第一个呢，就是分布式的并行和同步
166
00:08:29,660 --> 00:08:34,960
那第二个呢，就是硬件的内存优化和计算AI框架支持的分布式
167
00:08:34,960 --> 00:08:35,920
并行之后呢
168
00:08:35,920 --> 00:08:38,870
我们就可以基于AI框架和AI集群
169
00:08:38,870 --> 00:08:42,050
用我们的大模型训练非常多好的精度
170
00:08:42,050 --> 00:08:42,860
好的结果
171
00:08:42,860 --> 00:08:45,500
做很多不同的实验
172
00:08:45,920 --> 00:08:49,040
最后呢，发一篇非常完美的paper
173
00:08:49,820 --> 00:08:52,650
完成我整个学术的生涯
174
00:08:52,650 --> 00:08:56,070
但是成功的路上没有那么简单
175
00:08:56,070 --> 00:08:58,420
总是有绊脚石在出现
176
00:08:58,420 --> 00:08:59,980
那有哪些绊脚石呢
177
00:08:59,980 --> 00:09:03,880
我们可以在02就是大模型训练会遇到什么挑战
178
00:09:03,880 --> 00:09:05,640
这里面呢，去讲讲
179
00:09:05,640 --> 00:09:10,069
其实我们要训练大模型是遇到非常多的阻碍的
180
00:09:10,069 --> 00:09:11,989
第一个呢，就是内存墙
181
00:09:11,989 --> 00:09:13,429
网络模型太大了
182
00:09:13,429 --> 00:09:15,259
一个内存塞不下怎么办
183
00:09:15,259 --> 00:09:17,250
这个呢，就是通讯墙
184
00:09:17,250 --> 00:09:19,470
既然有这么多机器网络模型呢
185
00:09:19,470 --> 00:09:21,810
分布在不同的机器通讯起来了
186
00:09:21,810 --> 00:09:23,479
肯定是很困难的
187
00:09:23,520 --> 00:09:25,140
什么时候进行同步
188
00:09:25,140 --> 00:09:26,280
什么时候进行异步
189
00:09:26,280 --> 00:09:27,570
什么时候进行通讯
190
00:09:27,570 --> 00:09:28,800
通讯慢怎么办
191
00:09:28,800 --> 00:09:30,390
引起了一系列的问题
192
00:09:30,390 --> 00:09:34,239
另外我们还会有性能墙，大模型的训练起来呢
193
00:09:34,239 --> 00:09:37,330
确实性能可能很重要啊
194
00:09:37,330 --> 00:09:43,319
不可能让我一等等几个月，才告诉我训练的大模型精度不达标
195
00:09:43,360 --> 00:09:46,140
导师只能让我延期毕业
196
00:09:46,140 --> 00:09:49,920
那最后一个呢，就是调优墙，大模型要调优
197
00:09:49,920 --> 00:09:54,840
在分布式集群里面调优真的没有想象中那么简单哦
198
00:09:54,840 --> 00:09:56,940
啊其实我们刚才讲了很多挑战
199
00:09:56,940 --> 00:10:01,140
这些挑战归结起来了还是只有一个目标
200
00:10:01,140 --> 00:10:03,240
就是提升我们的TTA
201
00:10:03,400 --> 00:10:05,440
减少我们训练的耗时
202
00:10:05,440 --> 00:10:07,930
提升我们训练的速率
203
00:10:07,930 --> 00:10:11,420
那提升我们训练的速率呢，就有了三种方法
204
00:10:11,440 --> 00:10:14,740
第一种就是单设备计算速率的提升
205
00:10:14,740 --> 00:10:16,480
我们可以做很多的算法呀
206
00:10:16,480 --> 00:10:18,400
混合精度、算子融合、激活重计算、加速优化器
207
00:10:22,090 --> 00:10:24,800
第二个呢，就是设备数的提升
208
00:10:25,200 --> 00:10:26,460
脑子不够用
209
00:10:26,460 --> 00:10:27,210
没关系
210
00:10:27,210 --> 00:10:28,859
多几台机器嘛
211
00:10:29,620 --> 00:10:32,640
第三个就是多设备的并行效率
212
00:10:32,640 --> 00:10:34,320
又提出了数据并行模型
213
00:10:34,320 --> 00:10:35,959
并行流水线并行
214
00:10:36,060 --> 00:10:38,160
多设备的运行效率的提升
215
00:10:38,160 --> 00:10:41,520
是大模型训练或者大模型效率提升的一个关键
216
00:10:41,520 --> 00:10:43,339
所以我们往下打开
217
00:10:43,960 --> 00:10:45,480
在第七的上里面呢
218
00:10:45,480 --> 00:10:47,400
我们去讲了数据的并行
219
00:10:47,400 --> 00:10:50,370
数据并行其实有DP DDP FSDP
220
00:10:50,370 --> 00:10:55,440
针对网络模型里面的不同的参数进行不同的并行策略
221
00:10:55,440 --> 00:10:58,260
那第二个呢，就是张量并行啊
222
00:10:58,260 --> 00:11:00,230
张量并行是模型并行的一种哦
223
00:11:00,230 --> 00:11:05,490
我们就把张量呢，切换到不同的机器上面去做一个并行处理的
224
00:11:05,490 --> 00:11:07,230
另外的话，流水线并行呢
225
00:11:07,230 --> 00:11:09,510
我们会07的下里面去介绍
226
00:11:09,510 --> 00:11:12,890
那流水线并行也是模型并行的一种
227
00:11:12,890 --> 00:11:15,640
因为它大部分都是对模型进行处理
228
00:11:15,640 --> 00:11:19,540
我们会对网络模型的层呢，拆分成不同的stage
229
00:11:19,540 --> 00:11:22,620
然后交给不同的机器进行并行的
230
00:11:23,060 --> 00:11:24,920
讲了这么多模型并行，不是每个并行独立去用的
231
00:11:27,560 --> 00:11:29,580
我是混合在一起用的哦
232
00:11:29,580 --> 00:11:32,290
所以呢，又出现了多维混合并行
233
00:11:32,290 --> 00:11:35,950
而作为混合并行里面呢，我们用了两个例子
234
00:11:35,950 --> 00:11:38,110
第一个例子就是推荐大模型啊
235
00:11:38,110 --> 00:11:41,330
deep learning recommendation model
236
00:11:41,330 --> 00:11:42,290
推荐大模型
237
00:11:42,290 --> 00:11:50,860
第二个呢，就是Megatron-LM 语言大模型去介绍混合并行是怎么实现的呢
238
00:11:50,860 --> 00:11:52,979
这是第八章里面的内容
239
00:11:53,460 --> 00:11:55,940
最后回到我们对训练性能的提升
240
00:11:55,940 --> 00:12:00,080
刚才呢，我们通过第七章第八章去讲了多设备的并行
241
00:12:00,080 --> 00:12:02,870
实际上我们单设备也要提升速率
242
00:12:02,870 --> 00:12:06,199
于是呢，单设备又有了很多不同的算法
243
00:12:06,880 --> 00:12:11,070
现在看回我们这个内容呢，有没有了一些感觉呢
244
00:12:11,070 --> 00:12:14,440
我们首先去看看我们的AI集群的架构
245
00:12:14,440 --> 00:12:15,580
然后呢，有了集群
246
00:12:15,580 --> 00:12:17,140
我们需要通讯嘛
247
00:12:17,140 --> 00:12:20,410
集群能够通讯的证明我们的硬件都ok了
248
00:12:20,410 --> 00:12:23,430
于是呢，我们就去研究大模型的算法
249
00:12:23,430 --> 00:12:27,329
但是大模型要训练起来就会遇到很多挑战
250
00:12:27,329 --> 00:12:32,710
这个时候呢AI框架就可以帮助我们去构建一些分布式训练的能力
251
00:12:32,710 --> 00:12:35,770
但是有分布式训练的能力还不够
252
00:12:35,770 --> 00:12:37,660
我们需要提升训练的性能
253
00:12:37,660 --> 00:12:41,080
于是呢,就提出了很多并行维度的策略
254
00:12:41,080 --> 00:12:45,880
我们对这些策略的混合在一起去提升我们通信的性能
255
00:12:45,880 --> 00:12:48,180
最后呢，针对单机单卡
256
00:12:48,180 --> 00:12:51,810
我们还有一些内存和计算的优化的方式
257
00:12:51,810 --> 00:12:55,780
使得整个大模型训练的又快又好
258
00:12:57,700 --> 00:12:58,740
卷的不行了
259
00:12:58,740 --> 00:12:59,640
卷的不行了
260
00:12:59,640 --> 00:13:01,320
记得一键三连加关注哦
261
00:13:01,320 --> 00:13:05,740
所有的内容都会开源在下面这条链接里面拜了个拜